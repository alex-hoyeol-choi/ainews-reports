# OpenAI closes $110B raise from Amazon, NVIDIA, SoftBank in largest startup fundraise in history @ $840B post-money - 요약

**원문 URL**: https://www.latent.space/p/ainews-openai-closes-110b-raise-from
**번역일**: 2026-02-28 13:08
**발행일**: 2026-02-28

---

다음은 바쁜 기술 경영진과 AI 엔지니어를 위한 AI 뉴스 브리핑입니다.

### 🔥 주요 뉴스
*   **[OpenAI, 1,100억 달러 투자 유치 및 전략적 파트너십 강화]** — OpenAI가 SoftBank, NVIDIA, Amazon으로부터 총 1,100억 달러 규모의 투자를 유치하며 8,400억 달러의 포스트머니 가치를 달성했습니다. NVIDIA와는 Vera Rubin 시스템에서 3 GW의 인퍼런스 및 2 GW의 학습 용량 사용을 포함하고, Amazon과는 AWS를 OpenAI Frontier의 독점 클라우드 제공업체로 지정하며 Trainium3 및 Trainium4 칩을 포함한 2 GW의 Trainium 용량을 8년간 제공받는 등 파트너십을 강화했습니다.
    ![alt](url)

### 📊 모델 & 벤치마크
*   **Alibaba, Qwen3.5 모델 확장 출시:** Alibaba가 Apache 2.0 라이선스의 Qwen3.5 27B dense, 122B A10B MoE, 35B A3B MoE 모델을 출시했습니다. 이 모델들은 262K 컨텍스트를 지원하며 YaRN을 통해 1M까지 확장 가능합니다. Artificial Analysis Intelligence Index에서 27B 및 122B A10B 모델은 42점, 35B A3B 모델은 37점을 기록했습니다.
*   **Arena 리더보드 2026년 2월 순위 발표:** Arena가 2026년 2월 텍스트 및 코드 부문 상위 오픈 모델 순위를 발표했습니다. 텍스트 부문에서는 GLM-5 (1455), Qwen-3.5 397B A17B (1454), Kimi-K2.5 Thinking (1452)이 상위권을 차지했으며, 코드 부문에서는 GLM-5 (1451)가 1위, Kimi-K2.5와 MiniMax-M2.5가 공동 2위를 기록했습니다.
*   **Perplexity, 양방향 임베딩 모델 오픈소스화 (주장):** Perplexity가 리트리벌을 위한 문서 수준 이해도 향상을 목표로 양방향 "Qwen3-retrained" 임베딩 모델(0.6B/4B)을 MIT 라이선스로 오픈소스화했다고 알려졌습니다.

### 🛠️ 제품 & 도구
*   **OpenAI, Deployment Safety Hub 출시:** OpenAI가 배포 안전성 문서에 대한 접근성을 높이기 위해 "시스템 카드"를 검색할 수 있는 Deployment Safety Hub 웹사이트를 출시했습니다.
*   **Arena-Rank 오픈소스 랭킹 패키지 공개:** Arena가 재현 가능한 리더보드 구축을 위한 오픈소스 랭킹 패키지인 Arena-Rank를 공개했습니다.

### 🔬 연구 & 논문
*   **Sakana AI, Hypernetworks 기반 Doc-to-LoRA 및 Text-to-LoRA 방법론 발표:** Sakana AI가 하이퍼네트워크를 학습시켜 단일 포워드 패스로 LoRA 어댑터를 생성하는 Doc-to-LoRA 및 Text-to-LoRA 방법을 소개했습니다. Doc-to-LoRA는 기본 모델 컨텍스트 윈도우보다 약 5배 긴 시퀀스에서 거의 완벽한 정확도를 보고하며, VLM에서 텍스트 전용 모델로 시각 정보를 전송하는 교차 모달 트릭을 시연했습니다.
*   **DeepSeek, DualPath I/O 시스템 수준 재설계 논문 제안:** DeepSeek, THU, PKU 연구진이 RDMA를 통해 디코드 노드의 유휴 스토리지 NIC 대역폭을 활용하는 Prefill/Decode의 시스템 수준 재설계를 제안했습니다. 이는 에이전틱 긴 컨텍스트 인퍼런스를 위한 KV-캐시 이동 병목 현상을 목표로 하며, DS-660B에서 1.87배의 속도 향상을 주장합니다.
*   **Databricks MosaicAI, 오프-폴리시 RL 방법 OAPL 공개:** Databricks가 GRPO와 유사하거나 능가하면서 약 3배 적은 학습 세대를 사용하는 안정적인 오프-폴리시 강화 학습 방법인 OAPL(Optimal Advantage-based Policy Optimization with lagged inference policy)을 발표했습니다.
*   **Experiential Reinforcement Learning (ERL) 방법론 소개:** 에피소드 내 반성/재시도 및 디스틸레이션을 삽입하는 Experiential Reinforcement Learning(ERL)이 표준 RLVR과 대조되며, Sokoban에서 81% 향상된 성능을 보고했습니다.
*   **Mamba-2 / GDN 초기화 버그 확인:** Albert Gu가 Mamba-2의 일부 결과에 실질적인 영향을 미치는 초기화 버그가 존재함을 명확히 했습니다.

### 💰 산업 동향
*   **Anthropic, 국방부의 대규모 감시 및 자율 무기 사용 거부:** Anthropic이 대규모 국내 감시 및 완전 자율 무기 사용을 공개적으로 거부했습니다. 이에 미국 국방부는 Anthropic을 "국가 안보에 대한 공급망 위험"으로 지정하려 했으며, Anthropic은 공식 성명을 통해 법정에서 이의를 제기할 의사를 밝혔습니다.

### ⚡ 인프라 & 하드웨어
*   **vLLM, ROCm 어텐션 백엔드 출시 및 성능 향상:** vLLM이 KV-캐시 레이아웃 변경, 배치 트릭, 모델별 커널을 포함한 ROCm용 7가지 어텐션 백엔드를 발표했습니다. AMD GPU에서 환경 변수 스위치(VLLM_ROCM_USE_AITER=1)를 통해 최대 4.4배의 디코드 처리량 향상을 보고했으며, MI300X/MI325X/MI355X 칩에서의 처리량 이점을 상세히 설명했습니다.

---

*이 문서는 Latent Space AINews 뉴스레터를 자동 요약한 것입니다.*
