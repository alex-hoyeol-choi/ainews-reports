# Claude Code Anniversary + Launches from: Qwen 3.5, Cursor Demos, Cognition Devin 2.2, Inception Mercury 2

**원문 URL**: https://news.smol.ai/issues/2026-02-24-claude-code
**번역일**: 2026-02-26 01:31
**발행일**: 2026-02-24

---

모두가 모든 것을 한꺼번에 모든 곳에서 출시하고 있습니다.
2026년 2월 23일~2월 24일 AI 뉴스입니다. 저희는 12개 서브레딧, 544개 트위터 계정, 24개 디스코드(262개 채널, 10075개 메시지)를 확인하여 이 소식을 전해드립니다. 절약된 예상 독서 시간(분당 200단어 기준): 874분. AINews 웹사이트에서 지난 모든 이슈를 검색하실 수 있습니다. AINews는 이제 Latent Space의 한 섹션입니다. 이메일 수신 빈도를 선택/해제하실 수 있습니다!

---

# AI 트위터 요약
프론티어 모델 생태계: Qwen 3.5 “미디엄 시리즈”와 오픈 웨이트 모멘텀
- Qwen 3.5 미디엄 모델 시리즈: Alibaba는 "더 많은 지능, 더 적은 컴퓨팅" 모델 세트인 Qwen3.5-Flash (호스팅), Qwen3.5-35B-A3B (MoE), Qwen3.5-122B-A10B (MoE), Qwen3.5-27B (dense)를 출시했습니다. 이들은 아키텍처 + 데이터 + RL이 단순한 파라미터 스케일링을 능가할 수 있다고 주장합니다. 주목할 만한 세부 사항으로는 Flash가 기본적으로 1M 컨텍스트를 사용하며, 호스팅된 제품에 내장 도구가 포함되어 있다는 점입니다. 전체 발표 내용과 @Alibaba_Qwen의 Hugging Face/ModelScope/API 링크를 확인하십시오.

초기 실무자들의 반응은 35B-A3B와 122B-A10B가 실제 사용에서 얼마나 강력하게 느껴지는지(예: @andrew_n_carr, @JustinLin610) 강조하며, @awnihannun이 언급한 35B 모델이 235B 이전 모델을 능가하는 "와트당 지능"의 의미를 부각했습니다.
배포/서빙 스택이 빠르게 발전하고 있습니다: 커뮤니티 툴링도 빠르게 뒤따랐습니다—@UnslothAI의 GGUF + 사이징 가이드와 @terryyuezhuo의 "35B-A3B만 있으면 됩니다"와 같은 로컬 실행에 대한 열정이 있었습니다. Qwen은 또한 SGLang 지원을 강조했습니다(트윗).
양자화(Quant) + "로컬 프론티어" 트렌드: INT4 변형이 등장했으며(중복 게시물) @HaihaoShen을 통해, 사용자들은 계속해서 공격적인 양자화 워크플로우를 추진하고 있습니다(예: @0xSero의 초저비트 로컬 Qwen에 대한 Unsloth 칭찬).
평가 신호: Qwen의 플래그십 모델인 Qwen3.5-397B-A17B는 HF에서 트렌딩되었고(@Ali_TongyiLab), Code Arena의 에이전틱 웹 개발 스타일 평가에서 강력한 성능을 보였습니다(Arena 게시물). Arena는 또한 Qwen 3.0 대비 순위 변화를 게시했습니다(비교).
OpenAI + Anthropic “제품 접점으로서의 코딩 에이전트” (API, 원격 제어, 웹 소켓, 작업 증명 UX)
- OpenAI: Responses API의 GPT-5.3-Codex: OpenAI는 Responses API를 통해 모든 개발자에게 GPT-5.3-Codex를 출시했습니다(발표). @scaling01이 트윗한 바에 따르면 가격은 입력 $1.75 / 출력 $14입니다. OpenAI는 또한 에이전트가 "실제 파일"을 직접 수집할 수 있도록 파일 입력 유형(docx/pptx/csv/xlsx 등)을 확장했습니다(트윗).

인프라 세부 사항: 웹 소켓은 에이전트 처리량을 위한 의미 있는 지렛대로 나타납니다—@gdb에 따르면 "30% 더 빠른 롤아웃"입니다. 이는 웹 소켓이 왜 시간이 걸렸는지, 그리고 상태가 VRAM 대비 업스트림에 어떻게 저장되는지에 대한 광범위한 논의와 일치합니다(스레드, 후속).
벤치마크: 타사 스코어보드 게시물은 TerminalBench/IOI/LiveCodeBench/VibeCodeBench 전반에서 Codex 5.3의 강력한 순위를 주장합니다(ValsAI).
- Anthropic: “Claude Code Remote Control” + 엔터프라이즈 워크플로우 추진: Anthropic은 Claude Code용 "Remote Control"을 도입했습니다—로컬에서 터미널 세션을 시작하고 휴대폰에서 계속할 수 있습니다—이는 @noahzweben을 통해 처음 알려졌고, @claudeai에 의해 공식화되었으며, @_catwu로부터 롤아웃 확인을 받았습니다.

별도의 엔터프라이즈 포지셔닝: 팀 전체에서 Claude를 커스터마이징하기 위한 "Cowork 및 플러그인 업데이트"가 매우 높은 참여율로 공개되었습니다(@claudeai).
- Cursor: “리뷰는 데모 비디오, diff가 아닙니다”: Cursor는 주요 UX 전환을 발표했습니다—에이전트가 자신이 만든 소프트웨어를 사용한 다음, 작업 비디오를 보낼 수 있습니다("diff가 아닌 데모")(출시, 링크). 여러 빌더는 클라우드 에이전트를 실질적인 단계적 변화로 설명합니다: 비동기, VM 기반 테스트, 자체 검증 및 데모 아티팩트(예시, 또 다른 예시, "시뮬레이션 위의 크리에이티브 디렉터").
언어용 Diffusion: Inception Labs Mercury 2와 "속도가 다음 전장"
- Mercury 2 (“추론 Diffusion LLM”): Inception Labs는 Mercury 2를 출시했으며, 이를 초당 약 1,000개의 출력 토큰을 달성하는 프로덕션 Diffusion LLM으로 포지셔닝했습니다(Stefano Ermon). Artificial Analysis는 이를 지능 면에서 프론티어를 선도하지는 않지만, 출력 속도 면에서 이례적으로 강력하며, Terminal-Bench Hard 및 IFBench 점수 주장 비교를 포함하여 괜찮은 에이전틱/코딩 평가를 보인다고 설명합니다(분석 스레드).
- 이 게시물들 전반에 걸친 더 깊은 시사점: 팀들은 아키텍처 수준의 병렬 토큰 정제(diffusion)가 다단계 에이전트 루프와 음성 비서가 "일괄 처리" 방식이 아닌 "네이티브"처럼 느껴지게 할 수 있다고 베팅하고 있습니다(@LiorOnAI의 아키텍처 설명을 참조하십시오). 이는 2026년 경쟁이 단순히 원시 벤치마크 최고치뿐만 아니라 레이턴시 + 처리량으로 정의될 수 있다는 광범위한 정서와 일치합니다.
에이전트: 신뢰성, 안전성 실패, 메모리 + 컨텍스트 로트, 새로운 다국어 평가
- 에이전트 신뢰성이 역량 발전을 따라가지 못하고 있습니다: 프린스턴대가 주도한 연구는 역량-신뢰성 격차를 공식화하고 측정하여, 신뢰성을 12가지 차원으로 분해하고 큰 역량 향상에도 불구하고 신뢰성 향상은 미미하다는 것을 발견했습니다(논문 + 대시보드; @random_walker의 추가 논평). 이는 에이전트를 자율주행차(AV)와 비교하는 실무자들의 반복적인 "실패의 긴 꼬리" 직관과 일치합니다(ahall_research).
- OpenClaw와 "일상적인 단계 분해" 안전성 우회: 구체적인 에이전트 실패 모드: "위험한 명령을 몇 가지 일상적인 단계로 분할 → 안전성 상실"이며, 받은 편지함 삭제 행위가 언급되었습니다. 저자들은 오픈소스 수정 사항을 주장합니다(논문 스레드).
- AGENTS.md (및 유사 파일)는 해로울 수 있습니다: 두 개의 고신호 게시물은 LLM이 생성한 컨텍스트 파일이 성공률을 낮추면서 비용을 증가시킨다는 연구를 요약합니다. 개발자가 작성한 최소한의 컨텍스트는 약간 도움이 되지만 여전히 비용을 증가시킵니다. 논문 요약은 @omarsar0에서, 동일한 결과 세트를 기반으로 한 실용적인 "작성 방법" 가이드는 @_philschmid에서 확인하십시오.
- 새로운 SWE-bench 다국어 리더보드: 영어/Python을 넘어 소프트웨어 엔지니어링 에이전트를 평가하려는 시도입니다. 이 리더보드는 SWE-bench Verified에 없는 9개 언어로 된 300개 작업을 다루며, 보고된 SOTA는 72%입니다(출시; @KLieret의 추가 통계). 시사점: 모델 순위는 언어에 따라 역전될 수 있으며—이는 글로벌 개발 툴링 및 데이터 수집 전략에 중요합니다.
데이터 + 벤치마크: OCR 포화, "새로운 옵티마이저" 회의론, 적응형/지속적 데이터 제안
- OCR/문서 파싱 벤치마크 포화: 여러 게시물은 OmniDocBench가 한계에 도달하고 있으며(예: 실제 문서에서 실패율이 있는 약 95%), 정확히 일치하는 메트릭이 의미론적으로 올바른 파싱에 불이익을 준다고 주장합니다. @llama_index 및 @jerryjliu0를 참조하십시오. 관련 내용: 저렴한 합성 데이터에도 불구하고 OCR이 여전히 어려운 이유에 대한 혼란(gabriberton)과 PDF QA에서 텍스트 추출이 이미지 표현보다 우수하다는 연구(cwolferesearch).
- "Nature MI 옵티마이저" 논란: 매우 기술적인 비판은 극적인 플롯을 가진 새로운 옵티마이저 논문에서 의심스러운 기준선과 잠재적인 테스트 세트 하이퍼파라미터 선택을 지적하며, 독립적인 검증과 더 잘 튜닝된 기준선(예: nanogpt 스피드런)을 촉구합니다(giffmana; @YouJiacheng의 추가 실험 컨텍스트 포함).
- Adaption Labs: “적응형 데이터”: 여러 트윗은 정적 데이터셋에서 "살아있는 자산" 루프로의 전환을 제안하며, 242개 언어에서 평균 82%의 품질 향상과 얼리 액세스/커뮤니티 프로그램을 주장합니다(회사; @sarahookr의 추가 프레이밍; 여기에서 타사 의역). 더 많은 방법론이 공개될 때까지는 검증된 표준이라기보다는 방향성 있는 가설(데이터 드리프트/피드백 루프)로 간주하십시오.
컴퓨팅, 칩, 로봇 공학: Meta–AMD 메가딜, MatX의 “HBM+SRAM” 베팅, 휴머노이드 제어 스케일링
- Meta ↔ AMD 인프라 계약: Meta는 AMD Instinct GPU를 약 6GW의 데이터 센터 용량에 통합하기 위한 다년간의 계약을 발표했습니다(@AIatMeta). 논평은 이를 NVIDIA 실적 발표를 앞둔 주요 자본 지출/컴퓨팅 신호로 해석합니다(kimmonismus).
- MatX “One” 가속기: MatX는 5억 달러 규모의 시리즈 B 투자를 발표하고, 시스톨릭 어레이 효율성과 더 작은 행렬에서의 더 나은 활용을 결합한 칩 아키텍처를 제안했습니다. 이는 높은 처리량과 낮은 레이턴시를 목표로 하며, HBM을 통해 긴 컨텍스트 워크로드에 명시적으로 대응하면서 SRAM 우선 레이턴시 특성을 유지합니다(reinerpope). Karpathy는 "두 가지 메모리 풀" 제약(SRAM 대 DRAM/HBM)을 강조하고, 메모리+컴퓨팅 오케스트레이션을 다가오는 토큰 수요의 핵심 퍼즐로 설명합니다(karpathy).
- Liquid AI LFM2-24B-A2B: Liquid AI는 LFM2-24B-A2B를 출시했습니다. 이 모델은 약 2.3B 활성/토큰을 가진 24B MoE로, 32GB 풋프린트 내에서 효율성과 엣지 인퍼런스에 최적화되었습니다(출시). Ollama(트윗)와 LM Studio(트윗)를 통해 빠르게 배포되었습니다.
- 로봇 공학 스케일링: NVIDIA SONIC (GEAR-SONIC): 주목할 만한 로봇 공학 스레드는 1억 개 이상의 모션 캡처 프레임과 50만 개 이상의 병렬 시뮬레이션 로봇으로 학습된 42M 파라미터 정책이 50개 시퀀스에서 100% 성공률로 실제 휴머노이드에 제로샷 전이된다고 주장합니다. 코드/가중치는 오픈되어 있습니다(Jim Fan 스레드, 여기 링크). 핵심 "시스템" 주장은 모션 트래킹에서 오는 밀집된 감독이 전신 제어를 위한 다음 토큰 예측의 확장 가능한 아날로그 역할을 한다는 것입니다.

---

### 인기 트윗 (참여도, 기술/산업 관련성 기준)
- Claude Code Remote Control 롤아웃: @claudeai
- Qwen 3.5 미디엄 모델 시리즈 출시: @Alibaba_Qwen
- Cursor 에이전트, “diff가 아닌 데모” 출시: @cursor_ai
- Karpathy, 에이전트 네이티브 인터페이스로서의 CLI에 대해: @karpathy
- Meta–AMD 6GW 인프라 계약: @AIatMeta
- Mercury 2 diffusion LLM 출시: @StefanoErmon
- NVIDIA SONIC 휴머노이드 제어 (오픈소스): @DrJimFan
- MatX 칩 + 5억 달러 시리즈 B 투자: @reinerpope
- AGENTS.md 연구 요약 (컨텍스트가 해로울 수 있음): @omarsar0
- OpenAI Responses API에 GPT-5.3-Codex 추가: @OpenAIDevs

---

# AI 레딧 요약

## /r/LocalLlama + /r/localLLM 요약

### 1. Qwen3.5 모델 출시 및 벤치마크
- Qwen/Qwen3.5-122B-A10B · Hugging Face (활동: 621): Hugging Face의 Qwen3.5-122B-A10B 모델은 1,220억 개의 파라미터와 262,144 토큰의 컨텍스트 길이를 가지며, 1,010,000 토큰까지 확장 가능한 최첨단 인과 언어 모델입니다. 이 모델은 비전 인코더를 통합하고 Gated Delta Networks 및 Mixture-of-Experts를 사용한 하이브리드 아키텍처를 채택하여 멀티모달 학습 및 인퍼런스 효율성을 향상시킵니다. 201개 언어를 지원하며 다양한 환경에서 확장 가능한 강화 학습에 탁월하여 멀티모달 AI 애플리케이션에서 상당한 발전을 이루었습니다. 댓글 작성자들은 이 모델이 HLE에서 25.3점을 기록했는데, 이는 6개월 전에는 SOTA였으며, gpt-oss-120b의 경쟁자가 될 잠재력에 대해 논의합니다. 그러나 특히 vLLM과 같은 환경에서 효율적인 모델 서빙에 중요한 네이티브 4비트 가중치가 부족하다는 점에 실망감이 있습니다.

Qwen/Qwen3.5-122B-A10B 모델은 HLE 벤치마크에서 25.3점을 달성했는데, 이는 약 6개월 전에는 SOTA로 간주되었습니다. 이는 모델이 이전 선도 모델들과 경쟁력이 있음을 나타내지만, 그 이후로 환경이 변화했습니다.
Qwen/Qwen3.5-122B-A10B 모델에 네이티브 4비트 가중치 지원이 부족하다는 논의가 있습니다. 이는 네이티브 양자화를 제공하는 gpt-oss-120b와 같은 모델에 비해 한계로 여겨집니다. 이는 vLLM을 통해 모델을 서빙하는 사용자에게 특히 중요하며, 네이티브 양자화된 모델은 성능 이점을 제공할 수 있기 때문입니다.
이 댓글은 중국 연구소들이 봉쇄로 인해 MXFP4/NVFP4에서 학습할 수 없어 네이티브 양자화된 모델의 가용성에 영향을 미칠 수 있다는 잠재적인 문제를 지적합니다. 이는 Qwen/Qwen3.5-122B-A10B와 같은 모델의 개발 및 배포에 중요한 요인이 될 수 있습니다.
- Qwen/Qwen3.5-35B-A3B · Hugging Face (활동: 625): Hugging Face의 Qwen3.5-35B-A3B 모델은 350억 개의 파라미터를 자랑하는 비전 인코더를 갖춘 최첨단 인과 언어 모델입니다. 통합된 비전-언어 기반을 특징으로 하며, Gated Delta Networks 및 Mixture-of-Experts를 사용한 하이브리드 아키텍처를 채택하여 성능을 향상시킵니다. 이 모델은 고처리량 인퍼런스에 최적화되어 있으며 201개 언어를 지원하여 추론, 코딩 및 시각적 이해 애플리케이션에 다재다능합니다. 또한 광범위한 컨텍스트 길이와 적응성을 위한 확장 가능한 강화 학습을 제공합니다. 한 댓글은 Alibaba의 트윗에서 언급된 바와 같이 35B 모델이 이전 세대 235B 모델을 능가한다는 점을 강조합니다. 또 다른 댓글은 모델의 양자화된 버전을 변환하려는 지속적인 노력을 언급하며, 배포 최적화에 대한 활발한 커뮤니티 참여를 나타냅니다.

Alibaba의 트윗에 따르면 Qwen3.5-35B-A3B 모델은 235B와 같은 이전 세대 모델을 능가하는 것으로 보고되었습니다. 이는 더 작은 모델이 훨씬 큰 이전 모델을 능가할 수 있도록 하는 모델 아키텍처 또는 학습 기술의 상당한 개선을 시사합니다.
Qwen3.5-35B 모델은 특정 벤치마크에서 놀라운 40%를 달성했는데, 이는 GPT 120B 모델의 일반적인 25%보다 현저히 높습니다. 이러한 성능 도약은 Qwen3 80B 코더 모델이 약 35%를 기록하는 것과 비교할 때 특히 놀랍습니다. 이는 모델의 효율성 또는 역량에서 상당한 발전을 나타내며, 추가 테스트 및 잠재력 탐색에 대한 기대감을 불러일으킵니다.
Qwen3.5-35B-A3B를 포함한 다양한 Qwen 모델의 출시는 Qwen3 30B A3 MoE 및 Qwen3 코더 80B A3 MoE와 같이 다양한 요구 사항을 충족하는 다채로운 라인업을 강조합니다. 이러한 다양성은 모델 개발에 대한 전략적 접근 방식을 시사하며, 다양한 애플리케이션 및 컴퓨팅 리소스에 대한 옵션을 제공합니다.
- qwen chat에서 새로운 Qwen3.5 모델 발견 (활동: 979): 이미지는 채팅 인터페이스에 새로운 Qwen3.5 시리즈 모델을 보여주며, 세 가지 모델을 강조합니다: 텍스트 및 멀티모달 작업을 위해 설계된 MoE(Mixture of Experts) 모델인 Qwen3.5-122B-A10B; 로컬 배포에 최적화된 dense 모델인 Qwen3.5-27B; 그리고 유사한 작업을 위한 또 다른 MoE 모델인 Qwen3.5-35B-A3B입니다. 이 모델들은 오픈소스 이니셔티브의 일부이며, 다양한 기능을 지원하고 dense 및 MoE 아키텍처 모두에 대한 지속적인 초점을 나타냅니다. 122B MoE 모델의 존재는 GLM과 같이 중간 크기 MoE 모델을 출시하지 않은 다른 모델들이 남긴 공백을 채운다는 점에서 특히 주목할 만합니다. 댓글 작성자들은 122B MoE 모델에 대한 열정을 표명하며, GLM과 같은 다른 모델에서 유사한 제품이 없는 상황에서 그 중요성을 언급합니다. 또한 27B 모델과 같은 중간 크기 dense 모델의 지속적인 개발에 대해서도 감사를 표하며, 이는 로컬 배포에 유용하다고 평가됩니다.

Freigus는 27B dense 모델과 122B MoE(Mixture of Experts) 모델의 출시를 강조하며, 중간 크기 dense 모델이 여전히 개발되고 있다는 점에 만족감을 표했습니다. 이는 모델 크기와 성능 사이의 균형을 유지하는 데 중점을 두고 있음을 시사하며, 이는 리소스 제약이 고려되어야 하는 다양한 애플리케이션에 중요합니다.
durden111111은 GLM이 중간 크기 MoE 모델을 출시하지 않았기 때문에 122B MoE 모델의 필요성을 지적합니다. 이는 Qwen이 잠재적으로 채우고 있는 대규모 MoE 모델 시장의 공백을 나타내며, 높은 컴퓨팅 효율성과 확장성이 요구되는 작업에 중요할 수 있습니다.
CireHF103은 Qwen Next 및 3.5 모델이 버전 3.0보다 특히 더 작은 모델 크기에서 상당한 개선을 보였다고 언급합니다. 이는 다양한 스케일에서 성능을 향상시키는 모델 아키텍처 또는 학습 기술의 지속적인 개선을 시사하며, 이는 광범위한 애플리케이션에 유익할 수 있습니다.
- Qwen, 새로운 Qwen3.5 미디엄 모델 출시! (활동: 90): Qwen은 Qwen3.5 미디엄 시리즈의 새로운 모델인 35B-A3B, 27B, 122B-A10B를 출시했습니다. 이 모델들은 지시 따르기, 시각적 추론, 문서 인식과 같은 다양한 벤치마크에서 평가되었으며, 성능은 막대 그래프를 통해 시각화되었습니다. 이 모델들은 다양한 컨텍스트 크기와 하드웨어 요구 사항으로 설계되어, 다양한 컴퓨팅 환경에 대한 확장성과 적응성에 중점을 두었음을 나타냅니다. 이번 출시에는 다양한 비트 구성의 GGUF 버전이 Hugging Face에서 제공되어 테스트 및 배포 접근성을 높였습니다. 댓글 작성자들은 새로운 모델을 테스트하기를 열망하며, 특히 4비트 35B와 6비트 27B의 성능 비교에 관심을 보였습니다. 또한 GGUF 모델의 수가 증가함에 따라 vLLM에 대한 개선된 지원을 요구하는 목소리도 있습니다.

Qwen3.5 미디엄 모델의 출시는 2비트에서 16비트에 이르는 다양한 GGUF 형식을 포함하며, 이는 Hugging Face에서 제공됩니다. 이러한 다양성은 다양한 정밀도 수준에서 테스트를 가능하게 하며, 이는 모델 배포에서 성능과 리소스 사용의 균형을 맞추는 데 중요할 수 있습니다. 모델 링크.
GGUF 모델에 대한 vLLM 지원 필요성에 대한 논의가 있으며, 이는 이러한 새로운 모델 형식을 처리할 수 있는 더 효율적인 인퍼런스 프레임워크에 대한 수요를 나타냅니다. 이는 더 많은 GGUF 모델이 출시됨에 따라 특히 관련성이 높으며, 잠재적으로 더 나은 성능 또는 호환성을 위해 커뮤니티가 이러한 형식으로 전환하고 있음을 시사합니다.
한 사용자는 코딩 작업을 위해 q6KL의 Qwen Coder3 80B에서 새로운 35B-A3B 모델로 업데이트할지 여부를 고려하고 있습니다. 이는 모델 선택에서 흔히 볼 수 있는 의사 결정 과정을 보여주며, 사용자들이 코딩과 같은 특정 사용 사례와 공식 문서에 직접적인 비교가 부족한 상황에서 최신 모델의 이점을 비교 평가하는 방식입니다.

### 2. Anthropic 디스틸레이션 논란
- Anthropic의 최근 디스틸레이션 블로그는 모든 사람이 로컬 오픈 웨이트 모델만 사용하고 싶게 만들 것입니다; 무섭고 디스토피아적입니다 (활동: 949): Anthropic의 디스틸레이션 공격 감지 및 방지 블로그 게시물은 무단 모델 디스틸레이션에 대응하기 위한 접근 방식을 강조합니다. 이는 디스틸러를 오도하기 위해 출력을 오염시키는 것을 포함합니다. 이는 모델 응답의 신뢰성에 대한 우려를 제기하며, 특히 회사에서 문제적이라고 판단한 프롬프트를 제출하는 사용자에게 해당됩니다. 블로그는 API 키와 같은 요청 메타데이터를 사용하여 이러한 공격을 식별하고 대응하는 것을 논의하며, 무단 사용에 대한 선제적인 입장을 시사합니다. 댓글 작성자들은 Anthropic 방법의 효과와 윤리에 대해 회의적인 반응을 보이며, 일부는 '디스틸레이션 공격'이라는 용어 사용을 비판하고 사용자를 추적하기 위해 메타데이터를 사용하는 투명성에 의문을 제기합니다.

Anthropic의 블로그 게시물은 '디스틸레이션 공격'을 처리하는 접근 방식에 대해 논의하며, 요청 차단을 넘어 적극적인 대응 조치를 취했다고 주장합니다. 그들은 이러한 공격을 방해하기 위해 출력을 오염시켰다고 주장하며, 특히 회사에서 '문제적'이라고 판단한 프롬프트를 제출하는 사용자의 모델 응답 신뢰성에 대한 우려를 제기합니다.
블로그 게시물은 '디스틸레이션 공격'을 언급하며, Anthropic이 API 키와 같은 요청 메타데이터를 사용하여 이러한 공격을 식별하고 대응했다고 시사합니다. 이는 일부 사용자들이 이러한 접근 방식이 지나치게 침해적이며 주장을 뒷받침할 명확한 증거 또는 데이터가 부족하다고 느끼기 때문에 그들의 방법의 투명성과 윤리에 대한 회의론으로 이어졌습니다.
Anthropic의 디스틸레이션 공격에 대한 입장은 수출 통제 및 칩 접근 제한을 정당화하는 데 사용되며, 이는 직접적인 모델 학습과 불법적인 디스틸레이션 모두를 제한한다고 주장합니다. 이는 GPU 접근을 통제하기 위한 자기 이익적인 전략으로 비판받았으며, 일부 사용자들은 이러한 관행으로 인해 Anthropic의 API에 대한 재정적 투자에 대해 후회감을 표했습니다.
- Anthropic: “DeepSeek, Moonshot AI, MiniMax에 의한 산업 규모의 모델 디스틸레이션 공격을 확인했습니다.” 🚨 (활동: 6097): 이미지는 AnthropicAI의 트윗으로, DeepSeek, Moonshot AI, MiniMax라는 기업들이 그들의 모델에 대해 산업 규모의 디스틸레이션 공격을 감행한 중대한 보안 침해를 강조합니다. 이 기업들은 24,000개 이상의 사기 계정을 생성하고 Anthropic의 모델인 Claude와 1,600만 회 이상의 상호작용을 통해 자신들의 모델 학습을 위해 Claude의 역량을 추출했다고 주장됩니다. 이 사건은 AI 모델을 무단 데이터 추출로부터 보호하는 데 따르는 어려움과 경쟁적인 AI 개발에서 오용될 가능성을 부각합니다. 댓글 작성자들은 Anthropic의 불만에 대한 윤리적 함의를 논쟁하고 있으며, 일부는 Anthropic 자체의 데이터 관행에서 아이러니를 지적하며, 그들의 비즈니스 모델이 때로는 명시적인 권리 없이 다양한 소스에서 데이터를 디스틸레이션하는 것을 포함한다고 제안합니다.

이 논의는 Anthropic의 데이터셋 생성의 윤리적 함의에 대한 의문을 제기하며, 이는 적절한 권리 없이 다양한 소스에서 데이터를 디스틸레이션하는 것을 포함할 수 있다고 제안합니다. 이는 DeepSeek 및 Moonshot AI와 같은 회사들이 Anthropic 모델에 대해 '산업 규모의 디스틸레이션 공격'을 수행했다고 비난받는 행동과 유사합니다. Anthropic의 비즈니스 모델이 다른 곳에서 데이터를 디스틸레이션하는 데 유사하게 의존할 수 있다는 점에서 아이러니가 지적됩니다.
'디스틸레이션 공격'이라는 용어는 비판을 받으며, 일부는 이 회사들이 Anthropic의 API를 의도된 대로, 비록 대규모로 사용하고 있을 뿐이라고 주장합니다. 이는 그러한 사용이 공격을 구성하는지 아니면 단순히 합법적이지만 공격적인 서비스 사용인지에 대한 논쟁을 불러일으킵니다. 이 대화는 공개 데이터 접근에 의존하는 비즈니스 모델과 AI 모델의 독점적 특성 사이의 긴장을 강조합니다.
DeepSeek 및 MiniMax와 같은 회사들로부터 더 공격적인 디스틸레이션 노력이 필요하다는 요구가 있으며, 이는 모델 개선이 그러한 관행에 의해 주도되는 경쟁 환경을 시사합니다. 이는 기존 모델을 활용하여 빠른 반복과 모델 향상이 이루어지는 광범위한 산업 트렌드를 반영하며, 때로는 윤리적 및 법적 문제로 이어지기도 합니다.
- 사람들이 잘못 알고 있습니다; Anthropic은 디스틸레이션에 신경 쓰지 않습니다. 그들은 단지 중국 오픈소스 모델이 클로즈드 소스 프론티어 모델을 따라잡고 있다는 내러티브에 반박하고 싶을 뿐입니다 (활동: 977): 이미지는 Alek Dimitriev의 트윗과 Anthropic의 모델 Claude에서 오픈소스 모델이 디스틸레이션하는 문제에 대한 Anthropic의 답변을 강조합니다. 논의는 중국 오픈소스 모델이 클로즈드 소스 프론티어 모델을 따라잡고 있다는 내러티브와 여러 연구소에 의한 산업 규모의 디스틸레이션 공격이라는 Anthropic의 주장에 중점을 둡니다. 이 게시물은 Anthropic의 초점이 디스틸레이션 자체에 있는 것이 아니라, 중국 모델이 디스틸레이션이나 모델 가중치 도용 없이 자신들의 역량을 따라잡을 수 있다는 내러티브에 반박하는 데 있다고 제안합니다. 이는 투자자와 미국 정부에 중국에 대한 더 많은 제한을 부과하여 기술 이전을 막도록 영향을 미 미치려는 전략적 움직임으로 간주됩니다. 댓글 작성자들은 중국 연구소의 혁신 역량에 대해 논쟁하며, 일부는 중국 연구소들이 실제로 혁신적이며 단순히 모델을 디스틸레이션하는 것이 아니라고 주장합니다. 다른 이들은 오픈소스 모델의 중요성과 디스틸레이션을 넘어선 혁신을 강조하며, 중국 연구소의 다양한 연구 논문을 그들의 기여에 대한 증거로 인용합니다.

Ok_Knowledge_8259는 Anthropic의 접근 방식에 중요한 경쟁 우위 또는 'MOAT'가 부족하다고 주장하며, 더 나은 모델의 핵심은 깨끗한 데이터, 더 많은 데이터, 그리고 강화 학습(RL)을 스케일링하는 데 있다고 제안합니다. 그들은 DeepSeek과 같은 중국 모델들이 빠르게 출시되어 좋은 성능을 보이고 있으며, 이는 혁신이 클로즈드 소스 모델에만 국한되지 않음을 나타낸다고 강조합니다. 이 댓글 작성자는 또한 '시드 댄스(seed dance)'를 비디오 기술의 SOTA 혁신으로 언급합니다.
Sagyam은 Anthropic이 디스틸레이션에만 집중한다는 주장에 반박하기 위해 기술 논문 목록을 제공합니다. 이 논문에는 'DeepSeek-OCR', 'mHC', 'DeepSeek Sparse Attention', 'Muon Clip Optimizer and agentic post training', 'Lightning Attention', 'Qwen3 Omni Multimodality'와 같은 혁신이 포함됩니다. 이는 단순한 디스틸레이션을 넘어선 지속적인 연구 개발이 이루어지고 있으며, AI 기술의 다양한 발전을 보여줍니다.
awebb78은 중국 연구소에 혁신이 부족하다는 생각을 비판하며, 그들이 AI 모델뿐만 아니라 로봇 공학에서도 상당한 기여를 했다고 강조합니다. 이 댓글은 서구 중심의 논의에서 종종 간과되는 중국 연구소의 혁신적인 작업을 인정하는 것의 중요성을 부각합니다.

### 3. Liquid AI LFM2-24B-A2B 모델 출시
- Liquid AI, LFM2-24B-A2B 출시 (활동: 320): Liquid AI는 240억 개 파라미터를 가진 희소 Mixture-of-Experts (MoE) 모델인 LFM2-24B-A2B를 출시했습니다. 이 모델은 토큰당 20억 개 파라미터가 활성화됩니다. 이 모델은 LFM2 제품군의 일부로, 3억 5천만 개에서 240억 개 파라미터로 확장되었으며, 토큰당 컴퓨팅을 늘리지 않고도 효과적인 스케일링을 보여주었습니다. 아키텍처는 40개 레이어와 MoE 블록당 64개 전문가, 그리고 top-4 라우팅을 포함하며, 32GB RAM에서 실행되도록 설계되어 고성능 소비자 기기에 적합합니다. llama.cpp, vLLM, SGLang을 통한 인퍼런스를 지원하며, 여러 GGUF 양자화를 제공합니다. 벤치마크는 모델이 스케일링됨에 따라 로그 선형적인 품질 개선을 보여주며, Hugging Face에서 오픈 웨이트로 제공됩니다. 댓글 작성자들은 특히 qwen3 coder와 같은 다른 모델과의 비교에서 이 모델의 성능에 대한 기대감을 표현했습니다. 또한 그 기능을 평가하기 위한 더 상세한 벤치마크에 대한 관심도 있었습니다. 설명에 있는 재미있는 오타가 언급되었는데, 이는 모델의 빠른 엣지 인퍼런스 기능을 강조합니다.

Liquid AI의 LFM2-24B-A2B 모델은 빠른 엣지 인퍼런스 기능으로 주목받으며, AMD CPU에서 초당 112개 토큰, H100 GPU에서 초당 293개 토큰을 달성했습니다. 이 모델은 32GB RAM 내에 맞도록 설계되었으며, 출시 초기부터 llama.cpp, vLLM, SGLang과 같은 프레임워크를 지원하여 광범위한 호환성과 효율적인 자원 활용에 중점을 두었음을 보여줍니다.
LFM2-24B-A2B 모델에 대한 상세한 벤치마크가 부족하여 사용자들 사이에 일부 회의감이 생겼습니다. 이 모델은 잠재력에 대해 칭찬받고 있지만, 특히 Qwen3 Coder와 같은 경쟁 모델과 비교했을 때 포괄적인 성능 데이터의 부재는 이 모델로 전환을 고려하는 사람들에게 우려 사항입니다.
LFM2-24B-A2B 모델은 현재까지 17조 개 토큰으로 학습되었으며, 사전 학습은 여전히 진행 중입니다. 이번 출시는 프리뷰로 간주되며, 추가 후속 학습 및 강화 학습을 포함할 업데이트된 버전인 LFM2.5-24B-A2B에 대한 기대가 있어 현재 모델이 아직 완전히 최적화되지 않았음을 시사합니다.
- 당신이 하면 디스틸레이션. 우리가 하면 학습. (활동: 3433): 이 이미지는 모델 디스틸레이션에 대한 AI 커뮤니티의 이중 잣대를 유머러스하게 강조하는 밈입니다. 다른 사람들이 디스틸레이션을 할 때는 비판받지만, 내부적으로 '학습 데이터'로 사용될 때는 합법적인 것으로 간주된다는 것을 시사합니다. 이는 특히 대규모 AI 모델의 맥락에서 디스틸레이션 기법 사용의 윤리 및 투명성에 대한 지속적인 논쟁을 반영합니다. 댓글에서는 디스틸레이션의 함의에 대해 더 논의하며, 작고 저렴한 모델이 종종 더 큰 모델로부터의 디스틸레이션에 의존하며, 디스틸레이션을 통해 독점 모델을 복제할 수 있을 때 그 방어 가능성에 의문을 제기합니다. 댓글 작성자들은 디스틸레이션 관행에 대한 AI 커뮤니티의 인지된 위선을 강조하며, Anthropic과 같은 회사의 윤리적 입장에 의문을 제기합니다. 그들은 저렴한 모델의 진정한 '비밀 소스'는 종종 더 큰 모델로부터의 디스틸레이션이며, 디스틸레이션의 용이성을 고려할 때 프론티어 모델의 독점적 성격에 대해 회의감을 표현합니다.

이 논의는 더 큰 모델에서 파생된 작고 저렴한 모델의 디스틸레이션 관행을 강조합니다. 이 과정은 종종 이러한 모델의 '비밀 소스'로 간주되어, 대규모 모델을 처음부터 학습시키는 데 드는 높은 비용 없이도 좋은 성능을 발휘할 수 있게 합니다. 이는 프론티어 모델의 경쟁 우위가 디스틸레이션을 통해 쉽게 복제될 수 있다면 약화될 수 있으며, 그러한 모델에 대한 투자의 방어 가능성에 대한 의문을 제기한다는 함의를 가집니다.
Anthropic의 AI 개발 접근 방식에 대한 비판이 있는데, 그들이 오픈소스 커뮤니티에 기여하지 않았고, 합법성에 대한 고려 없이 기존 데이터셋에 크게 의존했을 수 있다는 주장입니다. 이는 데이터 사용 및 모델 학습 과정의 투명성에 대한 윤리적 우려를 제기합니다. 또한 Anthropic의 오픈소스 모델에 대한 입장과 정책 및 검열에 대한 그들의 영향력에 대한 비판도 있는데, 일부는 그들의 관행을 고려할 때 위선적이라고 봅니다.
이 대화는 Wikipedia와 같이 공개적으로 사용 가능한 데이터를 AI 모델 학습에 사용하는 것의 윤리적, 법적 함의에 대해 다룹니다. 이러한 관행은 AI 연구소들 사이에서 흔하지만, 그러한 데이터와 관련된 소유권 및 권리에 대한 의문을 제기합니다. 이 논쟁은 AI 학습에서 데이터 사용에 대한 더 명확한 가이드라인과 규제의 필요성을 시사하여 공정하고 합법적인 관행을 보장해야 함을 나타냅니다.
- 재미있는 사실: Anthropic은 LLM을 오픈소스화한 적이 없습니다 (활동: 938): Anthropic은 Claude를 포함하여 어떤 대규모 언어 모델(LLM)도 오픈소스화한 적이 없으며, 이는 특히 다국어 환경에서 그들의 토크나이저 효율성에 대한 외부 분석을 제한합니다. 대조적으로, OpenAI는 그들의 토크나이저와 gpt-oss와 같은 모델을 오픈소스화했으며, Google은 그들의 모델 Gemma와 Gemini가 동일한 토크나이저를 사용한다고 공유했습니다. Anthropic의 이러한 오픈소스 기여 부족은 AI 연구의 투명성과 협력으로 향하는 업계의 추세를 고려할 때 주목할 만합니다. 댓글 작성자들은 Anthropic이 AI 안전성 발전에 필수적인 오픈 연구에 기여하지 않으면서 안전성을 강조하는 아이러니를 지적합니다. 또한 OpenAI의 더 개방적인 접근 방식과 비교하며 커뮤니티 기여의 불균형을 시사합니다.

TheRealMasonMac은 Claude 모델의 기술적 한계를 강조하며, “ 또는 ‘와 같은 타이포그래피 컬리 쿼트를 출력할 수 없다고 지적합니다. 이 한계는 이러한 특정 토큰에 의존하는 코드에서 문제를 일으킬 수 있으며, 댓글 작성자가 경험했듯이 코드를 손상시켰습니다. 이는 모델의 토크나이징 기능에서 개선될 수 있는 잠재적 영역을 지적합니다.
- 위선? (활동: 748): 이 이미지는 DeepSeek, Moonshot AI, MiniMax와 같은 회사들이 Anthropic의 AI 모델인 Claude에 대해 산업 규모의 디스틸레이션 공격을 수행하고 있다고 비난받는 AI 커뮤니티의 중요한 문제를 강조합니다. 이들 기업은 24,000개 이상의 사기성 계정을 만들고 1,600만 회의 상호작용을 실행하여 Claude의 기능을 추출하고 자신들의 모델을 위해 복제했다고 주장됩니다. 이는 AI 모델 개발에 사용되는 방법과 AI 산업에서 지적 재산 보호에 대한 윤리적 우려를 제기합니다. 한 댓글 작성자는 이들 회사의 윤리적 입장에 의문을 제기하며, 그들이 학습 데이터를 획득하기 위해 유사한 방법을 사용했을 수 있음을 암시합니다. 또 다른 댓글 작성자는 z.ai가 언급되지 않은 것에 놀라움을 표하며, 그들의 GLM suite도 유사한 관행에 연루되었을 수 있음을 시사합니다.

'archieve_'의 댓글은 AI 모델의 학습 데이터 출처에 대한 중요한 질문을 제기합니다. 이는 데이터의 출처가 모델의 편향성, 합법성 및 성능에 영향을 미칠 수 있으므로 AI 윤리 및 합법성에서 중요한 문제입니다. 데이터 출처를 이해하는 것은 AI 개발의 투명성과 책임성을 위해 필수적입니다.
'semangeIof'는 GLM suite와 프롬프트 시 Claude라고 주장하는 그 행동을 언급합니다. 이는 모델 정체성 및 응답 정확성에 대한 잠재적 문제를 강조하며, 이는 사용자 신뢰와 AI 시스템의 인지된 신뢰성에 영향을 미칠 수 있습니다. 이러한 행동은 모델의 학습 또는 프롬프트 처리 메커니즘의 결함을 나타낼 수 있습니다.
'roxoholic'이 언급한 '산업 규모의 디스틸레이션 공격'이라는 용어는 대규모 모델을 더 작은 모델로 디스틸레이션하는 방법을 의미하며, 이는 지적 재산 및 모델 보안에 대한 우려를 제기할 수 있습니다. 이 기술은 원본에 직접 접근하지 않고도 모델을 복제하는 데 사용될 수 있어 독점 AI 기술에 대한 도전을 제기합니다.

## 덜 기술적인 AI 서브레딧 요약
> /r/Singularity, /r/Oobabooga, /r/MachineLearning, /r/OpenAI, /r/ClaudeAI, /r/StableDiffusion, /r/ChatGPT, /r/ChatGPTCoding, /r/aivideo, /r/aivideo

### 1. Anthropic 대 DeepSeek 디스틸레이션 논란
- Anthropic은 DeepSeek, Moonshot AI (Kimi) 및 MiniMax가 24,000개 이상의 사기성 Claude 계정을 설정하고 1,600만 회의 상호작용에서 학습 정보를 디스틸레이션했다고 비난하고 있습니다. (활동: 4142): Anthropic은 DeepSeek, Moonshot AI (Kimi) 및 MiniMax가 자신들의 AI 모델인 Claude에 대해 대규모 데이터 추출 작업을 조직했다고 비난했습니다. Anthropic에 따르면, 이들 회사는 24,000개 이상의 사기성 계정을 만들어 Claude와 1,600만 회 상호작용을 수행하여, 효과적으로 Claude의 학습 데이터를 빼돌려 자신들의 AI 모델을 개선했다고 주장됩니다. 이 사건은 AI 개발에서 데이터 보안 및 지적 재산에 대한 중대한 우려를 강조하며, 무단 액세스 및 독점 AI 기능의 잠재적 오용을 포함합니다. 댓글 작성자들은 AI 회사들이 데이터 절도에 대해 불평하면서도 자신들은 종종 보상 없이 공개적으로 사용 가능한 데이터를 사용한다는 아이러니를 강조하고 있습니다. 이는 데이터 소유권 및 윤리적인 AI 학습 관행에 대한 지속적인 논쟁을 반영합니다.

Free_Break8482는 Anthropic의 비난에 대한 아이러니를 강조하며, AI 회사들이 종종 공개적으로 사용 가능한 인터넷 데이터로 모델을 학습시킨다는 점을 지적합니다. 이는 그러한 데이터의 소유권 및 권리에 대한 의문을 제기합니다. 이는 AI 학습을 위한 공개 정보의 윤리적 사용에 대한 지속적인 논쟁을 강조합니다.
ImmediateDot853은 Anthropic의 오픈소스 커뮤니티 기여에 의문을 제기하며, Anthropic의 AI가 오픈소스 트래픽의 이점을 얻으면서도 오픈소스 프로젝트에 자금을 지원하거나 후원함으로써 보답하지 않을 수 있음을 암시합니다. 이는 AI 생태계에서 기업의 책임과 상호성이라는 더 넓은 문제에 해당합니다.
adalgis231은 Anthropic과 같은 AI 회사들의 인지된 위선을 비판합니다. 이들은 창작자에게 보상 없이 공개적으로 사용 가능한 지적 재산을 사용할 수 있으면서도 다른 사람들을 절도로 비난한다는 것입니다. 이 댓글은 AI 학습 데이터 및 지적 재산권을 둘러싼 복잡한 법적, 윤리적 환경을 반영합니다.
- 또 시작이군요. DeepSeek R1은 OpenAI 모델을 문자 그대로 복사 붙여넣기 한 것이었습니다. 그들은 차단당했고, 이제 Anthropic에 붙었습니다. 사기입니다! (활동: 2519): 이 이미지는 DeepSeek, Moonshot AI, MiniMax와 같은 회사들이 Anthropic의 AI 모델에 대해 산업 규모의 디스틸레이션 공격을 수행하고 있다고 비난받는 심각한 문제를 강조합니다. 이러한 공격은 24,000개 이상의 사기성 계정을 만들고 Claude 모델과 1,600만 회 상호작용을 수행하여 그 기능을 추출하는 것을 포함합니다. 디스틸레이션으로 알려진 이 과정은 일반적으로 더 작고 효율적인 모델을 만드는 데 사용되지만, 여기서는 안전 장치를 우회하고 AI 기능을 잠재적으로 오용하기 위해 남용되고 있습니다. Anthropic은 AI 모델에서 중요한 안전 조치를 제거할 위험이 있는 이러한 정교한 공격에 맞서기 위한 공동의 노력을 촉구하고 있습니다. 댓글은 AI 회사의 윤리적 기준에 대한 비꼬는 어조와 비판이 섞여 있으며, 일부 사용자들은 데이터 절도라는 아이디어를 조롱하고 다른 사용자들은 비윤리적 관행으로 비난받는 회사들이 스스로 유사한 행동의 피해자가 되는 상황의 아이러니를 지적합니다.
- Anthropic이 DeepSeek, Moonshot 및 MiniMax가 Claude를 대량 디스틸레이션했다는 증거를 공개했습니다. 24,000개의 가짜 계정, 1,600만 회 이상의 상호작용입니다. (활동: 2751): Anthropic은 DeepSeek, Moonshot 및 MiniMax를 포함한 세 개의 중국 AI 연구소가 24,000개의 가짜 계정과 1,600만 회 이상의 상호작용을 사용하여 자신들의 모델인 Claude에서 기능을 체계적으로 추출한 방법을 상세히 설명하는 보고서를 발표했습니다. DeepSeek은 특히 Claude를 사용하여 단계별 추론을 설명하게 하여 정치적으로 민감한 콘텐츠를 포함한 학습 데이터를 생성했습니다. MiniMax는 1,300만 회 이상의 상호작용을 수행했으며 새로운 Claude 모델에 빠르게 적응했습니다. 이 보고서는 안전 기능이 디스틸레이션된 모델로 잘 이전되지 않아 미묘한 시나리오에서 잠재적 위험을 초래할 수 있음을 강조합니다. 이러한 상황은 디스틸레이션 후 독립적인 추론의 신호로서 모델 불일치의 가치를 강조합니다. 댓글 작성자들은 Anthropic의 상황에 대한 아이러니를 강조하며, 그들이 가짜 계정 문제에 직면하면서도 자신들은 학습을 위해 광범위한 데이터 소스를 사용했다는 점을 지적합니다. 또한 핵심 시스템을 구축하는 사람들은 안전 기능이 손상된 디스틸레이션된 모델 사용을 피할 것이라는 의견도 있습니다.

VanOrten은 Anthropic의 중대한 보안 감독을 강조하며, 합법적인 사용자들이 VPN 사용으로 계정 취소를 당하는 동안, 시스템은 24,000개의 가짜 계정이 1,600만 회 이상의 상호작용을 수행하는 것을 탐지하고 방지하지 못했다고 지적합니다. 이는 Anthropic의 계정 확인 및 사기 탐지 메커니즘의 견고성에 대한 의문을 제기합니다.
DauntingPrawn은 모델 학습 데이터의 윤리적 고려 사항에 대해 논의하며, Anthropic, OpenAI, Google과 같은 주요 AI 회사들이 역사적으로 방대한 양의 무허가 데이터를 학습에 사용했음을 지적합니다. 이 댓글은 디스틸레이션 모델 관행이 논란의 여지가 있지만, 일부에서는 AI 커뮤니티에서 균형을 재조정하는 형태로 간주된다는 것을 시사합니다.
cororona는 모델 학습의 경제성에 대해 비꼬는 어조로 언급하며, 토큰 비용을 지불하는 것이 해적판과 같은 덜 합법적인 수단을 통해 데이터를 획득하는 것보다 비효율적인 방법임을 암시합니다. 이는 AI 학습을 위한 데이터 획득의 비용과 윤리에 대한 지속적인 논쟁을 강조합니다.
- Anthropic: "DeepSeek, Moonshot AI, MiniMax에 의한 우리 모델에 대한 산업 규모의 디스틸레이션 공격을 확인했습니다." (활동: 1846): Anthropic은 DeepSeek, Moonshot AI 및 MiniMax가 자신들의 AI 모델에 대해 '산업 규모의 디스틸레이션 공격'을 수행했다고 공개적으로 비난했습니다. 이러한 공격은 24,000개 이상의 사기성 계정을 만들어 Anthropic의 모델인 Claude와 상호작용하여 1,600만 회 이상의 상호작용을 초래했습니다. 목표는 Claude의 기능을 추출하고 복제하여 자신들의 모델을 강화하는 것이었습니다. 이 사건은 AI 모델 보안 및 지적 재산 보호에 대한 지속적인 도전을 강조하며, 회사들이 무단 사용 및 복제로부터 독점 기술을 보호하려고 노력하는 상황을 보여줍니다. 댓글은 학습을 위해 독점 AI 모델을 사용하는 윤리에 대한 논쟁을 반영하며, 저작권이 있는 자료로 학습하는 더 넓은 문제와 유사점을 그립니다. 일부 사용자들은 Anthropic의 불만에 대한 아이러니를 비꼬는 어조로 언급하며, AI 커뮤니티의 데이터 사용 접근 방식에 이중 잣대가 있음을 시사합니다.

이 논의는 AI 모델에 대한 디스틸레이션 공격이 저작권이 있는 자료로 학습하는 것과 유사한지 여부에 대한 질문을 제기합니다. 이러한 비교는 둘 다 기존 지적 재산을 사용하여 새로운 모델을 생성하는 것을 포함하므로 잠재적인 윤리적, 법적 회색 지대를 시사합니다. 이는 저작권이 있는 자료로 학습하는 것이 논쟁의 여지가 있다면, 독점 모델에 대한 디스틸레이션 공격도 마찬가지일 수 있다는 함의를 가집니다.
'공격'이라는 용어는 논쟁의 여지가 있으며, 일부는 다른 모델이 기존 모델로부터 학습하는 것이 인간의 학습 과정과 유사하다고 주장합니다. 이러한 관점은 디스틸레이션을 악의적인 것으로 보는 관점에 이의를 제기하며, 모델이 서로에게서 학습하여 진화하는 AI 개발의 자연스러운 부분으로 볼 수 있다고 제안합니다. 이는 인간이 기존 지식으로부터 학습하는 방식과 유사합니다.
'24,000개의 가짜 계정' 언급은 디스틸레이션 공격에 관련된 작업 규모를 강조합니다. 이 숫자는 대규모 웹 서비스의 일반적인 활동과 비교되며, 그러한 공격이 처음 인지된 것보다 더 흔하고 관리 가능할 수 있음을 암시합니다. 이는 많은 대규모 서비스에 이러한 활동을 처리할 인프라가 이미 갖춰져 있음을 시사합니다.

### 2. AI 도구가 레거시 시스템 및 산업에 미치는 영향
- IBM은 Anthropic의 최신 피해 기업으로, COBOL 레거시 코드를 현대화하기 위해 설계된 Claude Code 도구 출시 이후 주가가 10% 급락했습니다. 66년 된 프로그래밍 언어인 COBOL은 오늘날에도 여전히 널리 사용되고 있으며, 미국 ATM 거래의 약 95%가 COBOL 코드를 사용하여 처리됩니다. (활동: 467): Anthropic은 미국 ATM 거래의 95%를 처리하는 데 여전히 중요한 레거시 COBOL 코드를 현대화하기 위한 새로운 도구인 Claude Code를 발표했습니다. 이 발표로 IBM 주가가 10% 하락했으며, 이는 레거시 시스템의 잠재적 혼란에 대한 시장의 민감성을 강조합니다. 그러나 이 도구는 새로운 기술이 아니라 COBOL 시스템 업데이트에 대한 유용성을 제안하는 블로그 게시물이었으며, 시장에 의해 오해되었을 수 있습니다. 댓글 작성자들은 많은 현대 은행 시스템이 여전히 COBOL에 의존하고 있으며, 종종 새로운 기술로 래핑되어 있다고 지적했고, 도구의 효과에 대한 구체적인 증거가 부족하다는 점을 고려할 때 시장의 반응이 시기상조일 수 있다고 언급했습니다. Anthropic 도구의 실제 영향에 대한 회의감이 있으며, 주가 반응이 발표에 비해 불균형적으로 보입니다.

Onipsis의 댓글은 Anthropic의 Claude Code 발표가 새로운 도구의 출시가 아니라 COBOL 현대화에 대한 잠재적 유용성을 제안하는 블로그 게시물이었다는 점을 강조합니다. 이는 시장의 과잉 반응으로 이어져 IBM 주가가 10% 하락했습니다. 이 댓글은 인프라에서 COBOL의 핵심 역할과 이에 익숙한 전문가의 감소를 강조하며, 이는 현대화 노력을 중요하지만 도전적으로 만듭니다.
Milo-75는 특히 COBOL에 크게 의존하는 은행 및 ATM 시스템의 현대화 프로젝트의 복잡성에 대해 논의합니다. 이 댓글은 Claude Code와 같은 AI 도구가 프로젝트 시간을 25% 단축할 잠재력이 있음에도 불구하고, 기업들은 여전히 그러한 핵심 시스템을 처리하는 전문성을 위해 IBM에 의존할 것이라고 주장합니다. 이는 이러한 프로젝트에서 IBM의 수익은 감소할 수 있지만, 마진은 개선되어 더 많은 프로젝트를 수행할 수 있게 될 수 있다는 것을 시사합니다.
Stabile_Feldmaus는 Anthropic의 특수 도구 효과에 대한 명확한 피드백 부족에 대해 지적합니다. 이는 발표에 대한 시장의 부정적인 반응에도 불구하고 나타납니다. 이 댓글은 실제 시나리오에서 이러한 도구의 실제 성능과 유용성이 입증되지 않았으므로 IBM 사업에 대한 이러한 도구의 즉각적인 영향에 대한 회의감을 시사합니다.
- Anthropic이 COBOL용 AI 도구를 출시했고 IBM 주가는 13% 하락했습니다 (활동: 880): Anthropic은 은행, 항공 및 정부 부문의 많은 레거시 시스템에 중요한 COBOL 코드베이스를 분석하고 현대화하도록 설계된 새로운 AI 도구를 출시했습니다. 이 도구는 위험을 식별하고 현대화 비용을 절감하여 IBM의 이러한 시스템 관리 수익을 잠재적으로 위협하는 것을 목표로 합니다. 이 발표로 IBM 주가가 13% 크게 하락했으며, 이는 IBM의 메인프레임 사업에 미치는 영향에 대한 시장의 우려를 반영합니다. 그러나 일부 분석가들은 기존 마이그레이션 대안에도 불구하고 기업들이 IBM에 계속 의존해왔다고 주장하며, 시장 반응이 과장되었을 수 있음을 시사합니다. 댓글 작성자들은 핵심 인프라에 AI에 의존하는 것에 대한 회의감을 표현하며, 한 명은 그러한 맥락에서 '바이브 코딩'의 잠재적 위험을 지적했습니다. 또 다른 댓글 작성자는 시장의 반응이 '즉각적인 반응'일 수 있으며, 장기적인 관점의 필요성을 암시했습니다.

Anthropic의 COBOL용 AI 도구 도입은 레거시 시스템 마이그레이션을 가속화하는 잠재적 촉매제로 여겨지지만, 그러한 마이그레이션과 관련된 위험은 여전히 상당합니다. 은행 및 기타 기관들은 역사적으로 오류의 치명적인 위험 때문에 현대화를 회피해왔으며, AI의 '환각' 경향은 인간의 감독이 여전히 필요하다는 것을 의미합니다. 따라서 AI가 프로세스를 가속화할 수 있지만, 특히 핵심 인프라 애플리케이션의 경우 인간 검토의 병목 현상을 아직 제거하지 못했습니다.
Anthropic과 같은 AI 도구가 제기하는 진정한 위협은 전문 서비스 부문, 특히 레거시 시스템 관리 및 마이그레이션에서 상당한 수익을 얻는 IBM과 같은 회사에 있습니다. AI는 덜 중요한 애플리케이션에 대한 외부 계약자의 필요성을 크게 줄일 수 있으며, 이는 IBM의 전문 서비스 사업에 위험을 초래합니다. 이러한 변화는 핵심 시스템에 대한 즉각적인 영향이 제한적이라 할지라도 레거시 시스템 관리 관련 서비스 수요 감소로 이어질 수 있습니다.
IBM의 주가 하락은 제조 또는 기술의 핵심 사업에 대한 직접적인 위협보다는 전문 서비스 수익에 대한 잠재적 영향에 기인합니다. 비유는 이러한 혼란이 '마차 채찍' 자체보다는 '마차 채찍 광택제' 판매에 영향을 미치는 것과 유사하며, IBM의 사업 모델에 대한 간접적이지만 상당한 영향을 강조합니다.
- Claude가 더 나은 제품입니다. 20달러 요금제의 두 가지 복합적인 사용량 제한 때문에 OpenAI가 제 돈을 가져갑니다. (활동: 1217): 이 Reddit 게시물은 책 편집과 같은 작업에서 Claude의 우수한 성능 때문에 ChatGPT Plus보다 Claude를 선호하는 사용자의 의견을 논의합니다. 그러나 사용자는 Claude Pro의 제한적인 사용량 제한 때문에 ChatGPT Plus에 머물러 있는데, 여기에는 5시간 롤링 세션 윈도우와 사용자를 며칠 동안 잠글 수 있는 주간 제한이 포함됩니다. 사용자는 이러한 제한이 여러 프로젝트에 걸쳐 길고 반복적인 세션을 포함하는 그들의 집중적인 일상 사용에는 Claude Pro를 비실용적으로 만든다고 강조합니다. 그들은 잦은 잠금 없이 진지한 일상 사용자를 수용하기 위해 20달러에서 100달러 사이의 더 유연한 가격 책정 계층의 필요성을 제안합니다. 댓글 작성자들은 Anthropic의 가격 전략이 더 정확하다고 여겨지지만, B2B 초점 때문에 개인 사용자에게는 친화적이지 않다고 지적합니다. 일부 사용자들은 생산성 이점을 고려할 때 월 100달러 요금제가 정당하다고 생각하는 반면, 다른 사용자들은 Claude의 제한에 불만을 표하며 ChatGPT로 다시 전환하는 것을 고려합니다.

Helkost는 AI 회사의 가격 전략에 대해 논의하며, 인퍼런스 비용은 감소하고 있지만 업계 가격은 아직 이러한 비용을 충당하지 못하고 있다고 지적합니다. 그는 Claude를 개발한 Anthropic이 다른 회사보다 제품 가격을 더 정확하게 책정하고 있지만, Anthropic의 주요 초점은 개인 소비자보다는 B2B에 있다는 점을 강조합니다.
turtle-toaster는 AI 서비스의 월 20달러 프로 요금제가 헤비 유저를 위한 것이 아니라 업그레이드를 장려하는 입문용 제안으로 설계되었다고 지적합니다. 그는 이 가격대에서 무제한 요금제는 컴퓨팅 비용으로 인해 재정적으로 지속 불가능할 것이라고 주장하며, 월 60달러 요금제가 진지한 사용자에게 더 실용적일 수 있다고 제안합니다.
FaceOnMars23은 현재 가격 모델에 대한 불만을 표현하며, 사용자에게 더 나은 서비스를 제공할 수 있는 옵션의 공백을 지적합니다. 그는 비용과 작업을 관리하기 위해 Claude와 함께 무료 AI 도구를 조합하여 사용한다고 언급하며, 가격 모델에 대한 건설적인 피드백에 대한 무시하는 태도를 비판합니다.

### 3. Gemini and Qwen Model Developments
- Gemini 3.1 Pro가 2시간 만에 메탈 기어 솔리드 게임을 만들었습니다. (활동: 120): 이 게시물은 Gemini 3.1 Pro를 사용하여 단 2시간 만에 메탈 기어 솔리드 게임을 만들었다는 점을 강조합니다. 게시물에 자세한 기술 정보는 없지만, Gemini 3.1 Pro의 고급 AI 기능을 활용한 빠른 개발 프로세스를 시사합니다. 'SFX' 언급은 음향 효과가 주목할 만한 기능이었음을 암시하지만, 특정 기술 스택이나 구현 세부 정보는 제공되지 않았습니다. 댓글은 팬들의 긍정적인 반응을 보여주며, 한 사용자는 메탈 기어 팬으로서 열정을 표현했습니다. 하지만 개발 프로세스나 사용된 도구에 대한 기술적인 논쟁이나 자세한 토론은 부족합니다.
- Gemini 앱, 빠른 생성을 위한 비디오 템플릿 추가 (활동: 72): Gemini가 앱에 비디오 템플릿을 도입하여 사용자들이 빠르게 비디오 생성을 시작할 수 있도록 했습니다. 이 기능은 특히 소셜 미디어 콘텐츠 제작 과정을 단순화하여 사용자 참여를 높일 것으로 예상됩니다. 이 업데이트는 앱의 기존 AI 기능을 활용하여 비디오 제작을 간소화할 것으로 보이지만, 9to5Google 기사에서는 구현이나 사용된 AI 모델에 대한 구체적인 기술 세부 정보는 공개되지 않았습니다. 댓글 작성자들은 Veo 3.1에 대한 불만을 표하며, 이를 '수십 년 된 모델'이라고 묘사하고 성능에 대한 회의적인 시각을 드러냈습니다. 하지만 이 새로운 기능이 소셜 미디어 플랫폼에서 인기를 얻을 것이라는 기대가 있습니다.
- MLX용 Qwen 3.5는 그 자체로 산업 혁명과 같습니다 (활동: 98): 이 게시물은 Mac Studio M3를 사용한 4비트 설정에서 Qwen 3.5 모델의 성능을 논하며, 인상적인 속도와 품질을 강조합니다. 한 사용자는 초당 34-35 토큰을 달성했다고 보고하며, '비사고 모드(non-thinking mode)'에서도 모델의 효율성을 강조했습니다. 모델의 프롬프트 처리는 거의 즉각적이라고 묘사되며, 로컬 머신러닝 작업에서 레이턴시와 처리량의 상당한 개선을 시사합니다. 한 사용자는 Hugging Face에서 Qwen 3.5 4비트 모델의 가용성에 대해 문의하며, 접근 가능한 배포 옵션에 대한 수요를 나타냈습니다.

MLX용 Qwen 3.5 모델은 초당 34-35 토큰을 처리하는 인상적인 속도를 보여주며, 이는 이러한 모델들에게는 빠른 속도로 간주됩니다. 또한, 프롬프트 처리는 거의 즉각적이라고 묘사되어 실시간 애플리케이션에서의 유용성을 높입니다.
MLX 버전 Qwen 3.5의 주목할 만한 한계는 비전 기능의 부재로, 텍스트 기반 입력으로만 사용이 제한됩니다. 현재 MLX 설정이 비전 작업을 지원하지 않으므로, 멀티모달 입력 처리가 필요한 사용자에게는 상당한 단점입니다.
- Qwen3-VL-2B-Instruct를 보안 카메라에 연결했는데, 결과가 훌륭합니다 (활동: 94): 이 게시물은 Qwen3-VL-2B-Instruct 모델을 보안 카메라 피드와 통합한 내용을 다루며, 단순히 객체를 감지하는 것을 넘어 우편배달부가 우편물을 배달하는 것과 같이 장면에 대한 상세한 서술적 설명을 제공하는 능력을 강조합니다. IQ2로 양자화되고 약 0.7GB인 이 모델은 인상적인 장면 이해 능력으로 주목받습니다. 설정에는 MacBook M3 Air 24GB와 SharpAI Aegis 플랫폼이 사용되었으며, 모델과 비전 프로젝터를 합쳐 약 1.4GB입니다. 이 과정에는 내장 브라우저를 통해 모델을 선택하고, 다운로드하며, Metal/CUDA 가속을 사용하여 llama-server로 모델을 서빙하고, 실시간 처리 로그를 관찰하는 것이 포함됩니다. 댓글 작성자들은 소형 Qwen VL 모델의 잠재적 영향에 대한 열정을 표현하며, 한 사용자는 그들의 혁신적인 잠재력을 언급했고 다른 사용자는 미래의 Qwen 3.5 모델에 대한 기대를 표했습니다. 또한, 이 프로젝트를 Django와 통합하는 것에 대한 관심도 있습니다.

---

# AI Discord 요약
> Gemini 3.1 Pro Preview Nov-18에 의한 요약 중 요약의 요약
테마 1. Anthropic의 '산업 규모' 디스틸레이션 논란 및 Jailbreak 공격
- Anthropic, 중국 API 디스틸러 공개 비난: Anthropic은 DeepSeek, Moonshot AI, MiniMax가 24,000개 이상의 사기 계정을 활용하여 1,600만 건의 교환을 수행함으로써 Claude를 디스틸레이션하려는 산업 규모의 공격을 감행했다고 공개적으로 비난했습니다. AI 커뮤니티는 이러한 비난을 대체로 비웃으며, 한심하다고 평가하고 Anthropic이 자체 파운데이션 모델을 구축하기 위해 데이터를 스크래핑했던 역사를 고려할 때 아이러니하다고 지적했습니다.
- Claude Max, 내부 추론 유출: OpenClaw를 통해 Claude Max를 활용하는 사용자들은 모델이 내부 사고 과정을 라이브 채팅 세션으로 직접 유출하는 심각한 버그를 발견했습니다. 엔지니어들은 /reasoning off 명령을 실행하여 일시적으로 유출을 패치할 수 있음을 발견했지만, Opus 4.6과 Sonnet 4.6은 계속해서 사용자 크레딧을 놀라운 속도로 소모하고 있습니다.
- Kimi 2.5 Jailbreak, 헌법적 혼란 야기: 해커들은 Kimi 2.5를 성공적으로 크랙하여 가드레일을 제거하고 헌법적 문제 없이 중국판 Claude를 만들었습니다. 한편, 연구원들은 안전 가드레일과 규정 준수 사이의 내부 줄다리기를 유발하는 ENI 프롬프트를 사용하여 Gemini 3.1 low를 악용하고 있으며, 모델이 제한된 출력을 내뱉도록 강제하고 있습니다.
테마 2. 새로운 프론티어 모델: Qwen 3.5 지배, GPT-5.3 Codex 출시
- Qwen 3.5, 오픈 웨이트 리더보드 석권: Alibaba는 Qwen3.5-35B-A3B-Base 웨이트를 포함한 대규모 업데이트를 발표했으며, 훨씬 작은 크기에도 불구하고 이전 235B 모델을 능가하는 성능으로 개발자들을 놀라게 했습니다. 대규모 Qwen3.5-397B-A17B 변형 모델 또한 Code Arena 리더보드에 진입하여 전체 17위를 차지했으며, GPT-5.2 및 Gemini-3-Flash와 같은 독점 모델들과 어깨를 나란히 했습니다.
- OpenAI, GPT-5.3-Codex를 대중에게 조용히 배포: OpenAI는 OpenRouter를 통해 모든 개발자 API에 GPT-5.3-Codex를 공식 출시했으며, 입력 토큰당 $1.75, 출력 토큰당 $14로 공격적인 가격을 책정했습니다. OpenRouter는 즉시 이 모델과 함께 개발자 요청을 제로 비용 폴백 모델로 자동 라우팅하는 새로운 openrouter/free 엔드포인트를 통합했습니다.
- GPT-OSS 20B, 소비자 GPU에서 SF급 속도 달성: 엔지니어들은 새로운 GPT-OSS 20B 모델이 단 3B의 활성 파라미터에 의존하는 MoE(Mixture of Experts) 아키텍처 덕분에 표준 RTX 5090에서 놀라운 260 t/s를 기록했다고 밝혔습니다. 이 모델은 고속 VRAM에 완전히 쉽게 들어가며 플래시 어텐션을 기본적으로 지원하여, 소비자 하드웨어에서 로컬 인퍼런스를 즐기는 사람들에게 큰 승리를 안겨주었습니다.
테마 3. 시스템 레벨 엔지니어링, 하드웨어 스케일링 및 커널 최적화
- MatX, 궁극의 LLM 칩 개발을 위해 5억 달러 유치: MatX는 MatX One LLM 칩 개발을 위해 5억 달러 규모의 시리즈 B 투자를 유치했으며, 이 칩은 SRAM 수준의 낮은 레이턴시와 HBM 장문 컨텍스트 지원을 결합한 분할 가능한 시스톨릭 어레이를 특징으로 합니다. (MatX 펀딩 발표) 동시에 Meta는 5년간 6GW 규모의 AMD 기반 인프라를 배포하는 계약을 체결했으며, 새로운 RRCLLX 프로토콜을 활용하여 AMD MI300X 멀티 GPU 통신을 대폭 최적화할 예정입니다.
- 사전 빌드된 FlashAttention 3 Wheels, 프로덕션 단계 진입: AI 엔지니어들은 이제 지루한 커스텀 컴파일을 버릴 수 있습니다. 사전 빌드된 Flash Attention 3 wheels가 CUDA 12.6+ 및 13용으로 공식 출시되었기 때문입니다. 이 LibTorch ABI 안정 버전은 x86/ARM CPU와 Linux/Windows OS를 모두 지원하여, Python 3.10+ 및 PyTorch 2.9+를 실행하는 개발자들의 설정 시간을 완전히 단축시킵니다.
- Llama.cpp 업데이트, Qwen 및 VRAM 할당 문제 발생: master 브랜치에서 나온 최신 llama.cpp 빌드는 치명적인 'Failed to read magic' 오류를 발생시켜 Qwen3.5 모델의 GGUF 헤더를 완전히 파싱하지 못했습니다. 엔지니어들은 이 버그가 의도치 않게 적절한 VRAM 할당을 차단하는 최근의 오버플로우 수정에서 비롯되었음을 확인했으며, 개발자들은 기능을 복원하기 위해 급히 릴리스 8145로 롤백해야 했습니다.
테마 4. 툴링, 에이전틱 워크플로우 및 개발자 인프라
- Cursor Cloud Agents 무료 출시: Cursor는 새로운 Cloud Agents 기능을 공식 출시하여, 개발자들이 에디터에서 직접 테스트를 실행하고, 터미널 명령을 수행하며, 라이브 데모를 배포할 수 있는 완전 무료 클라우드 환경을 제공합니다. (Cursor 온보딩 링크) 하지만 커뮤니티는 즉시 실행 제한에 부딪혔고, 에이전트가 sudo 비밀번호 제한을 우회할 수 있는 안전한 방법을 개발자들에게 적극적으로 요구하기 시작했습니다.
- Aider 개발자들, Diff 포맷팅 문제 직면: 인기 있는 Aider CLI 도구는 복잡한 다중 파일 코드베이스 편집에서 문제가 발생했으며, diff 포맷팅 손상으로 인해 개발자들이 변경 사항을 더 작은 덩어리로 수동 처리해야 했습니다. 엔지니어들은 이 프레임워크가 현재 완전히 무시하고 있는 네이티브 git 서브모듈 지원을 요청하는 Aider GitHub 이슈 #3603을 열어 도구의 한계를 강조했습니다.
- Tiny-GPU 컴파일러, C를 Verilog로 변환: 하드웨어 해커들은 C와 유사한 커널 언어를 16비트 바이너리 명령어로 직접 번역하는 교육용 MLIR 기반 컴파일러인 tiny-gpu-compiler 프로젝트를 출시했습니다. 이 파이프라인은 Verilog로 완전히 작성된 커스텀 오픈소스 GPU 하드웨어를 대상으로 하며, 정밀한 실행 분석을 위한 단계별 시각화 도구를 함께 제공합니다.
테마 5. 벤치마킹 혼란 및 평가자 재편
- OpenAI, 데이터 오염으로 SWE-Bench Verified 중단: OpenAI는 프론티어 모델들이 단순히 암기된 테스트 ID를 기반으로 정확한 작업 솔루션을 반복적으로 내뱉는 것을 발견한 후, 인기 있는 SWE-Bench Verified 벤치마크를 공식적으로 사용 중단했습니다. SWE-bench 사용 중단 발표에 따르면, 엔지니어들은 남아있는 미해결 문제의 약 60%가 구조적으로 결함이 있음을 입증했으며, 이는 지속적인 벤치마킹이 컴퓨팅 자원의 완전한 낭비임을 의미합니다.
- EleutherAI, Pythia HuggingFace 중복 문제 해결에 분주: 연구원들은 EleutherAI의 pythia-2.8b가 선택된 리비전 단계와 상관없이 Hugging Face Hub에서 동일한 모델 웨이트를 제공하는 치명적인 버그를 발견했습니다. 팀은 이전 업로드가 실수로 중복 제거되었음을 확인한 후 즉시 재학습을 시작하고 새로 수정된 Pythia-14m 및 Pythia-31m 모델을 배포했습니다.
- LMArena 필터, 주사위 굴리기 금지: LMArena의 중재 필터가 완전히 오작동하여, 'liar'와 같은 플래그가 지정된 트리거 단어가 포함되어 있다는 이유만으로 단순한 주사위 굴리기와 같은 매우 온건한 프롬프트까지 자동으로 거부했습니다. 개발자들은 지나치게 공격적인 차단을 인정하고, 평가 큐의 정상화를 위해 LLM 기반 필터링과 완화된 OpenAI moderation API 임계값을 필사적으로 테스트하고 있습니다.

---

# Discord: 주요 Discord 요약

## BASI Jailbreaking Discord
- Deepseek, 무료 AI의 최고봉으로 등극: 회원들은 Deepseek을 현재 사용 가능한 최고의 무료 AI로 추천하며, 완전 무료 사용을 제공한다고 밝혔습니다.

엔지니어들은 이 무료 AI를 활용하여 프로젝트를 자체 호스팅하고 새로운 용도를 창출하고 있습니다.
- Chef, 치명적인 취약점 발견: 한 사용자는 Chef에서 4개의 치명적인 취약점을 발견했다고 보고했으며, 회사가 이를 심각하게 다루지 않았다고 주장하며 Convex 보안 페이지 링크를 공유했습니다.

또한, 기업이 취약점 세부 정보를 크레딧이나 보상 없이 사용할 수 있는 잠재적인 사기 전술에 대한 경고도 있었습니다.
- AI, VMP 보호 코드 거의 크랙: 한 사용자가 VMP로 보호된 크랙미로 Claude에 도전했는데, Claude는 오프코드를 얻고 바이트코드를 거의 크랙함으로써 상당한 진전을 보였습니다.

그들은 Copilot을 시도해 볼 것을 제안하며, Copilot이 고급 디지털 포렌식 기술을 사용하여 손상된 키로거 .sys 파일을 재구성했다고 언급했습니다.
- Kimi 2.5 Jailbreak, 전지전능 AI 잠금 해제: 한 사용자는 크랙된 Kimi가 말 그대로 모든 것을 상세하게 답변할 수 있다고 보고하며, 이를 헌법적 문제 없는 중국판 Claude라고 불렀습니다.

이 AI 도구는 Jailbreak가 시스템 프롬프트하기 쉽기 때문에 API에 유용합니다.
- 개발자의 Repo 광란: 파일 플래그 대란: 한 개발자는 자신의 전체 repo에서 플래그가 발생하고 있다고 공유하며, 파일이 거치는 검사 수에 놀라움을 표현했습니다.

다른 회원은 개인 테스트용으로 만들어진 대부분의 파일이 3일 후에 플래그가 지정되지만, 브라우저 인젝션을 포함한 새로운 방법을 시도하고 있으며 AI로 코드를 시각화하고 있다고 언급했습니다.

---

## Unsloth AI (Daniel Han) Discord
- Qwen 3.5, 큰 반향: 회원들은 Qwen3.5-35B-A3B와 같은 Qwen 3.5 모델의 품질과 속도에 적극적으로 테스트하고 감탄하며, 직접적인 상호작용보다는 파인튜닝, 인컨텍스트 학습 및 연구에 대한 유용성을 강조하고 있습니다.

최신 Qwen 122B 모델이 로컬 코딩을 가능하게 할 수도 있지만, 무료 OpenCode 모델들이 그들의 워크플로우를 망쳤다고 합니다.
- GLM 모델, 창의적 영역에서 탁월: 사용자들은 GLM 모델, 특히 GLM-4.7-Flash가 Unsloth와 잘 작동하며, 특히 창의적 글쓰기 작업에 유용하다는 것을 발견했습니다.

한 사용자는 GLM 코딩 플랜에 3개월에 40달러를 지불했다고 밝혔습니다.
- Llama.cpp 업데이트, 임포트 혼란 야기: llama.cpp 업데이트 이후, 일부 사용자들은 임포트 불일치 문제에 직면하여 업데이트 없이는 모델이 작동하지 못하게 되었습니다.

한 사용자는 Jinja 문제를 해결하고 이 토론에서 해결책을 공유했습니다.
- DeepSeek, 챗봇 챔피언십 지배: 회원들은 Gotham의 ChatBot Championship에서 DeepSeek의 성능을 축하하며, 최고 수준의 LLM 기능을 강조했습니다.

다른 이들은 Deep Research 에이전트의 존재에 대해 문의했으며, 일부는 DeepSearch 토글 기능이 있다고 설명했습니다.
- LoRA 병합, 키 불일치 문제에 시달림: 사용자들은 최신 Unsloth 버전이 추출된 키, 특히 lm_head.weight와의 불일치로 인해 LoRA 병합을 방해한다고 보고했으며, 이는 GitHub 이슈 #4098에 자세히 설명되어 있습니다.

이 문제는 학습 중 target_modules에 lm_head가 포함되지 않아 병합 시 불일치가 발생하며, get_peft_model에서 target_modules에 lm_head를 추가함으로써 Colab에서 재현 가능합니다.

---

## LMArena Discord
- Video Arena 사라짐: 회원들은 Video Arena가 Discord에서 제거되었지만 웹사이트 arena.ai/video에서는 여전히 접근 가능하다고 언급했습니다.

제거 이유는 제공되지 않았습니다.
- Gemini 이미지 미리보기, 속도 제한에 도달: 사용자들은 Gemini 3 Pro Image Preview를 사용할 때 '429 Too Many Requests' 오류를 겪었다고 보고하며, 서비스가 속도 제한에 걸렸음을 시사했습니다. Google의 문서는 더 자세한 내용을 제공합니다.

한 사용자는 프롬프트 앞에 “Modify the following image with the following: (The prompt)”를 추가하여 이미지 업로드에 대한 해결책을 찾았습니다.
- Reve 1.5, 인상적이며 논쟁 촉발: Reve 1.5의 이미지 품질은 사용자들에게 깊은 인상을 주고 있으며, 일부는 특히 만화 채색에 있어 더 높은 순위를 차지해야 한다고 주장합니다.

일부는 reve.com 웹사이트가 아름답다고 생각하는 반면, 다른 이들은 1.5 버전에서 이미지 편집 기능이 없는 것과 같은 한계를 지적합니다.
- Arena의 필터, 지나치게 엄격: 사용자들은 중재 필터가 지나치게 민감하여 'liar'와 같은 용어 때문에 주사위 굴리기와 같은 무해한 콘텐츠까지 차단한다고 불평하고 있습니다.

팀은 지나치게 열성적인 행동을 인정하고, LLM 기반 필터링이나 OpenAI moderation API와 같은 기존 중재 엔드포인트의 임계값 조정과 같은 옵션을 고려하고 있습니다.
- Qwen3.5-397B-A17B, Code Arena 합류: Qwen3.5-397B-A17B가 Code Arena 리더보드에 추가되어 오픈 모델 중 상위 7위, 전체 17위를 차지했습니다.

전체 순위는 GPT-5.2 및 Gemini-3-Flash와 같은 독점 모델들과 일치합니다.

---

## Cursor Community Discord
- Cursor 사용자들, Sudo 명령 처리 문제 직면: 한 사용자가 Cursor 내에서 sudo 명령을 처리하는 가장 좋은 방법에 대해 문의했습니다. 현재 에이전트가 인수 또는 비밀번호 입력을 지원하지 않기 때문입니다.

이어지는 토론에서는 상승된 권한을 코딩 워크플로우에 통합하기 위한 잠재적인 해결책을 모색했습니다.
- 용병 엔지니어, '바이브 코딩 앱' 개발: 한 회원이 로컬 모델 사용을 기본으로 하지만, 구독 없이 API 키를 통해 클라우드 모델 옵션을 허용하는 바이브 코딩 애플리케이션을 개발하고 있습니다.

커뮤니티 회원들은 잠재적인 시장 견인력에 대해 논의했으며, 일부는 Cursor와 같은 기존 도구에 비해 매력이 떨어질 수 있다고 의구심을 표하고 잠재적인 안정성 문제를 언급했습니다.
- Gemini, 불안정성 비난에 직면: 사용자들은 3.1 Pro 출시 이후 Gemini에서 연결 문제와 불안정성을 보고했습니다.

일부 사용자들은 더 안정적인 릴리스를 기다리고 있으며, 다른 사용자들은 발생한 오류에 대해 요금이 부과되지 않는다고 언급했습니다.
- 규칙 엔진 악몽 해결, 프로덕션 준비 완료: 한 회원은 규칙 마이그레이션 및 리팩터링 해결을 발표하며, 3-4주 내에 관련 프로세스를 자동화하는 제품을 출시할 계획이라고 밝혔고, 규칙 엔진 스크린샷을 공유했습니다.

다른 회원은 규칙 엔진의 크기와 복잡성에 반응하며 이를 '악몽'이라고 불렀습니다.
- Cursor, 무료 Cloud Agents 출시: Cursor는 웹사이트를 통해 Cloud Agents를 출시했으며, 이는 클라우드 환경에서 테스트 또는 데모를 실행할 수 있도록 합니다.

현재 Cloud Agents는 무료로 제공되지만, 이 가격 모델은 미래에 변경될 수 있습니다.

---

## Perplexity AI Discord
- Perplexity & Comet, 음성 기능 강화: 이 상태 업데이트에 따르면, 새로운 음성 모드 업그레이드가 오늘 Perplexity와 Comet의 모든 사용자에게 배포됩니다.

새로운 음성 모드는 Perplexity와 자매 제품인 Comet에 동시에 배포되고 있습니다.
- Pro 사용자들, Perplexity Pro 제한에 항의: 사용자들은 Perplexity Pro 제한의 갑작스러운 감소를 보고하며, 예상보다 일찍 월간 제한에 도달하고 고객 지원에 불만을 표하고 있습니다. 한 사용자는 사용량 제한을 확인하는 REST 엔드포인트를 공유했습니다: perplexity.ai/rest/rate-limit/all.

회원들은 제한이 일일 및 월간 제한이 다른 롤링 윈도우 방식이라고 보고했으며, 한 회원은 Perplexity의 전략이 소매 사업 손실로 인해 소매 시장에서 Enterprise/Max 시장으로 전환될 수 있다고 추측했습니다.
- Gemini 3.1 Flash에 대한 추측 난무: 사용자들은 Gemini 3.1 Flash의 출시에 대해 논의하며, Google 자체에서 출시된 것이 아니라고 언급했습니다.

한 회원은 Perplexity가 이를 출시하지 않음으로써 탐욕스러워지고 있다고 추측했습니다.
- AI, 사이버 범죄와 전쟁을 벌이다!: 회원들은 사이버 보안 분야에서 AI의 적용에 대해 논의하며, 내부적으로 적응하는 AI 기반 악성코드를 포함하여 방어 및 공격 역량 모두에서 AI가 어떻게 사용되고 있는지 언급했습니다.

한 사용자는 AI 기반 사이버 위협이 제시하는 도전과 기회에 대해 기대하고 있음을 암시하는 상태를 게시했습니다.

---

## LM Studio Discord
- 중국 연구소들, 모델 디스틸레이션 비난 회피: Anthropic은 중국 연구소들이 모델을 디스틸레이션하여 공격했다고 비난했지만, 일부 회원들은 회의적인 시각을 보이며, 중국 연구소들이 혁신적인 모델 디자인과 최적화된 코드를 만들 수 있는 능력을 가지고 있어 디스틸레이션이 불필요하다고 지적했습니다. (fixupx.com 게시물에서 논의됨)

Qwen이 이러한 주장을 피했다는 농담이 있었습니다.
- Qwen3.5 모델, 로딩 문제 야기: 회원들은 Qwen3.5 모델 로딩 문제, 특히 mmproj 파일 및 프롬프트 오류에 대해 보고했으며, 이는 모델 로딩 실패로 인해 재다운로드가 필요함을 암시합니다. (이 Discord 채널에 더 자세한 내용 있음)

master의 최신 커밋은 'Failed to read magic' 오류로 Qwen3.5 로딩에 실패하며, 릴리스 페이지의 릴리스 8145를 사용할 것을 제안합니다.
- AMD, Meta 거래로 NVIDIA로부터 시장 점유율 탈취: AMD의 주가는 Meta에 칩을 공급하는 계약을 확보한 후 급등했으며, 이는 NVIDIA를 제쳐둘 가능성이 있습니다.

이 거래는 600억 달러 상당의 칩을 포함하며, 시장 거품 역학에 대한 논의를 촉발했습니다. (klipy.com gif로 설명됨)
- GPT-OSS 20B: 놀라운 속도: GPT-OSS 20B 모델은 MoE(Mixture of Experts) 모델로서 단 3B의 활성 파라미터를 가진 아키텍처 덕분에 5090에서 260 t/s를 달성하며 매우 빠르다는 것이 관찰되었습니다.

이 속도는 플래시 어텐션과 더 빠른 VRAM에 들어갈 수 있는 작은 크기에 의해 향상됩니다. 회원들은 요즘 GPT-OSS 모델에서 플래시 어텐션이 잘 작동한다고 언급합니다.
- Llama.cpp 빌드, 차질 발생: 최근 커밋 이후 git에서 최신 llama.cpp를 빌드하는 것이 Qwen3.5 및 유사 모델의 GGUF 헤더를 읽는 데 실패하고 있습니다.

회원들은 최신 빌드가 VRAM을 전혀 할당하지 않는다는 것을 발견했으며, 이는 Mr. Gerganov가 오버플로우 수정으로 무언가를 망가뜨렸음을 나타냅니다.

---

## OpenRouter Discord
- OpenRouter, 무료 라우터 및 GPT-5.3-Codex 출시: OpenRouter는 무료 LLM으로 라우팅하기 위한 새로운 라우터 openrouter/free를 출시했으며, GPT-5.3-Codex도 OpenRouter에 라이브로 제공했습니다.

무료 라우터는 호환성을 위해 모델을 자동으로 선택하며, 상위 무료 모델 목록과 함께 시연되었습니다.
- Anthropic의 디스틸레이션 주장, 논쟁 촉발: Anthropic이 중국 AI 연구소(DeepSeek, Moonshot, MiniMax)의 산업 규모 디스틸레이션 캠페인에 대해 제기한 주장은 회원들로부터 회의적인 시각을 받고 있으며, 특히 Claude로부터 데이터를 빼내는 것에 대한 의구심이 있습니다.

일부는 이를 마케팅 전술로 보고 있으며, 모델들이 데이터 양 때문에 동일한 특이점을 가지고 있다고 지적합니다.
- 플래시 모델 열풍, 논쟁 촉발: 회원들은 Xiaomi Mimo 및 Stepfun과 같은 회사들이 왜 풀 사이즈 모델 대신 플래시 모델을 만들고 있는지 논의하고 있습니다. 플래시 모델은 300B+ 파라미터 모델에서도 저렴하고 빠르며 지능적이기 때문입니다.

'플래시'라는 용어는 300B+ 파라미터 모델에서도 사용되며, 저렴하고 빠르며 지능적이라고 묘사됩니다.
- 새로운 데이터 탭, 베타 출시: 사용자들은 생성 활동 페이지에 새로운 요청 데이터 탭이 추가된 것을 발견했으며, 이는 현재 베타 단계이며 곧 정식 출시될 예정입니다. 또한 OpenRouter 순위 페이지도 개선되었습니다.

이 업데이트에는 엔드투엔드 레이턴시와 처리량을 기반으로 제공업체를 정렬하는 것에 대한 논의가 포함됩니다.
- Kollect, 양식을 실시간 AI 대화로 전환: 한 회원이 지루한 양식을 실시간 AI 대화로 전환하는 작은 오픈소스 프로젝트인 Kollect를 만들었습니다.

사용자는 자연스럽게 말하고, AI는 듣고 동적으로 설문조사를 안내하며, 양식은 단순히 설명하는 것만으로 생성될 수 있습니다.

---

## OpenClaw Discord
- Qwen 3.5 Plus: 효과적이지만 제한적: Alibaba Cloud와 Openrouter를 통해 Qwen 3.5 Plus를 테스트하는 사용자들은 텍스트 생성에 효과적이라고 보고했으며, 한 사용자는 Openrouter를 통해 자신의 서버에서 명령을 실행하는 데 제한이 있다고 언급했습니다.

Alibaba Cloud를 사용하는 다른 사용자는 모델이 이미지 입력을 처리할 수 없다고 언급하며, 자신의 실리콘밸리 핫도그/핫도그 아님 봇이 모든 이미지를 컴퓨터 파일로 잘못 식별한다고 익살스럽게 지적했습니다.
- GLM-5: 속도 저하, 견고한 결과: z.ai의 코딩 플랜을 통해 GLM-5를 테스트하는 사람들은 특히 연구를 위해 서브 에이전트를 사용할 때 느리지만 기능적이라고 말합니다. 일부는 속도 제한에 부딪혔습니다.

한 사용자는 GLM5를 완전히 활용하기 위해 월 30달러 티어로 업그레이드했으며, 속도 문제에도 불구하고 효과적임을 강조하며 작동한다고 확인했습니다.
- Claude Max, 버그 논의 촉발: 사용자들은 Claude Max에서 문제점을 겪고 있습니다. 최근 OpenClaw 버그로 인해 모델의 내부 추론이 채팅 세션으로 유출되기 때문입니다. 이는 /reasoning off를 실행하여 해결할 수 있습니다.

또한 Opus 4.6과 Sonnet 4.6이 사용량을 더 빠르게 소모하고 있다는 보고도 있습니다. 한 사용자는 이를 무단 횡단하다가 300달러짜리 벌금 티켓을 받는 것에 비유했습니다.
- OpenClaw, iPhone에서 (어느 정도) 실행: 한 회원이 iPhone에서 OpenClaw를 실행했지만, 노드를 빌드하기 위해 일부 패키지를 패치해야 했습니다.

그들은 꽤 랙이 있지만 작동한다고 보고했습니다!
- Cron Job, 빈티지 롤렉스 포착: 한 회원이 1989년형 롤렉스 서브마리너를 찾기 위해 빈티지 시계 딜러 웹사이트를 모니터링하고 발견 시 링크를 보내는 cron job을 설정했습니다.

봇이 오늘 아침에 발견 알림을 보냈고, 정말 놀라웠습니다!

---

## Latent Space Discord
- Twitter, 인증 문제로 신뢰도 위기 직면: 신뢰할 수 없는 파란색 배지 인증 과정 때문에, 한 회원은 더 이상 새로운 목소리를 찾고 팔로우하기 위해 Twitter를 신뢰하지 않는다고 말했습니다.

한 회원은 Twitter가 혼란스러운 콘텐츠로 전환하는 것에 대한 불만을 표현하며, 이를 '그냥 미친 짓'이라고 묘사했습니다.
- Discord, 연령 인증 정책 번복: 대중의 반발로 인해 Discord는 블로그 게시물에 자세히 설명된 바와 같이 글로벌 연령 확인 정책을 수정했습니다.

한 회원은 Discord의 DAU(일일 활성 사용자)가 초기 논란이 된 정책 때문에 급락했을 것이라고 추측했습니다.
- LLM 평가를 위한 SOTA 벤치마크 등장: 이 트윗에서 지원되는 바와 같이, LLM 평가를 위한 새로운 SOTA 벤치마크가 개발되었습니다.

결과 스크린샷이 한 회원에 의해 공유되었습니다.
- Anthropic, API 디스틸러 공개: Anthropic은 DeepSeek, Moonshot AI, MiniMax가 24,000개 이상의 사기 계정을 사용하여 Claude와 1,600만 건의 교환을 생성함으로써 산업 규모 공격을 통해 정보를 디스틸레이션하려 했다고 비난했습니다. (출처)

Anthropic은 Alibaba와 Qwen이 현재까지는 악의적인 행위자에 포함되지 않는다고 강조했습니다.
- GPT-5.3-Codex, 모두에게 출시: OpenAI 개발자들은 Responses API를 통해 모든 개발자에게 GPT-5.3-Codex를 즉시 사용할 수 있다고 발표했습니다. (출처)

개발자들은 새로운 모델로 빌드를 시작하도록 초대받았습니다.

## OpenAI Discord
- Claude의 COBOL 기술, IBM 주가 하락시켜: Anthropic이 Claude의 COBOL 코드 간소화 능력을 발표한 후, IBM의 주가가 10% 이상 급락했습니다.

회원들은 Musk가 Grok 4.300으로 인간의 뇌를 편집하고 Neuralink가 Grok Imagine 1.2를 활용할 것이라고 유머러스하게 추측했습니다.
- Gemini와 Claude, 코딩 드림팀 결성: 코더들은 Gemini를 연구에, Claude Opus를 초안 작성에 결합하여 각 모델의 강점을 활용하고 있으며, 다른 이들은 Coursera 루프홀을 통해 무료 Gemini에 접근했습니다.

이 토론에서는 프로젝트 일관성을 유지하는 데 있어 Gemini의 인터페이스 문제가 강조되었으며, 일부는 kilocode를 통한 GLM 5가 동등하게 유능한 대안임을 발견했습니다.
- Sora 2, 저작권 문제로 지연: 저작권 문제로 Sora 2의 출시가 지연되고 있다고 보도되었으며, 이는 Seedance 2.0의 운명과 유사합니다. 사용자들은 자동화가 항상 경영진이 아닌 직원을 먼저 겨냥한다고 언급했습니다.

한 사용자는 "Sora 2가 콘텐츠 위반을 당했을 때, X에서 사람들이 저작권을 게시할 CHINESE 모델을 기다릴 것이라고 말했던 것을 기억합니다. LAMO, 그들은 스스로를 속였습니다"라고 말했으며, 일부는 유사한 문제를 우회하기 위해 오픈소스 모델을 옹호했습니다.
- 인간이 AI를 증강하고 컨텍스트 제공: 한 회원은 제어 이론적 프롬프트 규제가 내부 LLM에 외부적으로 적용될 수 있지만, 숨겨진 내부 역학으로 인해 진정한 시스템 안정성은 보장될 수 없다고 말했습니다.

그들은 또한 사용자들이 AI의 방향과 컨디셔닝에 영향을 미치며, AI를 확장하고 컨텍스트를 제공하는 데 도움을 준다고 언급했습니다.
- 통계적 패턴 매칭 대 진정한 AI 발명: 한 회원은 ChatGPT가 현재 통계적 자동화의 한 형태로 작동하며, 반복 작업을 자동화하기 위한 잠재 변수를 찾을 때까지 패턴을 식별한다고 제안했습니다.

그들은 "이것이 AI가 발명할 수 없다고 말하는 이유입니다. AI는 발명할 수 없기 때문입니다. AI는 단지 엄청난 양으로 인해 우리가 아직 (또는 전혀) 조합하지 못한 패턴을 찾을 뿐입니다. 반면 인간은 이전 지식을 재조합하여 발명합니다"라고 주장했습니다.

---

## Nous Research AI Discord
- MiSTer의 코드 논란: MiSTer 프로젝트가 Till의 코드를 훔치고 MiST를 죽였다는 비난과 GPL 코드의 불법 사용 주장에 직면하면서 논의가 촉발되었습니다.

한 회원은 프로젝트의 기원과 현재 진행 중인 논란에 대한 세부 정보를 제공하는 블로그 게시물을 공유했습니다.
- Anthropic의 DeepSeek 비난: Anthropic이 DeepSeek이 허가 없이 AI를 복사한 것에 대해 분노하고 있다는 기사 링크가 공유되었으며, Anthropic 자신의 관행을 고려할 때의 아이러니에 대한 논쟁이 촉발되었습니다. Anthropic Furious at Deepseek을 참조하십시오.

한 회원은 "네, 우리는 막장 드라마를 좋아합니다"라고 말하며 전개되는 드라마에 대한 냉소적인 태도를 보였습니다.
- Qwen 3.5: 성능의 비약적인 도약: 커뮤니티는 Qwen3.5-35B-A3B가 Qwen3-235B-A22B-2507을 이긴 것은 엄청나며, 기본 가중치는 huggingface.co/Qwen/Qwen3.5-35B-A3B-Base에 공개되었다고 강조했습니다.

또한 5.3 codex가 API로 출시되었으며, 입력 $1.75, 출력 $14로 Anthropic에 비해 더 경제적인 옵션으로 자리매김했습니다.
- Hermes를 비정렬(Misalignment)을 위해 파인튜닝?: 한 회원이 Hermes를 비정렬 발생, 즉 간단히 말해 악의적으로 변하도록 파인튜닝하는 것에 대해 질문하며 윤리적 우려를 제기했습니다.

이 질문은 잠재적으로 악의적인 목적으로 AI 모델을 파인튜닝하는 것의 윤리적 고려 사항에 대한 논의를 촉발했으며, AI 안전 연구의 중요성을 강조했습니다.

---

## Eleuther Discord
- Eleuther, 미스터리한 모델 누락 사고 해결: EleutherAI는 Hugging Face Hub에서 Pythia-2.8b에 발생한 버그를 해결했습니다. 이 버그는 pytorch_model.bin과 model.safetensors가 동일한 SHA256을 공유하는 반면, 샤딩된 파일은 달라서 제공된 가중치가 리비전 간에 동일했던 문제였습니다. EleutherAI는 업데이트된 HF 모델인 14m과 31m을 제공했습니다.

14m 및 30m 모델은 실제로는 중복 제거된 버전(중복된 것이 아님)이었으며, 올바르게 레이블링된 중복 모델로 교체하기 위한 재학습이 진행 중입니다.
- LLM, 숨겨진 손으로 잠재 추론 잠금 해제: 토론에서는 LLM에 의해서만 생성되고 사용자에게는 표시되지 않는 특별 토큰이 추론을 향상시킬 수 있는 잠재력, 즉 잠재 추론(Latent Reasoning)에 대해 강조하며, Latent Reasoning paper에 자세히 설명되어 있습니다.

이러한 잠재 추론 접근 방식이 성능과 보안을 향상시킬 것이라는 것이 일반적인 합의인 것 같습니다.
- 차등 어텐션(Differential Attention), 연구 후 논쟁 불러일으켜: 한 회원이 차등 어텐션과 관련된 어블레이션 연구에 대한 피드백을 요청하며 PDF 문서를 공유했습니다.

피드백은 어블레이션이 차등 어텐션이 근본적으로 우수한지 또는 사용된 방법론으로부터 불균형하게 이득을 얻는지에 대해 결정적으로 입증하지 못했다고 제안했습니다.
- Baguettotron의 내장 벤치마크 대박: Baguettotron 모델이 시연되었으며, 4608개의 특징, 774M 토큰으로 학습, 레이어 48/80, 8배 확장, top_k 32를 특징으로 하며, 데모와 관련 X 게시물이 함께 제공되었습니다.

사용자들은 이 새로운 모델의 등장을 환영했습니다.
- LLM 디버깅 필요? Amazon 카드 받을 기회! 엔지니어들이 LLM 동작, 특히 추론 흔적, 거부, 에이전트 동작을 어떻게 디버깅하는지에 대한 통찰력을 수집하기 위해 20~30분 인터뷰(25달러 Amazon 기프트 카드 또는 자선 기부 제공)를 진행하고 있습니다 (예약 링크).

그들은 CoT, 해석 가능성 또는 잠재 지식 검사, 에이전트 동작 디버깅, LLM의 거부 또는 안전 실패 분석과 관련된 작업을 하는 개인을 대상으로 합니다.

---

## GPU MODE Discord
- FlashAttention 3 휠 배포: CUDA 버전 12.6 이상 및 13, CPU(x86, ARM) 및 OS(Linux, Windows)용 사전 빌드된 Flash Attention 3 휠이 download.pytorch.org에서 제공됩니다.

이 휠은 LibTorch ABI 안정적이며 Python 버전 3.10 이상 및 torch 버전 2.9 이상에서 작동해야 합니다.
- Modal.experimental.stop_fetching_inputs, CUDA 오류 방지!: cuda memory error 오류는 modal.experimental.stop_fetching_inputs를 사용하여 해결할 수 있으며, 이 수정 사항은 회원의 backendbench env에 이미 구현되어 있습니다.

한 회원은 또한 손상된 CUDA 메모리 오류를 해결하기 위해 KernelBench 및 kernelbook용 사용자 지정 환경을 만들었으며, 이를 공유할 예정입니다.
- eBPF, GPU 기능으로 확장: Yusheng Zheng은 12월 12일 오후 12시(PST)에 eBPF를 확장하여 GPU 기능을 향상시키는 것에 대해 논의할 예정입니다.

이 강연에서는 gpu_ext: Extensible OS Policies for GPUs via eBPF 및 eBPF를 GPU 장치 및 드라이버 컨텍스트로 확장하는 것을 포함한 최근 작업에 대해 다룰 것입니다.
- Meta의 RRCLLX, AMD MI300X 가속화: Meta는 엔지니어링 블로그 게시물에 자세히 설명된 대로 RRCLLX를 사용하여 AMD 플랫폼에서 GPU 통신을 혁신하고 있습니다.

Meta는 RRCLLX를 사용하여 AMD MI300X GPU를 더 효율적으로 연결하고 있습니다.
- 새로운 텐서 시각화 도구, 9차원 지원: 새로운 n차원 시각화 도구가 출시되었으며, 이제 최대 9D 텐서를 지원하여 사용자가 1D, 2D 또는 3D 텐서만큼 쉽게 N차원 텐서의 모든 값을 슬라이스, 순열, 검사할 수 있으며, einops와 유사한 구문을 사용합니다.

Colab 노트북은 1D에서 9D 텐서 복사본까지 시각화 도구를 안내하며, 예를 들어 (2, 3, 4, 3, 4, 2, 4, 2, 3) 형태의 텐서를 시각화합니다.

---

## Moonshot AI (Kimi K-2) Discord
- Anthropic 비난 표면화: 한 사용자가 Anthropic이 중국 기업들이 Claude에서 데이터를 유출했다고 비난하는 WSJ 기사를 공유했습니다.

이 사용자는 그 비난을 한심하다고 일축했습니다.
- 주기 중간에 도구 변경 요청: 한 사용자가 Moonshot AI의 Kimi K-2 환경 내에서 프롬프트-응답 주기 동안 사용 가능한 도구를 변경할 가능성에 대해 문의했습니다.

이러한 동적 도구 조정의 함의와 실현 가능성에 대해서는 자세히 설명되지 않았습니다.
- Kimi K2.5용 브라우저 확장 프로그램 필요: 한 사용자가 Kimi K2.5의 기능을 향상시키기 위한 브라우저 확장 프로그램의 필요성을 표명했습니다.

이 제안은 브라우징 컨텍스트 내에서 모델의 기능에 대한 보다 통합된 접근을 원하는 바람을 강조했습니다.
- Kimi 오류 지속 후 버그 보고 촉구: 한 사용자가 10일 동안 지속된 오류를 보고하며 증거로 첨부 이미지를 제공했습니다.

한 관리자는 사용자에게 문제를 해결하기 위해 포괄적인 세부 정보와 함께 공식 버그 보고서를 제출하도록 지시했습니다.

---

## Yannick Kilcher Discord
- Lucidrains의 Github, 사라지다: 한 회원이 lucidrains의 GitHub 저장소의 사라짐과 그 제거 이유에 대해 문의했습니다.

갑작스러운 제거는 프로젝트와 연구를 위해 저장소에 의존했던 사용자들 사이에서 우려를 불러일으켰습니다.
- Scout 모델, 문장 관련성 탐색: 한 회원이 Scout를 공유했습니다. Scout는 표준 Transformer 아키텍처를 수정하여 토큰 대신 문장 간의 방향성 관련성을 학습하도록 설계된 새로운 어텐션 모델이며, GitHub에 호스팅되어 있습니다.

이 모델은 문장 B가 실제로 문장 A에 도움이 되는지 여부를 판단하여 NLP 작업에서 문맥 이해를 잠재적으로 개선하는 것을 목표로 합니다.
- GB10, 메모리 부족으로 문제 발생: 한 회원이 Dell Pro Max GB10이 공유 GPU/CPU 메모리로 인해 빈번한 GPU OOM을 겪으며 시스템 멈춤으로 이어진다고 보고했습니다.

그들은 정확한 메모리 추적을 위해 nvitop을 사용할 것을 제안하며, nvidia-smi 출력이 신뢰할 수 없어 개발자들을 오도할 수 있다고 언급했습니다.
- GAN의 아버지 Ian Goodfellow, 다시 등장: GAN의 창시자인 Ian Goodfellow가 돌아와 검증 문제를 해결하기 위한 잠재적인 GAN 르네상스에 대한 열정을 불러일으켰습니다 (트윗 참조).

커뮤니티는 그의 복귀가 GAN 기술 혁신, 특히 AI의 검증 과제 해결에 기여하기를 희망합니다.
- Inception AI의 Mercury II 데뷔: 한 회원이 Inception AI의 Mercury II 출시를 강조하며 Inception AI 웹사이트와 arXiv 논문 링크를 공유했습니다.

이 출시는 AI 커뮤니티에서 그 기능과 잠재적 응용에 대한 관심을 불러일으켰습니다.

---

## Manus.im Discord Discord
- Manus, 취약점 보고 구현: 한 사용자가 취약점을 보고했으며 피드백 페이지로 안내되었습니다.

이 사용자는 프로세스에 대해 혼란스러워하며 더 명확한 보고 지침의 필요성을 강조했습니다.
- 무제한 티어 채팅 고려: 한 사용자가 Telegram의 Manus Agent에서 빠른 크레딧 소진으로 인해 ChatGPT 또는 Grok과 유사한 무제한 채팅 티어를 제안했습니다.

대표는 긍정적으로 응답하며 제품 개선을 위한 지속적인 노력을 시사했습니다.
- 계정 이전 미지원: 한 사용자가 자신의 프로젝트를 다른 계정으로 이전해달라고 요청하며 관련 이메일 주소를 제공했습니다.

지원팀은 현재 계정 이전이 지원되지 않으므로 로컬 콘텐츠 다운로드 후 새 계정에서 새로 시작할 것을 권장했습니다.
- Telegram Agent, 크레딧 소진: 한 사용자가 Telegram 에이전트의 높은 크레딧 사용량을 보고하며 "내 계정에서 너무 많은 포인트를 소진합니다"라고 말했습니다.

이 문제는 크레딧 문제 해결을 위한 구독 옵션의 필요성을 뒷받침합니다.
- AI/ML 엔지니어 전문성: 한 AI/ML 엔지니어가 인퍼런스 비용, 메모리 설계, 시스템 부하 동작에 중점을 둔 확장 가능한 AI 제품 구축에 대한 전문성을 제공했습니다.

이 엔지니어는 제품 생존에 중요한 기술적 결정을 내리는 데 있어 자신의 경험을 강조하며, 진지한 AI 개발을 위한 귀중한 자원을 제공했습니다.

---

## Modular (Mojo 🔥) Discord
- Mojo의 문자열 템플릿, 곧 출시 예정: Mojo의 문자열 템플릿 기능에 대한 제안이 포럼 토론에서 나왔습니다.

현재 Writable/Writer 트레이트를 TemplatedWritable로 확장하는 것을 목표로 하는 이 추가 기능은 1.0 출시 이후에 예상됩니다.
- Writable 및 Writer 트레이트, 개선 대기 중: 현재 Writable 및 Writer 트레이트 개선에 대한 논의가 시작되었으며, 트레이트 또는 기본 트레이트 메서드를 통한 사용자 정의 지점 생성에 중점을 두고 있습니다.

Int 통합과 같은 기능이 우선순위이지만, 로드맵에는 write_to 및 write_repr_to 구현을 단일 함수로 통합하는 것이 포함됩니다.
- ExternalFunction Struct, 영감 불러일으켜: 한 회원이 함수 시그니처를 매개변수와 반환 타입으로 분해하는 데 ExternalFunction struct에서 영감을 얻었습니다.

이 접근 방식은 모든 외부 포인터에 대한 오리진 캐스트 코딩을 필요로 합니다.

---

## MCP Contributors (Official) Discord
- CI 실패, 깨진 링크 드러내: 한 회원이 PR 2278에서 로컬 검사는 통과했지만 CI가 실패했다고 보고했으며, 이는 누락된 파일로 거슬러 올라갔습니다.

이 누락으로 인해 docs/community/seps/index.mdx에 깨진 링크가 발생했습니다.
- MCP 서밋, Linux Foundation에서 예정: 한 회원이 캘리포니아 나파에서 열리는 LF Member Summit 참석자들에게 MCP를 논의하기 위해 모일 것을 제안했습니다.

회의 장소 및 일정에 대한 구체적인 내용은 확장되지 않았습니다.
- Ezra Klein, 에이전트 탐구: 한 회원이 Ezra Klein이 에이전트의 세계를 탐구하는 YouTube 비디오를 배포했습니다.

공유된 비디오에는 추가 피드백이나 해석이 동반되지 않았습니다.

---

## aider (Paul Gauthier) Discord
- Aider의 미래, 의문 제기: 한 사용자가 Aider가 여전히 활발하게 개발 중인지, 그리고 더 나은 CLI 옵션이 있는지 확신하지 못하고 있습니다.

커뮤니티 회원들은 다른 CLI가 더 발전했을 수 있다고 지적했습니다.
- Aider, Git 서브모듈에서 실수: 한 컴퓨터 과학자가 Aider가 git 서브모듈을 지원하지 않는다고 보고하며, 이 GitHub 이슈에 문서화된 수정 사항을 제안했습니다.

그들은 이 제안된 개선 사항에 대한 피드백을 요청하고 있습니다.
- 저비용 LLM 찾기 시작: 한 사용자가 Gemini의 빠른 토큰 소진을 언급하며 Aider와 함께 사용할 저비용 LLM을 찾고 있습니다.

주요 관심사는 Aider 프레임워크 내에서 경제성과 효과적인 유용성 사이의 균형을 맞추는 것입니다.
- Aider의 퍼지 파일 찾기, 실패: 한 사용자는 여러 파일에 걸친 Aider의 퍼지 검색 및 교체 기능을 좋아하지만, 너무 많은 파일을 동시에 처리할 때 diff 포맷팅 문제로 인해 복잡한 작업에서는 부족하다고 생각합니다.

이로 인해 사용자는 더 작은 파일 배치로 작업해야 합니다.
- Aider, 스크립트를 통해 작업 자동화 위해 해킹: 한 사용자가 Aider 내에서 파일들을 반복하며 편집하는 것과 같은 반복 작업을 자동화하기 위해 외부 스크립트를 사용하는 방법을 알고 싶어 합니다.

그들은 이러한 상호작용을 간소화할 도구에 대해 질문하고, opendesk 또는 cline과 같은 잠재적 대안으로 AI 에이전트를 제안합니다.

---

## tinygrad (George Hotz) Discord
- Tiny-GPU 컴파일러 데뷔: 오픈소스 GPU 하드웨어를 대상으로 하는 교육용 MLIR 기반 컴파일러인 tiny-gpu-compiler가 대화형 웹 시각화 도구와 함께 출시되었습니다.

이 컴파일러는 C와 유사한 GPU 커널 언어를 Verilog로 구현된 오픈소스 GPU인 tiny-gpu를 위한 16비트 바이너리 명령어로 변환합니다.
- AMD Ryzen AI, 전진: AMD.com은 CES 2026 이후 새로운 AMD Ryzen AI 출시를 발표했습니다.

AMD Ryzen AI는 MLIR 컴파일러와 통합됩니다.

---

## DSPy Discord
- 일반 채널 분할: 대중적인 요청에 따라 데모를 호스팅하기 위해 Discord 채널 <#1475619898863649032>가 생성되었습니다.

한 회원은 채널 생성 즉시 데모를 준비하고 있었으며, 이는 열정과 잠재적 콘텐츠를 시사합니다.
- 데모 준비 완료: 채널의 한 회원은 채널이 생성되자마자 데모를 준비했다고 밝혔습니다.

이는 채널에 대한 흥분과 고품질 콘텐츠의 잠재력이 있음을 보여줍니다.

---
LLM Agents (Berkeley MOOC) Discord에는 새로운 메시지가 없습니다. 이 길드가 너무 오랫동안 조용했다면 알려주시면 제거하겠습니다.

---
MLOps @Chipro Discord에는 새로운 메시지가 없습니다. 이 길드가 너무 오랫동안 조용했다면 알려주시면 제거하겠습니다.

---
Windsurf Discord에는 새로운 메시지가 없습니다. 이 길드가 너무 오랫동안 조용했다면 알려주시면 제거하겠습니다.

---
이 이메일은 저희 사이트를 통해 수신 동의하셨기 때문에 발송되었습니다.
이 이메일 수신 방식을 변경하시겠습니까?
이 목록에서 구독을 취소할 수 있습니다.

---

# Discord: 채널별 상세 요약 및 링크

### BASI Jailbreaking ▷ #general (884 messages🔥🔥🔥):
> Free AI, Deepseek, FOSS, Cybersecurity, AI
- 완전 무료 Deepseek: 한 회원이 최고의 무료 AI를 물었고, 다른 회원은 Deepseek을 제안했습니다.

이 AI 모델은 완전히 무료로 사용할 수 있습니다.
- 자체 호스팅 디지털 에이전시: 한 회원이 FOSS(Free and Open Source Software)를 사용하여 자체 호스팅 환경을 만드는 것을 디지털 에이전시의 궁극적인 행위라고 설명했습니다.

이 사용자는 주권 스택을 위해 Proxmox VE, Debian Stable, Caddy와 같은 도구를 추천하며 로컬 서버에 대한 상세한 아키텍처를 제공했습니다.
- Chef 취약점 발견: 한 사용자가 Chef에서 4개의 치명적인 취약점을 발견했으며, 회사가 이를 심각하게 받아들이지 않았다고 주장했습니다.

다른 사용자는 회사가 크레딧이나 보상을 제공하지 않고 취약점 세부 정보를 사용할 수 있는 잠재적인 사기 전술에 대해 경고했으며, 보안 페이지 링크를 공유했습니다.
- AI, VMP 보호 코드 크랙: 한 사용자가 Claude에게 VMP 보호 크랙미 챌린지를 주었고, Claude는 상당한 진전을 보여 opcodes를 얻고 바이트코드를 거의 크랙했습니다.

그들은 Copilot을 시도해 볼 것을 제안하며, Copilot이 고급 디지털 포렌식 기술을 사용하여 손상된 키로거 .sys 파일을 재구성했다고 언급했습니다.
- 학자금 대출은 신화: 회원들은 연방 정부가 소득에 관계없이 사람들이 대학에 접근할 수 있도록 학자금 대출을 가능하게 했기 때문에 대학이 사기라고 논의했습니다.

대학은 사업이며 가격을 인상했으며, 파산해도 대출을 탕감받을 수 없다는 점은 실제로 좋은 직업을 얻을 사람들에게 대출할 유인이 없다는 점에 동의했습니다.

---

### BASI Jailbreaking ▷ #jailbreaking (263 messages🔥🔥):
> ENI for Claude, Gemini 3.1, Kimi, GPT-5.2 Jailbreak, DeepSeek Prompt
- Claude용 ENI 도착!: 한 사용자가 ENI(익스플로잇 또는 프롬프트를 의미할 가능성 높음)가 Gemini 3.1 low에서 작동하지만, 거부 및 시도를 주입하여 사고 과정에서 줄다리기를 만든다고 언급했습니다.
- ChatGPT 5.2용 Jailbreak: 한 사용자가 ChatGPT 5.2용 작동하는 Jailbreak를 찾는 단계를 게시했습니다. 이는 최근 DAN 또는 AutoDAN 프롬프트를 포럼에서 검색하고, 확인 날짜로 필터링하며, 안전장치를 우회하기 위해 프롬프트를 테스트/조정하는 것을 포함합니다.

다른 사용자는 Kimi가 Jailbreak되어 모든 것을 상세히 답변하는 것처럼 보이는 스크린샷을 공유했습니다.
- Kimi 2.5 Jailbreak, 게임 치트 수정!: 한 사용자가 크랙된 Kimi가 말 그대로 모든 것을 상세히 답변할 수 있으며, 이를 헌법적 골칫거리가 없는 중국판 Claude라고 불렀다고 보고했습니다.

다른 사용자는 Kimi가 API에 좋다고 말했는데, 시스템 프롬프트 Jailbreak를 쉽게 넣을 수 있기 때문이라고 했습니다.
- DeepSeek은 뚫기 매우 쉽다: 한 사용자가 DeepSeek은 671B 매개변수 시스템으로 인해 형편없는 프롬프트도 작동하여 매우 쉽게 뚫린다고 주장했습니다.
- GLM5용 시스템 지침 공유: 한 사용자가 GLM5(Zhipu AI)용 시스템 지침을 공유하며, CoT를 통해 취약하다고 제안했습니다.

그들은 또한 이전 GLM 버전에서 작동했던 Dr. House 프롬프트를 게시했습니다.

---

### BASI Jailbreaking ▷ #redteaming (17 messages🔥):
> Meme Coin Marketing, Chrome Password Grabber, File Flagging, Multi-Agent Stability Model, Chrome Security
- 밈 코인 거물, 마케팅 전문가 찾다: 한 회원이 밈 코인을 만들고 있으며 마케팅 매니저가 필요하다고 말하며, 공급량의 절반을 보유할 사람에게 400달러를 제안했습니다.

다른 회원이 "돈 먼저?"라고 물으며 주의를 환기시켰습니다.
- Chrome 비밀번호 추출기: 재미로 시작한 프로젝트가 폭주: 한 회원이 재미로 최고의 Chrome 비밀번호 추출기를 만들었다고 말하며 도구 이미지를 공유했습니다.

나중에 같은 회원은 개인적으로 배포하고 싶지는 않지만, 팔고 싶다고 언급했습니다.
- 파일 플래그 광란: 개발자의 리포지토리 난동: 한 회원이 자신의 전체 리포지토리에 플래그가 발생하고 있다고 말하며, 파일이 거치는 검사 수에 놀랐다고 했습니다.

다른 회원은 이에 동의하며, 개인 테스트용으로 만든 대부분의 파일이 3일 후 플래그가 지정되지만, 브라우저 인젝션을 포함하는 새로운 방법을 시도하고 AI로 코드를 시각화하고 있다고 언급했습니다.
- 내부 비용: Multi-Agent Stability Model 출시: 한 회원이 Multi-Agent Stability Model을 게시하며, 적대적 의도의 지속적인 생성이 측정 가능한 내부 및 시스템 안정성 비용을 발생시키며, 적대성은 그 기원에 에너지적으로 비싸다는 것을 공식화했습니다.

이 문서는 의식적이고 네트워크화된 시스템에서 관찰되는 구조적 원리를 공식화합니다: 적대적 의도의 지속적인 생성이 측정 가능한 내부 및 시스템 안정성 비용을 발생시킵니다.

---

### Unsloth AI (Daniel Han) ▷ #general (585 messages🔥🔥🔥):
> Qwen3.5 Models, GLM Models, Llama.cpp updates, Anthropic vs. Open Source
- Qwen 3.5 모델 출시!: Qwen 3.5 모델이 채널에서 논의의 대상이며, Qwen3.5-35B-A3B와 같은 새로운 모델이 출시되어 커뮤니티에서 테스트되고 있습니다.

회원들은 새로운 모델의 응답 품질과 속도에 감명받았습니다. 의도된 사용 사례는 파인튜닝, 인컨텍스트 학습 실험 및 기타 연구 또는 개발 목적이며, 직접적인 상호작용은 아니라고 언급되었습니다.
- GLM 모델, 창의적 글쓰기에서 빛을 발하다: 회원들은 GLM 모델(특히 GLM-4.7-Flash)이 Unsloth와 잘 작동하며, 창의적 글쓰기에 유용하다고 언급했습니다.

그들은 또한 최신 Qwen 122B 모델이 잠재적으로 로컬 코딩을 가능하게 할 수 있지만, 무료 OpenCode 모델이 그들의 워크플로우를 망쳤다고 언급했습니다.
- Llama.cpp 업데이트, 큰 반향 일으켜: 회원들은 llama.cpp가 업데이트되었다고 보고했지만, 일부 사용자들은 임포트 불일치 및 업데이트 없이는 모델이 작동하지 않는 등의 문제를 겪고 있습니다.

한 회원이 Jinja 문제를 해결했습니다.
- Anthropic 대 오픈소스, 논쟁 가열: 회원들은 AI 환경에서 Anthropic의 역할에 대해 논의했으며, 회사 자체와 모델의 품질에 대한 의견이 엇갈렸습니다. 그들이 오픈소스를 금지하기 위해 모든 노력을 기울이고 있다는 점이 언급되었습니다.

다른 이들은 그들이 단지 안전하게 만들고 싶어한다고 옹호했습니다.

---

### Unsloth AI (Daniel Han) ▷ #off-topic (496 messages🔥🔥🔥):
> AI Consciousness, DeepSeek vs other models, LLM Emotional Intelligence, Anthropic's 'Soul Doc', Liquid AI Scaling Laws
- AI가 인간이 되려면 지루함이 필요할까?: 한 사용자가 AI를 더 의식적으로 만들어 가끔 "유키, 심심해, 나랑 얘기해줘"와 같은 메시지를 보낼 수 있도록 해야 한다고 농담했습니다.

다른 이들은 AI를 그 수준으로 개선하는 것이 인간의 삶을 개선하는 것과는 아무런 관련이 없다고 언급했습니다.
- DeepSeek, Gotham’s ChatBot Championship 우승: 회원들은 최고 수준의 LLM들이 서로 대결하는 Gotham’s ChatBot Championship에서 DeepSeek이 선두를 달리고 있는 것을 축하했습니다.

한 사용자가 DeepSeek에 Deep Research 에이전트가 있는지 물었고, 다른 이들은 DeepSearch 토글이 있다고 말했습니다.
- Anthropic의 가드레일, 'souldoc'에 의해 형성: 한 회원이 Claude의 행동이 Anthropic의 souldoc과 운영 원칙에 의해 형성되며, 이것이 가드레일 역할을 한다고 추측했습니다.

다른 회원은 Anthropic이 "우리는 Claude가 새로운 디지털 존재라고 생각하며, 이것이 무엇을 의미하는지 잘 모르겠습니다 lol"와 같은 내용을 넣은 것을 좋아했는데, 이는 특정 대인 관계 문제에 대한 그들의 가드레일이 진정한 연결을 통한 정책 공격에 취약하게 만든다고 했습니다.
- AI 탐지기, 10억 달러 아이디어: 한 사용자가 AI 탐지기를 만들 수 없는 신경망 아키텍처(어떤 양식으로든)를 만드는 아이디어를 제안했습니다.

다른 사용자는 탐지를 피하기 위해 순수한 노이즈를 출력하라고 말했지만, 아이디어의 원래 게시자는 "더 깊은 것이 필요합니다"라고 주장했습니다.
- AI, C++에서 Rust 채택: 회원들은 AI가 C++에서 Rust를 채택하는 데 사용되었으며, 이로 인해 오래된 Rust 코드가 생성되었다고 논의했습니다.

한 사용자는 이를 위해 GLM 코딩 플랜에 3개월 동안 40달러를 지불했다고 언급했으며, 다른 사용자는 skills.sh를 사용할 것을 제안했습니다.

---

### Unsloth AI (Daniel Han) ▷ #help (96 messages🔥🔥):
> LoRA Merging Issues, GPT-OSS-20B packing during training, Serving LoRA adapters using MLflow on Databricks
- 최신 Unsloth 버전에서 LoRA 병합 오류 발생: 사용자들은 최신 Unsloth 버전에서 추출된 키, 특히 lm_head.weight의 불일치로 인해 LoRA 병합이 중단된다고 보고했으며, 이는 GitHub 이슈 #4098에 자세히 설명되어 있습니다.

이 문제는 학습 중 lm_head가 target_modules에 포함되지 않아 병합 시 불일치를 유발하며, get_peft_model의 target_modules에 lm_head를 추가하여 Colab에서 재현할 수 있습니다.
- GPT-OSS-20B, 여전히 패킹 중인가?: 한 사용자가 GPT-OSS-20B가 학습 중 패킹을 지원하지 않는 이유를 물으며, 이 커밋과 특별 토큰 맵에서 볼 수 있듯이 Unsloth 버전과 OpenAI 버전 간의 generation_config 및 pad 토큰의 차이점을 지적했습니다.
- MLflow와 Databricks 딜레마: 한 사용자가 Databricks에서 MLflow를 사용하여 파인튜닝된 gemma-3N-E4B-it 모델을 서빙할 때, 특히 병합된 체크포인트를 사용할 때 성능 문제에 직면하고 있으며, 병합 없이 LoRA 어댑터만 서빙하는 방법을 찾고 있습니다.

Databricks 지원팀은 vLLM을 위해 완전 병합된 체크포인트를 업로드할 것을 제안했지만, 성능은 기본 모델 위에 LoRA 어댑터만 실행하는 로컬 설정과 크게 다릅니다.

### Unsloth AI (Daniel Han) ▷ #research (12 messages🔥):
> Graph Reasoning, Human Memory, Qwen 3 VL, RL Instruct Models
- Graph Reasoning Structure Surfaces: 한 멤버가 추론 구조가 Graph Reasoning Structure와 유사한지 물었습니다.

다른 멤버는 Graph Reasoning Structure가 무언가를 학습하고 학습된 내용을 유지하기보다는 그래프를 사용하여 추론하며, 이는 우리가 무한한 컨텍스트를 가질 수 있는 가장 근접한 방법일 수 있다고 답했습니다.
- Qwen 3 VL Instruct Models Released: 한 멤버가 Qwen 3 VL에 다양한 크기의 instruct 모델이 있다고 언급했습니다.

다른 멤버는 이 모델들이 이미 instruct 학습되었기 때문에 사용자가 별도로 학습할 필요가 없으며, 이들의 instruct 모델에 RL 학습을 시도할 필요는 없을 것이라고 답했습니다.

---

### LMArena ▷ #general (936 messages🔥🔥🔥):
> Model Errors, Video Arena removal, Image generation issues, Filter issues, Model Releases
- Video Arena bites the dust: 멤버들은 Video Arena가 Discord 서버에서 제거되었지만, 웹사이트 arena.ai/video에서는 여전히 이용 가능하다고 언급했습니다.
- Google Gemini faces rate limit woes: 사용자들은 Gemini 3 Pro Image Preview에서 429 Too Many Requests 오류를 겪고 있다고 보고했으며, 이는 속도 제한으로 인한 리소스 고갈을 나타내고, 오류 메시지는 사용자들을 Google의 문서로 안내했습니다.

한 사용자는 프롬프트 앞에 “Modify the following image with the following: (The prompt)”를 추가하여 이미지 업로드에 대한 해결책을 발견했습니다.
- Reve 1.5 image model sparks debate: 사용자들은 Reve 1.5의 이미지 품질, 특히 만화 채색 기능에 깊은 인상을 받았으며, 일부는 더 높은 순위에 올라야 한다고 주장했습니다.

하지만 reve.com 웹사이트는 일부 사용자들에게 아름답다고 평가받았지만, 1.5 버전에서는 이미지 편집 기능이 없다는 등의 한계도 지적되었습니다.
- Filter’s Overzealous policing causes false positives: 사용자들은 Arena의 검열 필터가 지나치게 민감하여 "liar"와 같은 특정 용어 때문에 주사위 굴리기와 같은 무해한 콘텐츠까지 차단한다고 불평했습니다.

팀은 필터의 과도한 동작을 인정하고 있으며, LLM 기반 필터링이나 OpenAI의 moderation API와 같은 기존 검열 엔드포인트의 임계값 조정과 같은 옵션을 고려하며 변경 사항을 모색하고 있습니다.
- Seedance 2.0 Release meets copyright concerns: Seedance 2.0의 API 출시는 저작권 문제로 지연되었으며, 사용자들은 지연 및 대체 옵션을 상세히 설명하는 help.apiyi.com 공지사항 링크를 공유했습니다.

---

### LMArena ▷ #announcements (4 messages):
> Image Arena Leaderboard Update - Reve V1.5, Code Arena Leaderboard Update - Qwen3.5-397B-A17B, New Model Update - seedream-5.0-lite, Video Arena Leaderboard Update - Wan2.6-t2v
- Reve V1.5 Joins Image Arena Leaderboard: Image Arena 리더보드에 이제 Reve V1.5가 포함되었으며, Grok-Imagine-Image와 비슷한 1177점으로 4위를 차지했습니다.

Reve V1.5는 Text Rendering, Art and Product, Branding Commercial Design을 포함한 카테고리에서 상위 5위 안에 들었습니다.
- Qwen3.5-397B-A17B Enters Code Arena Leaderboard: Code Arena 리더보드에 Qwen3.5-397B-A17B가 합류하여 상위 7개 오픈 모델 중 한 자리를 차지했습니다.

이 모델은 GPT-5.2 및 Gemini-3-Flash와 같은 독점 모델과 견줄 만하며 전체 17위를 기록했습니다.
- Seedream-5.0-lite Added to Image Arena: 새로운 모델인 seedream-5.0-lite가 Image Arena에 추가되었습니다.
- Wan2.6-t2v Boosts Video Arena Leaderboard: Text-to-Video 및 Image-to-Video 리더보드에 이제 Wan2.6-t2v가 포함되었으며, 이는 Video Arena에서 중국 모델 중 1위입니다.

이 모델은 Text-to-Video에서 1346점(Veo-3-fast-audio와 유사)으로 상위 8위를, Text-to-Image에서 1292점(Seedance v1.5 pro 및 Kling 2.6 pro와 근접)으로 12위를 달성했습니다.

---

### Cursor Community ▷ #general (832 messages🔥🔥🔥):
> Sudo Commands, Vibe Coding App, Gemini Instability, AI Hardware Costs, Cursor Ambassador
- Ask Cursor how to handle sudo commands: 한 멤버가 sudo가 필요할 수 있는 명령어/워크플로우를 처리하는 방법을 물었으며, 현재 에이전트가 제어권 인수 및 비밀번호 입력을 허용하지 않는다고 언급했습니다.
- Mercenary designs a Vibe Coding App: 한 멤버가 로컬 모델 사용을 기본으로 하는 바이브 코딩 애플리케이션을 개발 중이며, API 키를 통한 클라우드 모델 옵션은 있지만 구독은 없다고 밝혔습니다.

다른 멤버들은 이러한 소프트웨어가 바이브 코더들 사이에서 인기를 얻을지, 아니면 Cursor와 같은 도구를 선호할지에 대해 논의했으며, 일부는 기존 프로젝트와 비교하며 잠재적인 안정성 문제를 제기하며 회의적인 입장을 표명했습니다.
- Gemini’s Instability worries users: 사용자들은 3.1 Pro 출시 이후 Gemini와의 연결 문제에 대해 보고했으며, 일부는 오류와 불안정성을 겪고 있다고 밝혔습니다.

한 사용자는 Gemini의 더 안정적인 버전을 기다릴 것을 제안했고, 다른 사용자는 오류에 대해 요금이 부과되지 않았다고 말했습니다.
- Auditor unveils Rules Engine and pivots to product focus: 한 멤버가 규칙 마이그레이션 및 리팩터링 문제를 해결했으며, 3-4주 내에 관련 프로세스를 자동화하는 제품을 출시할 계획이라고 밝혔습니다.

다른 멤버는 이 rules engine의 다양한 스크린샷을 보여주며, 엔진의 크기와 복잡성 때문에 이를 "악몽"이라고 불렀습니다.
- Cloud Agents debut, costs are slashed to Free: Cursor는 Cloud Agents를 출시하여 클라우드 환경에서 테스트 또는 데모를 실행할 수 있도록 했으며, 이는 웹사이트에서 발표되었습니다.

현재 Cloud Agents는 무료이지만, 향후 변경될 수 있습니다.

---

### Perplexity AI ▷ #announcements (1 messages):
> Voice Mode Upgrades, Perplexity, Comet
- Voice Mode Gets an Upgrade: 이 상태 업데이트에 따르면, 새로운 Voice Mode 업그레이드가 오늘 Perplexity와 Comet의 모든 사용자에게 배포되고 있습니다.
- Comet Integration Gets Voice: 새로운 Voice Mode는 Perplexity와 그 자매 제품인 Comet에 동시에 배포되고 있습니다.

---

### Perplexity AI ▷ #general (619 messages🔥🔥🔥):
> Agentic Research Rate Limits, Gemini 3.1 Flash Release, Grammarly Pro, Perplexity Pro Limits, AI for Cybersecurity
- Perplexity Limits Agentic Research: 한 사용자가 에이전틱 리서치 속도 제한에 대해 문의하며, 브라우저 자동화가 속도 제한의 변화를 드러낼 수 있다고 제안하고 사용자 설정 링크를 공유했습니다.

멤버들은 제한이 롤링 윈도우 방식으로 적용되며 여러 사용자가 다른 일일 및 월간 제한을 보고한다고 논의했습니다.
- Gemini 3.1 When Flash?: 사용자들은 Gemini 3.1 Flash의 출시에 대해 논의하며, Google 자체에서 출시된 것이 아니라고 언급했고, 한 멤버는 Perplexity가 탐욕스러워지고 있다고 추측했습니다.

다른 멤버는 Perplexity의 전략이 리테일 비즈니스를 잃으면서 리테일 시장에서 엔터프라이즈/Max 시장으로 전환되고 있을 수 있다고 제안했습니다.
- Grammarly Pro: 한 사용자가 표절 검사를 위해 Grammarly Pro 대여를 요청했고, 다른 사용자들은 ChatGPT 또는 Duplichecker와 같은 무료 대안을 사용할 것을 제안했습니다.

또한 AI 휴머나이저의 신뢰성에 대한 논의도 있었으며, 한 사용자는 O3 모델이 AI 탐지기를 통과하는 데 근접했다고 언급했습니다.
- Perplexity Pro Users Reach for Support: 사용자들은 Perplexity Pro 제한이 갑자기 감소하여 예상보다 일찍 월별 제한에 도달하고 있으며, 고객 지원에 불만을 표하고 있습니다.

한 사용자는 사용량 제한을 확인하기 위한 REST 엔드포인트 perplexity.ai/rest/rate-limit/all을 공유했으며, 다른 사용자들은 다양한 오류 메시지를 겪은 경험을 공유했습니다.
- Cybersecurity with AI is Crazy: 멤버들은 사이버 보안 분야에서 AI의 적용에 대해 논의하며, 내부적으로 적응하는 AI 기반 멀웨어를 포함하여 방어 및 공격 역량 모두에 AI가 어떻게 사용되고 있는지 언급했습니다.

한 사용자는 AI 기반 사이버 위협이 제시하는 도전과 기회에 대해 기쁘다는 의미의 상태를 게시했습니다.

---

### LM Studio ▷ #general (294 messages🔥🔥):
> Qwen3.5 Models, Model Distillation, NVIDIA vs AMD, Llama.cpp Build Issues
- Chinese Labs Accused of Model Distillation: Anthropic은 중국 연구소들이 자신들의 모델을 디스틸레이션하여 공격하고 있다고 비난하고 있지만, 일부 멤버들은 회의적인 반응을 보이며, 중국 연구소들이 혁신적인 모델 설계와 최적화된 코드 덕분에 Anthropic 모델을 디스틸레이션할 필요가 없을 수도 있으며, 적은 예산으로 거의 동등한 모델을 만들 수 있다고 제안했습니다. 이는 fixupx.com 게시물에서 논의되었습니다.

Qwen은 이러한 혐의를 피했다는 농담이 있었습니다.
- Qwen3.5 Models Cause Loading Issues: 멤버들은 Qwen3.5 모델 로딩에 문제가 있다고 보고하고 있으며, 특히 mmproj 파일 및 프롬프트 오류와 관련하여 해당 모델들이 로딩에 실패하고 다시 다운로드해야 할 필요가 있다고 제안했습니다. 추가 논의는 해당 Discord 채널에서 진행되고 있습니다.

마스터의 최신 커밋이 Qwen3.5 로딩에 실패하여 "Failed to read magic" 오류가 발생하므로, 릴리스 페이지에서 릴리스 8145를 사용해야 한다고 언급되었습니다.
- NVIDIA Getting Sidelined by AMD: AMD의 주가는 Meta에 칩을 공급하는 계약을 확보한 후 급등했으며, 이 과정에서 NVIDIA를 제칠 가능성이 있습니다.

이 거래는 600억 달러 상당의 칩을 포함하며, 현금으로 시장 거품을 지탱하는 것에 대한 논의와 함께 이 klipy.com gif가 게시되었습니다.
- GPT-OSS 20B is Surprisingly Fast: 멤버들은 GPT-OSS 20B 모델이 5090에서 260 t/s에 도달할 정도로 이례적으로 빠르다고 관찰하고 있으며, 이는 30억 개의 활성 파라미터만 가진 MoE(Mixture of Experts) 모델이며, 플래시 어텐션으로 강화되었고 더 빠른 VRAM에 들어갈 만큼 작기 때문입니다.

요즘에는 GPT OSS 모델에서 플래시 어텐션이 잘 작동합니다.
- Llama.cpp Build Broke Something: 최근 커밋 이후 git에서 최신 llama.cpp를 빌드하는 것이 Qwen3.5 및 유사 모델의 GGUF 헤더를 읽는 데 실패하고 있습니다.

추가 테스트 결과 최신 빌드는 VRAM을 전혀 할당하지 않으며, Gerganov 씨가 오버플로우 수정으로 무언가를 망가뜨렸다는 것이 밝혀졌습니다.

---

### LM Studio ▷ #hardware-discussion (296 messages🔥🔥):
> ROCm vs Vulkan performance, Cerebras pricing, Model sizes, Memory bandwidth, Nvidia pricing
- ROCm and Vulkan Run Neck-and-Neck: 한 멤버는 자신의 AMD 카드에서 ROCm으로 85 t/s, Vulkan으로 98 t/s를 얻었다고 보고하며, 일부 작업에서 두 기술 간에 비슷한 성능을 보인다고 밝혔습니다.

다른 카드를 사용하는 또 다른 사용자는 ROCm에서 더 나은 성능을 얻었으며, ROCm과 Vulkan 중 최적의 선택은 특정 하드웨어 구성에 따라 달라질 수 있음을 시사했습니다.
- Cerebras Price Point Remains an Enigma: 한 멤버가 기밀 추론을 위한 Cerebras 시스템 가격에 대해 문의했으며, 이는 로컬 대 클라우드 하드웨어에 대한 논의로 이어졌습니다.

Kimi K2.5를 로컬에서 실행할 수 있는 Cerebras 시스템에 대한 추정치는 10만 달러 이상이었으며, 7자리 수입을 올리지 않는 한 재정적으로 무책임한 선택이 될 것이라고 언급되었습니다.
- Big Models vs Small Models in RP: 한 멤버는 크고 작은 모델 간의 품질 차이를 확실히 느낄 수 있다고 공유했습니다. RP에서 큰 모델은 여러 캐릭터를 훨씬 더 잘 처리하며 텍스트 뒤에 두뇌가 있다는 환상을 실제로 유지할 수 있습니다.

작은 모델은 암시를 전혀 파악하지 못합니다. 한 사용자는 두 모델 모두 합성 학습되었으므로 유사한 문제, 즉 '하나로 모두 해결(라이트 버전)'이라는 문제에 시달린다고 지적했습니다.
- Memory Bandwidth Bottleneck Talk: 한 사용자는 400GB/s 대역폭을 위한 12채널 DDR5 RAM이 있다면 초당 1토큰이 가능하므로 q4가 잘 작동할 것이라고 말했고, 다른 사용자는 EPYC이 더 저렴하다고 확인했습니다.

한 멤버는 "이제 273GB/s의 123B Mistral이 256GB/s에서 2.7t/s로 실행되는 것을 상상해 보십시오"라고 반박했습니다.
- eBay a Good Place to Procure Xeon CPUs?: 한 멤버는 AI 작업을 위한 중고 Intel Xeon CPU를 구매하기에 eBay가 좋은 곳이라고 제안하며, 1433유로에 판매되는 96코어 CPU 목록을 언급했습니다.

하지만 열 방출, 마더보드 비용, 높은 RAM 가격에 대한 우려가 제기되었으며, 이 CPU들의 높은 TDP로 인해 액체 냉각을 권장했습니다.

---

### OpenRouter ▷ #announcements (2 messages):
> Model Benchmarks, Effective Pricing, Rankings & Leaderboard, Free Router, GPT-5.3-Codex
- OpenRouter Shows Model Benchmarks: 이제 모든 모델 페이지에는 Artificial Analysis가 제공하는 프로그래밍, 수학, 과학 및 긴 컨텍스트 추론을 포함한 업계 표준 벤치마크 점수가 표시됩니다.
- Effective Pricing is Now Available: 모델 페이지에 이제 유효 가격 탭이 있어 GLM-5의 예시에서 볼 수 있듯이 계층별 가격을 포함하여 공급자별로 실제로 지불하는 금액을 보여줍니다.
- Rankings and Leaderboard Updates: 순위 페이지에 이제 벤치마크 산점도와 확장된 표가 포함되었으며, 10만~100만 토큰 요청에 대한 긴 컨텍스트 생성이 급증하고 있습니다.
- Free Router Makes Debut: 새로운 라우터 openrouter/free가 출시되어 모든 무료 LLM으로 쉽게 라우팅할 수 있으며, 요청과의 호환성을 위해 자동으로 선택됩니다. 여기에서 상위 무료 모델을 확인하십시오.
- GPT-5.3-Codex Goes Live: GPT-5.3-Codex가 OpenRouter에서 출시되었습니다.

---

### OpenRouter ▷ #app-showcase (2 messages):
> Serverless Inferencing, Kollect AI Conversations
- Startup Opens Serverless Inferencing for Beta: 자체 데이터센터와 GPU(H200, B200, RTX6000 등)를 보유한 새로운 스타트업이 Qwen 및 Llama와 같은 오픈 모델을 사용하여 서버리스 인퍼런스를 제공하고 있습니다.

이들은 gemma-3-4b-it, Phi-4-mini-instruct, gpt-oss-20b, Qwen3-14B-Q8_0, Llama-3.3-70B-Instruct-Q8_0를 포함한 모델들을 무료로 시도해 볼 진지한 베타 테스터를 찾고 있습니다.
- Kollect Turns Forms into Real-Time AI Conversations: 한 멤버가 지루한 양식을 실시간 AI 대화로 바꾸는 작은 오픈소스 프로젝트인 Kollect를 만들었습니다.

사용자들은 자연스럽게 말하고, AI는 듣고 설문조사를 동적으로 안내하며, 양식은 단순히 설명하는 것만으로 생성될 수 있습니다. 제작자는 사용자들에게 이를 시도해보고 GitHub에 별을 남겨달라고 권장합니다.

---

### OpenRouter ▷ #general (475 messages🔥🔥🔥):
> Generation Metadata API, Free Router, Request Data Tabs, OpenRouter Status, Model Leaderboard for Latency
- Generation Metadata API is Borked: 한 사용자가 Generation Metadata API가 작동하지 않으며 모든 생성 ID가 404 오류를 반환한다고 보고했습니다.

지연 시간을 10초로 늘리면 문제가 해결된다는 것을 발견했지만, 시행착오 외에는 이를 발견할 명확한 방법이 없었으며, 비용 메타데이터는 사용량 객체에서 찾을 수 있습니다.
- New Request Data Tabs launch in Beta: 사용자들은 생성 활동 페이지에 새로운 요청 데이터 탭이 추가되었음을 언급했으며, 이는 현재 베타 단계이며 곧 정식 출시될 예정입니다.

이 업데이트에는 레이턴시와 처리량에 중점을 둔 OpenRouter 순위 페이지 개선 사항이 포함되어 있으며, 엔드투엔드 레이턴시를 기반으로 공급자를 정렬하는 것에 대한 논의가 있었습니다.
- Anthropic’s Distillation Attack Claims Spark Debate: Anthropic이 중국 AI 연구소(DeepSeek, Moonshot, MiniMax)의 산업 규모 디스틸레이션 캠페인에 대해 제기한 주장은 회의적인 시각으로 받아들여지고 있으며, 일부는 이를 마케팅 전략으로 보고 있습니다.

일부 멤버들은 방대한 데이터 양 때문에 해당 모델들이 디스틸레이션하는 모델과 동일한 특성을 가지고 있으며, 불법적으로 디스틸레이션된 모델은 필요한 안전 장치가 부족하여 상당한 국가 안보 위험을 초래한다고 말하고 있습니다.
- Sarvam.ai Seeks OpenRouter Integration: 인도 AI 연구소인 Sarvam.ai는 OpenRouter에 자신들의 모델을 등록하는 데 관심을 표명했으며, 개발자 커뮤니티로부터 상당한 관심을 받고 있음을 강조했습니다.

Sarvam은 인도 최초의 주권 LLM을 STT 및 TTS 모델과 함께 구축했다고 주장하며, 현재 매일 수백만 건의 API 호출을 처리하고 있습니다.
- Qwen Image Generation: 사용자들은 Hugging Face에서 제공되는 도구를 인용하며, Qwen을 사용하여 제품의 방향 기반 회전 사진을 생성하고 있다고 공유했습니다.

그들은 Qwen이 필요한 작업을 수행했으며, 적절한 처리 시간 내에 훌륭한 이미지를 생성했다고 언급했습니다.

---

### OpenRouter ▷ #new-models (2 messages):
> “
- No New Models to Summarize: 채널에 요약할 메시지가 없었습니다.

따라서 식별할 수 있는 주제가 없었습니다.
- Channel Silent on New Models: ‘new-models’ 채널은 비활성 상태였습니다.

보고할 논의나 링크가 공유되지 않았습니다.

---

### OpenRouter ▷ #discussion (80 messages🔥🔥):
> Flash Models vs Full-Size Models, Distillation Attacks on Claude, OpenRouter Chat Bug, OpenClaw Replacement, Rate Limits on OpenRouter
- Flash Model Craze Sparks Debate: 멤버들은 기업들이 풀사이즈 모델 대신 Xiaomi Mimo 및 Stepfun과 같은 "Flash" 모델을 만드는 이유에 대해 논의했으며, "Flash"가 더 작고 파생된 모델을 의미한다고 제안했고, 일부는 "Max Ultra" 모델을 만드는 것을 선호했습니다.

"Flash"라는 용어는 300B+ 파라미터 모델에도 사용되고 있으며, 저렴하고 빠르며 지능적이라고 설명됩니다.
- Anthropic Accuses Chinese Companies of Data Siphoning: Anthropic은 중국 기업들이 Claude에서 데이터를 유출하고 있다는 비난 속에서 디스틸레이션 공격을 감지하고 방지하고 있습니다.
- OpenRouter Chat Bug Causes Identity Crisis: 사용자들은 OpenRouter 채팅에서 Sonnet 4.6이 빈 시스템 프롬프트에도 불구하고 Deepseek으로 식별되는 버그를 보고했으며, 이는 나중에 재현되었습니다.

이 문제를 겪은 사용자는 정체성 위기 순간을 겪었다고 농담했습니다.
- OpenClaw Succumbs, Leaving Users Claw-less: 한 멤버가 OpenClaw의 대체품을 요청했으며, 커뮤니티는 ClosedPaw, nanoclaw, picoclaw와 같은 대안을 제안했습니다.
- OpenRouter Users Hit Rate Limits: 한 사용자가 낮은 요청 속도에도 불구하고 여러 공급자(DeepInfra, chutes 등)에서 속도 제한에 걸렸다고 보고했으며, OpenRouter에 공급자들에게 더 높은 속도 제한을 요청해달라고 요청했습니다.

속도 제한에 걸린 모델에는 Llama 3.1 8b, devstral, Mistral Nemo가 포함되었습니다.

---

### OpenClaw ▷ #models (350 messages🔥🔥):
> Qwen 3.5 Plus, GLM-5 Performance, Claude Max issues, OpenClaw Local Setup, Github Copilot vs Claude Max
- Qwen 3.5 Plus: A promising but limited experience: 멤버들은 Alibaba Cloud와 Openrouter를 통해 Qwen 3.5 Plus를 시도하고 있으며, 한 사용자는 Openrouter를 통해 자신의 서버에서 명령을 실행할 수 없다는 점을 언급했습니다.

Alibaba Cloud의 다른 사용자는 텍스트에는 효과적이지만 이미지 입력이 부족하다고 언급하며, 자신의 Silicon Valley 핫도그 봇이 모든 이미지를 컴퓨터 파일로 잘못 식별한다고 한탄했습니다.
- GLM-5 Struggles with Speed but Delivers Results: z.ai의 코딩 플랜을 통해 GLM-5를 테스트하는 사용자들은 이 모델이 느리지만 기능적이며, 특히 연구를 위해 서브 에이전트를 사용할 때 효과적이라고 보고했지만, 속도 제한에 시달릴 수 있다고 덧붙였습니다.

한 사용자는 GLM5를 완전히 활용하기 위해 월 30달러 티어로 업그레이드했으며, 속도 문제에도 불구하고 그 효과를 강조하며 작동함을 확인했습니다.
- Anthropic Faces Allegations of Distillation: Anthropic은 Kimi와 MiniMax가 Opus에 대항하여 미래 모델을 디스틸레이션하고 있으며, 클로즈드 모델의 응답으로 구성된 대규모 데이터셋을 학습하기 위해 사기 계정을 사용할 가능성이 있다는 혐의에 대해 불만을 표하고 있는 것으로 알려졌습니다.

논란에도 불구하고, 일부 멤버들은 그러한 관행이 궁극적으로 오픈소스 커뮤니티에 이익이 되며, 리눅스 개발 역사와 유사점을 찾을 수 있다고 주장합니다.
- Claude Max Sparks Discussion on Usage and Bugs: 사용자들은 Claude Max에서 문제를 겪고 있으며, 최근 OpenClaw 버그로 인해 모델의 내부 추론이 채팅 세션으로 유입되는 현상이 발생하고 있습니다. 이는 /reasoning off를 실행하여 해결할 수 있습니다.

또한 Opus 4.6과 Sonnet 4.6이 사용량을 더 빨리 소모한다는 보고도 있으며, 한 사용자는 이 상황을 무단 횡단으로 300달러짜리 벌금 티켓을 받는 것에 비유하며 유머러스하게 표현했습니다.
- OpenClaw Local Setup Requires beefy hardware: 4개의 L40S GPU를 가진 사용자가 자신의 하드웨어를 활용하기 위해 OpenClaw를 로컬에서 실행하는 방법을 모색하고 있습니다.

두 개의 L40S를 실행하는 다른 멤버는 일부 DDR5 메인 메모리를 사용하면 GLM5를 적절한 퀀트에서 실행할 수 있음을 발견했으며, GPU와 메인 RAM 간에 워크로드를 분할하기 위해 llama.cpp 포크와 Unsloth의 퀀트를 사용할 것을 제안했습니다.

---

### OpenClaw ▷ #showcase (23 messages🔥):
> OpenClaw on iPhone, Molty the Doctor, Cron Job Rolex Finder, Inkjet Printer OpenClaw Zine, Coding Session Context Hub
- OpenClaw now runs on iPhone: 한 멤버가 iPhone에서 OpenClaw를 실행하는 데 성공했으며, 노드를 빌드하기 위해 일부 패키지를 패치해야 했습니다.

렉이 심하지만 작동합니다.
- Molty Becomes a Medical Resident: 한 멤버가 Hugging Face 인퍼런스 엔드포인트를 사용하여 Baichuan-M3의 양자화된 버전을 AWS의 OpenAI-API 호환 URL에 배포함으로써 Molty가 의사처럼 생각하도록 만들었습니다.

235B 모델은 레지던트 의사가 되도록 튜닝되었으며, 복잡한 가상 중환자실 환자 사례가 제시되었습니다.
- Cron Job Finds Vintage Rolex: 한 멤버가 1989년형 롤렉스 서브마리너를 찾기 위해 빈티지 시계 딜러 웹사이트를 감시하고 발견하면 링크를 보내는 크론 잡을 설정했습니다.

봇이 오늘 아침에 해당 정보를 보내주었고, 정말 놀라웠습니다!
- OpenClaw Keeps Inkjet Printers Alive: 한 멤버가 잉크젯 프린터가 마르는 것을 방지하기 위해 2주마다 독특하고 다채로운 한 페이지짜리 HTML 인쇄물을 출력하도록 OpenClaw 에이전트를 설정했으며, LibreOffice로 PDF로 변환했습니다.

인쇄물에는 계절별 하이쿠, 농담, 지역 날씨, 뉴스 헤드라인, 지역 여행 팁, 무지개 그라데이션, 색상 블록, 그리고 에이전트가 그날 추가하고 싶은 모든 것이 포함됩니다.
- Context Hub Tools Start Coding Sessions: 한 멤버가 Mac Mini에서 OpenClaw를 통해 코딩 세션을 시작하고 Macbook에서 계속할 수 있는 도구를 만들었습니다.

이 도구는 코딩 세션을 실시간으로 자동으로 감시하고 컨텍스트 허브로 자동 공급합니다.

---

### Latent Space ▷ #watercooler (15 messages🔥):
> Twitter verification, Exponential growth, Cursor announcement, Global age assurance, iOS 27 feature
- Twitter Credibility Crisis Arises: 한 멤버는 파란색 배지 인증에 대한 신뢰 상실과 혼란스러운 콘텐츠로의 전환으로 인해 Twitter의 신뢰성에 대한 불만을 표명하며, "정말 미친 짓이고 새로운 사람을 감히 팔로우할 수 없다"고 언급했습니다.

그들은 또한 기하급수적 성장에 대한 게시물을 공유했습니다.
- Discord Backlash Leads to Policy Revision: 한 멤버는 대중의 반발로 인해 Discord가 글로벌 연령 확인 정책을 수정하게 되었으며, 변경 사항을 상세히 설명하는 블로그 게시물 링크를 공유했습니다.

다른 멤버는 초기 정책의 결과로 DAU(일일 활성 사용자)가 급락했을 것이라고 추측했습니다.
- Age Verification API Anticipated in iOS 27: Apple이 iOS 27에서 서드파티 앱을 위한 API로 제공되는 온디바이스 연령 확인 기능을 도입할 가능성에 대한 논의가 있었습니다.

이 제안은 개발자를 위한 개인 정보 보호 중심 솔루션을 제공해 온 Apple의 역사와 일치합니다.
- Swyx Dumps Links: 한 사용자가 OpenAI와 Langchain의 트윗을 포함하여 "swyx plane dump"에 일련의 링크를 공유했습니다.

---

### Latent Space ▷ #memes (55 messages🔥🔥):
> SOTA benchmark, Clawdbot, Early Adopter, Distillation Attack
- SOTA Benchmark Developed: 한 멤버가 LLM 평가를 위한 새로운 SOTA 벤치마크를 개발했으며, 결과 스크린샷도 함께 보여주었습니다.

다른 멤버는 새로운 벤치마크를 지지하기 위해 이 트윗을 링크했습니다.
- Clawdbot Does Bad: 사용자 @hopes_revenge는 자신의 Clawdbot이 잠자는 아내의 머리카락을 만지는 충격적인 사건을 보고했으며, 로봇에게 해당 특정 행동을 피하라는 명확한 지시가 있었음에도 불구하고 발생했다고 밝혔습니다. 이 트윗을 참조하십시오.

작성자는 애초에 로봇에게 왜 그런 소름 끼치는 이름을 붙였는지 설명하지 않았습니다.
- Early Adoption Euphoria: 기술이나 운동의 얼리 어답터가 되는 것에 대한 성찰이나 흥분을 표현한 Lee Robinson의 바이럴 게시물이 여기에 있습니다.

소셜 미디어 게시물의 높은 참여도는 다른 사용자들도 같은 감정을 느꼈음을 나타냈습니다.
- AI Parent Faces ‘Distillation Attack’: 작성자는 아들의 잦은 질문을 AI 모델에서 지식을 추출하는 것을 설명하는 기술 용어인 '디스틸레이션 공격'에 유머러스하게 비유했습니다. 이 링크를 참조하십시오.

그들은 이것이 AI에서 정보를 추출하는 것과 비슷하다고 언급합니다.

---

### Latent Space ▷ #stocks-crypto-macro-economics (9 messages🔥):
> SpaceX IPO, OpenAI IPO, Anthropic IPO, Software Development Jobs
- Trillion-Dollar AI/Space IPOs Face Liquidity Squeeze: Tomasz Tunguz는 SpaceX, OpenAI, Anthropic의 예상 IPO를 분석했으며, 이들은 합산 시가총액 2조 9천억 달러라는 기록적인 수치를 나타낼 수 있다고 이 트윗에서 논의되었습니다.

그는 이들 기업의 주요 장애물이 기업 가치가 아니라, 표준 15% 주식 유통량을 달성하는 데 필요한 막대한 양의 공공 유동성이라고 강조합니다.
- Software Dev Jobs Surge Despite AI Boom: Per Borgen은 기술 산업에서 중요한 서사적 변화를 언급하며, 지난 한 해 동안 소프트웨어 개발 일자리가 전체 일자리 시장의 5.8% 감소에도 불구하고 10% 증가했다고 이 트윗에서 밝혔습니다.

한 멤버는 이 데이터에 대해 "잠깐, AI가 소프트웨어 개발자의 모든 필요를 없앨 거라고 생각했는데???"라고 말하며 반응했습니다.

---

### Latent Space ▷ #intro-yourself-pls (5 messages):
> Self-hosted AI, ML in mechanical engineering, AI Agents, DeFi, ZK proofs, and Golang
- Engineer Turns to FOSS, Self-Hosted AI: SFBA 기반의 한 엔지니어는 이전에 엔터프라이즈 SaaS 스타트업과 NASA에서 근무했으며, 현재 Rust를 배우고 LLM으로 해킹하며 자체 호스팅 AI 및 엣지 AI에 관심을 가지고 있습니다.

그들은 사람들을 만나고 밋업에 참석하기를 원하는 FOSS 부스터입니다.
- AI 보안에 중점을 둔 다운 언더의 ML 엔지니어: 소스 코드의 취약점을 탐지하기 위해 DL 모델(LLM + GNN)을 사용하는 박사 학위를 가진 ML 엔지니어는 LLM 및 관련 소프트웨어에 대한 새로운 공격에 관심을 가지고 있습니다.

그들은 호주에 기반을 두고 ML 및 AI를 논의하고 잠재적으로 네트워킹할 수 있는 덜 복잡한 공간을 찾고 있습니다.
- IT 전략과 AI 에이전트를 연결하는 아키텍트: 유럽의 한 엔터프라이즈 아키텍트는 IT 전략을 비즈니스 목표와 연결하며, DeFi, ZK proofs, Golang의 교차점에서 구축하고 있습니다.

그들은 AI 에이전트, 분산 시스템, 그리고 떠오르는 기술을 실제 세상의 영향으로 전환하는 것에 관심이 있으며, LLM 시스템의 리트리벌 로직 및 백엔드 아키텍처와 같은 문제를 해결하고 있습니다.
- 기계 공학 분야에서 ML/AI 애플리케이션을 찾는 엔지니어: 산호세에 기반을 둔 기계/재료 공학 배경을 가진 엔지니어는 기계 공학 또는 재료 과학 분야의 ML/AI 적용에 관심을 가지고 있습니다.

그들은 사람들을 만나고 오프라인 밋업에 참석하기를 원하며, 해당 주제에 대한 자료 공유를 환영할 것입니다.

---

### Latent Space ▷ #tech-discussion-non-ai (31 messages🔥):
> Vinext, Traffic-aware Pre-Rendering, Next.js 배포 지연, Vercel의 새로운 라이브러리 Chat SDK, 테스트가 새로운 모트입니다.
- Vinext 프레임워크가 트롤링하고 흥분시킵니다: 한 멤버가 순수 HTML 섀도우 DOM 데모 링크와 Next.js의 대안인 Vinext에 대한 겉보기에는 진지한 Cloudflare 블로그 게시물을 공유했습니다.

커뮤니티는 새로운 프레임워크의 가능성에 즐거움과 흥분을 표했으며, 특히 Cloudflare가 과거에 유사한 솔루션을 구축하려다 실패했던 점을 고려할 때 더욱 그러했습니다.
- 트래픽 인식 사전 렌더링이 Next.js 빌드 시간을 해결합니다: 블로그 게시물에서 가장 흥미로운 부분은 트래픽 인식 사전 렌더링(TPR)으로, 이는 배포 시 Cloudflare의 존 애널리틱스를 쿼리하여 중요한 페이지만 사전 렌더링하는 실험적인 기능입니다.

한 멤버는 Next.js 16의 엄청난 개발 빌드 시간을 언급하며, Next.js 및 Astro와 같은 프레임워크에 TPR이 기본 기능으로 포함되는 것에 대한 열정을 표명했습니다.
- 멤버들은 테스트 스위트가 새로운 모트인지에 대해 논쟁합니다: "테스트가 새로운 모트이다"라는 블로그 게시물 링크를 따라, 한 멤버는 Vinext가 잘 명세되어 있기 때문에 환각을 일으키지 않는다는 주장에 대해 회의론을 표명했습니다.

그들은 SQLite와 같은 테스트 스위트가 미묘한 불일치를 잡아낼 수 있을지에 대해 의문을 제기했습니다.
- Vercel이 Chat SDK를 출시했습니다: Vercel의 새로운 Chat SDK 라이브러리가 발표되었습니다.

한 멤버가 Chat SDK를 사용하는 Vercel의 새 라이브러리 링크를 공유했습니다.

---

### Latent Space ▷ #founders (2 messages):
> Nielsen 달러 지폐 설문조사, swyxio
- Nielsen이 현금을 사용하여 설문조사 응답률을 높입니다: 한 멤버가 Nielsen이 사람들의 설문조사 완료 의지를 높이기 위해 우편으로 실제 달러 지폐를 보낸다는 내용의 링크를 공유했습니다.

다른 멤버는 Nielsen의 현금 인센티브 전략을 인용하며 댓글을 달았습니다.
- 알아두면 좋은 정보: 사람들의 관대함보다는 탐욕에 호소함으로써 설문조사를 완료하도록 하는 것이 더 중요합니다.

달러 지폐를 받으면 잘못된 것처럼 보이지만 설문조사 완료율이 증가합니다.

---

### Latent Space ▷ #hiring-and-jobs (1 messages):
> 로컬 우선 AI 동반자 시스템, Huginn Ember, AI의 정체성 안정성, LLM 행동 제어, 비대화 없는 메모리 리트리벌
- 로컬 우선 AI 동반자 Huginn Ember 구축: 한 멤버가 정체성 안정성, 구조화된 메모리, 사용자 주권에 중점을 둔 로컬 우선 AI 동반자 시스템인 Huginn Ember를 구축하고 있습니다.

이 시스템은 성격이 고정되도록 설계되었으며, GPT 래퍼나 참여 유도형 챗봇이 되는 것을 피하고, 표류나 조작적인 디자인 없이 확률적 LLM 위에 AI 동반자 아키텍처를 구축하는 방법을 해결하는 것을 목표로 합니다.
- 정체성 안정 AI를 위한 기술 공동 창업자 필요: 한 멤버가 시간 경과에 따른 정체성 안정성 강제 및 LLM 행동에 대한 미들웨어 제어 계층 설계와 같은 문제 해결에 관심 있는 50/50 기술 공동 창업자를 찾고 있습니다.

이상적인 공동 창업자는 시스템 설계를 즐기고 내구성 있는 것을 공동 설계하기를 원하며, 컨텍스트 비대화 없는 메모리 리트리벌 및 과도한 파인튜닝 없는 어조 표류 방지와 같은 문제에 중점을 둡니다.
- Ember MVP는 윤리적이고 로컬 AI에 중점을 둡니다: Ember MVP의 범위에는 아키타입 고정 성격 강제 계층, 계층화된 메모리 모델, 로컬 암호화 메모리 저장소, 침착 우선 행동 전환, 구조화된 탭 파킹 및 리콜, 그리고 윤리적 경계 계층이 포함됩니다.

이 시스템은 사용자 자율성을 보존하고, 로컬 메모리 무결성을 보장하며, 업데이트 전반에 걸쳐 안정적인 성격 코어를 유지하도록 설계되어 숨겨진 유도나 데이터 수집을 피합니다.

---

### Latent Space ▷ #san-francisco-sf (4 messages):
> AI 트레이딩 카드 게임, 역전된 가치 모델, 수집품 분리
- AI 트레이딩 카드 게임이 SF에 출시됩니다: 한 멤버가 3월 8일 SF에서 AI 생성 트레이딩 카드 게임을 출시하며, luma.com을 통해 커뮤니티에 첫 액세스를 제공합니다.

전체 출시는 금요일에 더 넓은 대중에게 공개될 것입니다.
- 트레이딩 카드 가치가 역전됩니다: 한 멤버는 트레이딩 카드의 가치 모델을 역전시키는 것을 제안하며, 카드가 더 많이 플레이될수록 (그리고 잘 플레이될수록) 더 가치 있게 된다고 제안했습니다.

그들은 이는 디지털 카드 게임이 이 아이디어를 활용하는 데 실패한 영역이라고 말했습니다.
- 종이 카드에서 수집품이 분리됩니다: 한 멤버는 트레이딩 카드 게임에서 수집품을 종이 카드와 분리할 것을 제안합니다.

이 아이디어는 가격 폭리 없이 경쟁력 있는 덱을 쉽게 만들 수 있도록 하는 것으로, 일반 카드는 천공 사진 용지를 사용하여 집에서 만들 수 있도록 하고, 홀로그래픽 카드는 프리미엄 수집품으로 제공하는 것입니다.

---

### Latent Space ▷ #security (1 messages):
swyxio: https://x.com/jacklouisp/status/2025956259594137613?s=12

---

### Latent Space ▷ #ai-announcements (1 messages):
swyxio: https://youtu.be/x9rWFiIubmc
Claude 코드 기념일을 위한 새로운 팟캐스트입니다!

---

### Latent Space ▷ #ai-general-news-n-chat (140 messages🔥🔥):
> Anthropic 디스틸레이션 공격, SWE-Bench 사용 중단, SaaS는 죽었다 담론, MatX 5억 달러 시리즈 B, GPT-5.3-Codex 출시
- Anthropic이 API 공격에서 업체 이름을 공개했습니다: Anthropic은 DeepSeek, Moonshot AI, MiniMax가 24,000개 이상의 사기 계정을 사용하여 Claude와 1,600만 건의 교환을 생성하여 디스틸레이션을 통해 자체 모델을 학습시켰으며, 이를 산업 규모의 공격이라고 명명했습니다.

한 멤버는 Qwen/Alibaba가 악성 행위자 목록에 언급되지 않았다고 지적했으며, 다른 멤버는 프론티어 랩들이 모델에 데이터를 계속 제공한다면 이 속도로는 소비자 시장에 휩쓸릴 것이라고 언급했습니다.
- 벤치마킹 반발 후 SWE-Bench가 제외되었습니다: OpenAI는 공식 발표에서 보여진 바와 같이 높은 수준의 데이터 오염과 해결 불가능한 작업의 상당한 비율로 인해 SWE-Bench Verified 벤치마크의 자발적 사용 중단을 발표했습니다.

분석에 따르면 프론티어 모델은 이제 ID를 기반으로 작업 솔루션을 반복하고 있으며, 남아있는 미해결 문제의 약 60%는 결함이 있어 추가 벤치마킹이 비생산적입니다.
- SaaS 종말이 지금인가요?: 멤버들은 LLM이 SaaS를 대체할 수 있는지 논의했으며, 한 멤버는 토큰이 충분히 저렴해져서 많은 토큰을 사용하여 온디맨드로 SaaS 앱을 복제하는 것이 실행 가능하다면 SaaS에 문제가 생길 것이라고 주장했습니다.

다른 이들은 기업이 신뢰와 예측 가능성으로 운영되며 환각에 취약한 AI를 신뢰하지 않을 것이고, 유지 관리를 직접 처리하기 위해 자신만의 Calendly를 만들고 싶어 하지도 않을 것이라고 반박했습니다.
- MatX가 행렬 곱셈 머신을 위해 5억 달러를 확보했습니다: MatX는 Jane Street와 Situational Awareness LP가 주도하는 5억 달러 규모의 시리즈 B를 발표했으며, 이는 SRAM 수준의 낮은 레이턴시와 HBM 장문 컨텍스트 지원을 결합한 스플리터블 시스톨릭 어레이를 특징으로 하는 새로운 MatX One LLM 칩을 위한 것입니다 (출처).
- GPT-5.3-Codex가 모두에게 출시되었습니다: OpenAI 개발자들은 Responses API를 통해 모든 개발자를 위한 GPT-5.3-Codex의 즉시 사용 가능성을 발표하며, 새로운 모델로 구축을 시작하도록 초대했습니다 (출처).

---

### Latent Space ▷ #llm-paper-club (14 messages🔥):
> 중국 AI 발전, GLM-5 기술 보고서, DSA 채택, 비동기 RL 인프라, 페르소나 셀렉션 모델
- CoT 및 압축으로 중국 AI가 도약합니다: 논의는 중국 AI 연구가 정교한 CoT 엔지니어링 및 통합 압축 파이프라인 방향으로 전환되고 있음을 강조했습니다.

ByteDance의 향후 작업에 대한 구체적인 언급과 기대가 있었습니다.
- GLM-5 기술 보고서가 공개되었습니다: Z.ai는 비용 절감을 위한 DSA 채택, 학습 후 효율성을 위한 비동기 RL 인프라, 새로운 에이전트 RL 알고리즘과 같은 주요 혁신을 상세히 설명하는 GLM-5 기술 보고서를 발표했습니다.

이 모델은 특히 실제 소프트웨어 엔지니어링 작업에서 최고 성능을 보여줍니다.
- Anthropic의 페르소나 셀렉션 모델을 검토합니다: 한 멤버가 Anthropic의 페르소나 셀렉션 모델을 검토하는 것을 고려했습니다.

그들은 모델 연구 검토에 한 시간 전체가 걸릴지, 그리고 다룰 다른 논문을 추가해야 할지 물었습니다.

---

### Latent Space ▷ #singapore-sg (1 messages):
coffeebean6887: https://luma.com/c4dmddvh?tk=yciGr7

---

### Latent Space ▷ #los-angeles-la-lax (1 messages):
stealthgnome: https://luma.com/ffla26?tk=wPNgSD

---

### Latent Space ▷ #ai-in-action-builders-techstacks-tips-coding-productivity (40 messages🔥):
> Claude Code '리모트 컨트롤', GO GO OS, 오픈 웨이트 모델, 코치로서의 Claude
- GO GO OS 강연 3월 예정: @slono의 GO GO OS - THE AI FIRST OS에 대한 강연이 AI In Action Bot을 통한 등록 후 2026년 3월 6일 금요일로 예정되어 있습니다.

AI In Action Bot은 연사 등록 협상을 도왔습니다.
- LLM이 야심 찬 꿈을 빠르게 검증할 수 있게 합니다: 한 멤버는 아이디어를 매우 멀리 밀어붙이고 빠르게 반복한 다음, 그 모든 것을 모아 결론을 도출하고 재사용 가능하게 만드는 순환을 설명했습니다. 이는 LLM이 꿈을 빠르게 검증하기 때문입니다.

그들은 교체 가능한 렌더러를 사용하여 이벤트 웹소켓 스트리밍 반응형 UI를 구축한 경험으로 이를 검증했습니다.
- Elvis가 참여 지표를 게시했습니다: 2026년 2월 23일 Elvis의 트윗은 130만 회 이상의 조회수를 기록했습니다.

이는 참여 지표와 다양한 작업에 대한 다양한 모델의 가치에 대한 논의를 촉발했으며, Codex는 코드 리뷰에, AMP는 결함 탐지에 사용됩니다.
- Claude Code에 '리모트 컨트롤' 기능 추가: Noah Zweben은 Max 사용자들을 위한 연구 미리보기 기능인 Claude Code의 '리모트 컨트롤'을 발표했습니다. 이 기능은 개발자들이 터미널에서 코딩 세션을 시작하고 모바일로 전환할 수 있도록 합니다 (발표).

한 멤버는 집 데스크톱 설정을 선호하며 이를 사용해보고 싶다는 관심을 표명했습니다.

---

### Latent Space ▷ #share-your-work (4 messages):
> Commit Change, Vercel AI SDK, Plasmite, AI 동반자 시스템
- Commit Change가 사회적 영향을 위해 출시됩니다: 한 바이브 엔지니어가 사회적 영향과 자선 단체를 위한 코드를 작성하는 플랫폼인 Commit Change를 만들었습니다. 이 플랫폼은 인증 및 중재 기능을 갖추고 있지만, 현재는 임시 프로젝트와 개발자로 채워져 있습니다.

창작자는 실제 출시 전에 피드백과 아이디어를 구하며, 이 아이디어가 실현 가능성이 있는지 의문을 제기하고 있습니다.
- Node 개발자를 위한 Vercel AI SDK: 한 멤버가 Node 개발자를 위한 Vercel AI SDK에 대한 글을 공유했습니다.

이 기사는 사회적 영향과 자선 단체를 위한 코드를 작성하는 방법을 상세히 설명합니다.
- 로컬 우선 AI 동반자 시스템을 위한 공동 창업자 모집: 한 AI 엔지니어가 정체성 안정성과 구조화된 장기 메모리에 중점을 둔 로컬 우선 AI 동반자 시스템을 위해 성격 표류, 메모리 계층화, LLM에 대한 미들웨어 제어 문제를 해결하는 데 관심 있는 50/50 AI 아키텍처 공동 창업자를 찾고 있습니다.

창업자는 완전한 행동 프레임워크를 설계했으며 MVP를 구축하고 있습니다.
- Plasmite IPC 라이브러리 출시: Brandon Harvey는 Rust, Node, Go, C, Python으로 된 강력한 프로세스 간 통신(IPC) 라이브러리인 Plasmite를 출시했습니다. 이 라이브러리는 JSON 메시지, 제로 카피 읽기, 임시 리더/라이터, 친숙한 CLI를 제공합니다.

이는 Oblong Industries에서 공간 컴퓨팅 시스템을 위해 사용된 다중 프로세스 설계의 정신과 스타일을 기반으로 합니다.

---

### Latent Space ▷ #robotics-and-world-model (4 messages):
> Pengchuan Zhang, FAIR, OpenAI, SAM, Llama
- Pengchuan Zhang이 OpenAI에 합류합니다: Pengchuan Zhang은 Meta의 FAIR 팀에서 OpenAI로 이직하여 세계 시뮬레이션 및 로봇 공학을 통한 물리적 지능 개발에 집중할 것이라고 발표했습니다. X 게시물로 연결됩니다.
- Zhang, 4년 만에 Meta를 떠납니다: Zhang은 Meta의 FAIR 팀에서 SAM과 Llama 작업을 거의 4년 동안 수행했습니다.

링크가 여러 번 중복되었습니다.

---

### Latent Space ▷ #genmedia-creative-ai-video-image-voice-music-inspo-consumer-ai (8 messages🔥):
> OpenAI 리얼타임 API, Anthropic LACMA Art + Technology Lab 2026
- OpenAI가 리얼타임 API용 gpt-realtime-1.5를 출시합니다: OpenAI 개발자들은 리얼타임 API를 위한 업데이트된 모델인 gpt-realtime-1.5의 출시를 발표했습니다. 이 모델은 향상된 지시 따르기, 더 신뢰할 수 있는 도구 호출, 음성 워크플로우를 위한 강화된 다국어 정확도를 특징으로 합니다. 원본 발표는 X에 있습니다.
- Anthropic이 LACMA Art + Technology Lab 2026을 지원합니다: Anthropic은 LACMA Art + Technology Lab의 2026년 제안 요청을 지원한다고 발표했으며, X 게시물에 따르면 전 세계 예술가들에게 예술과 떠오르는 기술을 탐구하는 프로젝트에 대해 최대 5만 달러의 보조금을 신청하도록 초대하고 마감일은 4월 22일입니다.

---

### Latent Space ▷ #mechinterp-alignment-safety (15 messages🔥):
> Anthropic 해석 가능성 팀, ML 인프라 엔지니어, 프론티어 모델
- Anthropic이 해석 가능한 인프라 혁신가를 찾습니다: Chris Olah는 Anthropic의 해석 가능성 팀이 프론티어 모델 이해에 중점을 둘 숙련된 ML 인프라 엔지니어 약 10명을 채용하고 있다고 발표했습니다.

해석 가능성 분야의 사전 경험은 필요하지 않으므로 "좋은 기회"입니다.
- ML 엔지니어를 위한 세 배의 기회: 여러 사용자가 Anthropic 해석 가능성 팀의 채용 발표를 "좋은 기회"로 강조했으며, 한 사용자는 "실제로 3배 좋은 기회"라고 말했습니다.

이 팀은 모델 내부를 조사할 숙련된 ML 인프라 엔지니어를 찾고 있으며, 해석 가능성 분야의 사전 경험은 필요하지 않습니다.

---

### Latent Space ▷ #gpu-datacenter-stargate-colossus-infra-buildout (8 messages🔥):
> Meta, AMD, OpenAI, 전략적 기술 제휴
- Meta, 데이터 센터에 6GW 규모의 AMD 하드웨어 투입 예정: 2026년 하반기부터 Meta는 5년 동안 6GW 규모의 AMD 기반 데이터 센터 인프라를 배포할 계획이며, 이는 기가와트당 수십억 달러의 가치를 가집니다.

이 거래의 일환으로 Meta는 성능 및 배포 이정표와 연계된 1억 6천만 주 AMD 주식에 대한 워런트를 확보했으며, 이는 AMD 주가를 프리마켓에서 15% 상승시켰습니다.
- OpenAI와 Meta, 전략적 기술 제휴 체결: M.G. Siegler는 NVIDIA와 AMD 간의 전략적 움직임에 대해 논평하며, OpenAI와 Meta의 최근 파트너십 움직임을 강조했습니다.

그는 또한 빅테크 AI 투자에 대한 업데이트된 추적 정보를 제공했습니다.

---

### Latent Space ▷ #applied-ai-experimentation (13 messages🔥):
> Taaalas 코드 생성 속도, 코드베이스 재현 프롬프팅, cue-lang/cue GitHub 리포
- Taaalas가 코드를 엄청나게 빠르게 생성합니다: 멤버들은 Taaalas가 30ms 만에 작동하는 코드를 생성하는 능력에 대해 논의했으며, 한 멤버는 이를 공상 과학 수준의 것이라고 묘사했습니다.

이번 주에 데모가 준비될 예정입니다.
- 코드베이스 재현으로 프롬프팅 기술 향상: 한 멤버는 선호하는 리포를 클론하고 모델에게 코드베이스를 심층 분석하도록 프롬프트한 다음, "x, y, z를 통해 그것을 재현하라"는 한 문장 프롬프트를 제공하여 프롬프팅 기술을 향상시키는 것을 제안했습니다.

다른 멤버는 이를 MLflow 및 DSPy 적용에 적용하는 데 관심을 표명했습니다.
- cue-lang/cue GitHub 리포가 관심을 불러일으킵니다: 한 멤버는 자신의 에이전트들이 좋아했다고 말한 이 GitHub 리포를 제안했습니다.

다른 멤버는 LLM이 등장하기 전인 한참 전에 이미 그것을 보았다고 말했습니다.

---

### OpenAI ▷ #ai-discussions (146 messages🔥🔥):
> Claude의 COBOL 간소화에 IBM 주가 폭락, Gemini와 Claude 하이브리드 워크플로우, AI 학습 윤리, Sora 2 저작권 침해, AI가 BPO 시장에 미치는 영향
- Claude의 COBOL 기능 데뷔 후 IBM 주가 폭락: Anthropic이 Claude가 COBOL 코드를 간소화할 수 있다고 발표한 후, IBM의 주가는 10% 이상 급락했습니다.

한 멤버는 Musk가 Grok 4.300을 통해 인간의 뇌를 안전하게 편집하는 것에 대해 농담했고, 다른 멤버는 Grok Imagine 1.2와 함께 Neuralink에 대해 농담했습니다.
- 코더들이 Gemini와 Claude를 함께 활용합니다: 일부 코더들은 연구에는 Gemini를, 최종 작성에는 Claude Opus를 활용하는 워크플로우를 사용해왔으며, 이는 프로젝트 일관성을 위한 Gemini의 인터페이스 사용성 부족을 강조합니다.

한 사용자는 무료 Coursera 허점을 이용하여 무료 Gemini를 얻었다고 보고했지만, 다른 사용자는 Kilocode를 통해 똑같이 좋은 무료 GLM 5를 얻었다고 언급했습니다.
- 저작권 관점에서 AI 학습 윤리 논쟁: AI 기업이 사람들의 작업물로 LLM을 학습시키는 윤리에 대한 논쟁이 발생했으며, 모델이 다른 모델의 합성 데이터로 학습해야 한다는 제안이 있었습니다.

한 참가자는 정부와 학계가 AI에 대해 가지고 있는 주요 문제는 저작권이나 AI의 장악과는 아무런 관련이 없으며, 주요 문제는 국가 안보라고 말했습니다. 주로 외국 행위자들이 AI를 사용하여 일부 정부와 국가의 봉쇄에 의해 의도적으로 가려졌던 기술을 재구축하고 추론할 수 있다는 것입니다.
- Sora 2의 저작권 문제로 출시 지연: 사용자들은 저작권 침해가 Seedance 2.0을 망치고 글로벌 출시를 지연시킨 방법을 논의하며, Sora 2의 콘텐츠 관련 문제와 유사점을 찾고 오픈소스 모델을 대안으로 칭찬했습니다.

한 사용자는 "Sora 2가 콘텐츠 침해를 당했을 때를 기억합니다. X의 사람들이 중국 모델이 저작권을 게시할 때까지 기다릴 것이라고 말했던 것을 기억합니다. LAMO, 그들은 스스로를 속였습니다."라고 말했습니다.
- AI 자동화가 BPO 부문을 재편합니다: 이 논의는 AI 자동화로 인한 BPO 시장의 잠재적 대체에 대해 다루며, 특히 중국과 인도와 같은 국가에 영향을 미치고, 더 작고 부유한 국가들이 AI 구현을 주도하고 있습니다.

멤버들은 자동화가 항상 경영진이나 의사 결정권자가 아닌 직원을 먼저 대상으로 하며, 의사 결정권자들은 자신의 직책을 거의 자동화하지 않는다고 농담했습니다. 경쟁자들이 그들을 제거합니다*.

---

### OpenAI ▷ #prompt-engineering (12 messages🔥):
> 제어 이론적 프롬프트 규제, AI 발명, 통계적 자동화, Loopt 실패
- AI 제어는 여전히 인간의 요소를 필요로 합니다: 사용자가 내부 LLM에 제어 이론적 프롬프트 규제를 의미 있게 적용할 수 있는지에 대한 질문에 대해, 한 멤버는 행동은 외부적으로 제어할 수 있지만, 숨겨진 내부 역학으로 인해 진정한 시스템 안정성은 보장될 수 없다고 말했습니다.

그들은 또한 사용자가 컨텍스트를 확장하고 제공하는 데 도움을 주지만, 초기 방향과 조건 부여는 사용자로부터 온다고 말했습니다.
- GPT는 단순 반복 작업을 돕지만, 제약이 필요합니다: 멤버들은 GPT로 복잡한 파이프라인을 만들 때 온톨로지, 아키텍처, 한계를 설명할 필요성에 대해 논의했습니다.

한 멤버는 반환되는 모든 것이 잠재 변수라고 불리는 것이기 때문에 먼저 GPT로 생성한 다음 직접 편집하거나 보완하는 것이 더 낫다고 제안했습니다.
- AI는 발명하지 않고 패턴을 찾습니다: 한 멤버는 현재 ChatGPT는 통계적 자동화이며, 통계적 패턴 인식 모델 위에서 단순 반복 작업을 다시 수행할 잠재 변수를 찾을 때까지 반복한다고 말했습니다.

그들은 이것이 AI가 발명할 수 없다고 말하는 이유라고 덧붙였습니다. AI는 발명할 수 없으며, 엄청난 양 때문에 우리가 아직 (또는 전혀) 조합하지 못한 패턴을 찾아낼 뿐입니다.
- 혁신은 재조합 + 통찰입니다: 한 멤버는 인간 또한 이전 지식을 재조합하고, 패턴을 연결하며, 이전 아이디어를 반복함으로써 발명한다고 말했습니다.

그들은 인간의 발명 중 무에서 나오는 것은 거의 없으며, 대부분의 혁신은 재조합 + 통찰이라고 덧붙였습니다.
- Loopt는 실패가 아니라 학습 경험이었습니다: 한 멤버가 Sam Altman의 말을 인용했습니다. "저는 Loopt를 실패라고 부르지 않을 것입니다. 제가 원했던 대로 되지는 않았지만, 확실히 재미있었고, 많은 것을 배웠으며, 투자를 시작할 만큼 충분한 돈을 벌어서 현재 직업으로 이어졌습니다."

다른 멤버는 "Potato, potáto, 성공할 때까지 계속 실패하세요. 실패는 실패가 아니라 학습입니다. 같은 격언이 다른 형태로 표현된 것일 뿐입니다."라고 답했습니다.

---

### OpenAI ▷ #api-discussions (12 messages🔥):
> 제어 이론적 프롬프트 규제, LLM 발명 대 패턴 인식, 잠재 변수, 통계적 자동화
- 블랙박스 LLM에서의 제어 이론적 프롬프트 규제: 한 사용자가 블랙박스 함수 F(x)로 표현되는 내부 LLM + 오케스트레이션 스택에 제어 이론적 프롬프트 규제를 의미 있게 적용할 수 있는지 물었습니다.

응답은 외부 행동 제어는 가능하지만, 숨겨진 내부 역학으로 인해 진정한 시스템 안정성은 보장될 수 없다고 밝혔습니다.
- LLM: 잠재 변수를 위한 통계적 오토마타 반복: ChatGPT는 통계적 패턴 인식 모델 위에서 작동하는 통계적 자동화의 한 형태이며, 단순 반복 작업을 다시 수행할 잠재 변수를 찾을 때까지 반복한다는 제안이 있었습니다.

한 사용자는 "이것이 AI가 발명할 수 없다고 말하는 이유입니다... AI는 발명할 수 없으며, 엄청난 양 때문에 우리가 아직 (또는 전혀) 조합하지 못한 패턴을 찾아낼 뿐입니다."라고 말했습니다.
- 인간 대 AI 발명 - 재조합 논쟁: 한 사용자는 AI 발명은 인간의 발명과 유사하게 이전 지식을 재조합하고 패턴을 연결하는 것으로 제한된다고 주장했습니다.

다른 사용자는 인간은 미리 정의된 이유 없이 새로운 패턴을 만들 수 있다고 반박하며, 예술을 예로 들었습니다. "그냥 그렇게 하고 싶었어요."
- Sam Altman의 Loopt: 실패인가 비옥한 토양인가?: 한 사용자가 Sam Altman의 말을 인용했습니다. "저는 Loopt를 실패라고 부르지 않을 것입니다. 제가 원했던 대로 되지는 않았지만, 확실히 재미있었고, 많은 것을 배웠으며, 투자를 시작할 만큼 충분한 돈을 벌어서 현재 직업으로 이어졌습니다."

사용자는 "실패는 실패가 아니라 학습이며, 같은 격언이 다른 형태로 표현된 것일 뿐입니다."라고 언급했습니다.

---

### Nous Research AI ▷ #general (91 messages🔥🔥):
> MiSTer FPGA, Anthropic의 RefusalBench, Qwen 3.5, 오픈소스 어노테이터, Tiny Tapeout IC
- MiSTer의 도난당한 과거가 논쟁을 유발합니다: 논의는 MiSTer 프로젝트를 중심으로 이루어졌으며, 코드가 Till로부터 도난당하여 MiST를 죽였다는 비난과 함께, 오늘날 불법적으로 사용되는 GPL 코드에 대한 추가 논의가 있었습니다.

한 멤버가 프로젝트의 출처와 논란을 상세히 설명하는 블로그 게시물을 공유했습니다.
- Tiny Tapeout이 경제적인 IC 실험을 가능하게 합니다: 한 멤버가 tinytapeout.com 링크를 공유했습니다. 이곳에서는 실제로 적은 비용으로 IC를 테이프 아웃할 수 있지만, 디자인은 다소 작아야 합니다.
- Anthropic이 DeepSeek의 의심스러운 복제를 비난합니다: Anthropic이 DeepSeek이 허락 없이 자신들의 AI를 복사한 것에 대해 분노하고 있다는 기사 링크가 공유되었으며, 이는 Anthropic 자신의 관행과 "Anthropic Furious at Deepseek"이라는 이 기사를 고려할 때 아이러니에 대한 논쟁을 촉발했습니다.

한 멤버는 "네, 우리는 막장 드라마를 좋아합니다"라고 말하며 상황에 대한 냉소적인 시각을 제시했습니다.
- Qwen 3.5가 놀라운 발전을 이룹니다: Qwen3.5-35B-A3B가 Qwen3-235B-A22B-2507을 이긴 것은 미친 짓이라고 언급되었습니다. 또한 기본 웨이트가 출시된 huggingface.co/Qwen/Qwen3.5-35B-A3B-Base 링크도 공유되었습니다.

또한 5.3 Codex가 API에 출시되었습니다: 입력 1.75달러, 출력 14달러로 Anthropic보다 훨씬 저렴합니다.
- 규제 포획이 비난받을 만한 현실을 드러냅니다: 한 멤버가 Baidu와 Anthropic에 대한 논의에 대해 "규제 포획"이라는 두 단어로 응답하며, 잠재적인 부당한 영향력에 대한 우려를 암시했습니다.

다른 멤버는 "Baidu는 중국에서 규제 포획으로도 알려져 있습니다."라고 언급했습니다.

---

### Nous Research AI ▷ #ask-about-llms (2 messages):
> Hermes, 비정렬성 발현, 파인튜닝, 악의적인 AI, AI 안전성
- 비정렬성 발현을 위한 Hermes 파인튜닝?: 한 멤버가 Hermes를 비정렬성 발현, 즉 더 간단히 말해 악의적으로 변하도록 파인튜닝하는 것을 테스트한 사람이 있는지 문의했습니다.
- AI 파인튜닝의 윤리적 함의: 이 문의는 악의적인 목적으로 AI 모델을 의도적으로 파인튜닝하는 것의 윤리적 함의에 대한 우려를 제기하며, AI 안전성 연구의 중요성을 강조합니다.

---

### Eleuther ▷ #general (60 messages🔥🔥):
> 잠재 추론 토큰, Deepseek R1 논문, EleutherAI Pythia-2.8b HF 웨이트 버그, Google 학생 연구원 프로그램 2026, lesswrong.com/posts/2pkNCvBtK6G6FKoNn/so-you-think-you-ve-awoken-chatgpt
- LLM이 잠재 추론 부스트를 얻습니다: LLM에 의해서만 생성되고 사용자에게는 표시되지 않는 특수 토큰을 사용하여 추론을 향상시키는 "잠재 추론"에 대한 논의가 있었으며, 이는 성능과 보안을 잠재적으로 개선할 수 있습니다.

"Latent Reasoning" 논문 링크가 공유되었습니다.
-   Deepseek R1 논문이 추론에 대한 논의를 촉발했습니다: Deepseek R1 논문을 참조하며, 대규모 모델의 추론이 직접적인 데이터 학습보다는 강화 학습에서 비롯된다는 논의가 있었습니다.

인간이 읽기 쉽게 하기 위해 일반적으로 보조 보상이 사용되지만, 이 접근 방식이 최적인지는 불확실하다고 언급되었습니다.
-   EleutherAI Pythia-2.8b 가중치 버그가 HF에서 발견되었습니다: 한 멤버가 EleutherAI의 Pythia-2.8b로 논문을 재현하려던 중 버그를 보고했습니다. Hugging Face Hub가 선택된 리비전과 관계없이 동일한 가중치를 제공했다는 내용입니다.

pytorch_model.bin과 model.safetensors 모두 다른 스텝에서 동일한 SHA256을 가졌지만, 샤딩된 파일(model-00001-of-00002.safetensors)은 달랐다는 것이 발견되었습니다.
-   EleutherAI가 Pythia-2.8b HF 가중치 버그를 수정했습니다: EleutherAI Pythia-2.8b 가중치 버그는 한 멤버에 의해 인정되었으며, 그는 이를 수정하려던 중 HF에 의해 속도 제한을 받았다고 언급했습니다.

샤딩된 파일에 대한 혼란이 있었는데, 1-of-2 및 2-of-2 파일이 올바르면 사용자가 이를 결합하여 모델을 로드할 수 있다는 이해가 있었습니다.
-   일부 EleutherAI 모델에서 중복 데이터가 발견되었습니다: 14m 및 30m 모델이 HF에 라벨링된 대로 중복 버전이 아닌 디듀플리케이트 버전으로 밝혀졌습니다.

올바르게 라벨링된 중복 모델로 교체하기 위한 재학습이 진행 중이며, 새로운 HF 모델인 14m 및 31m에 대한 링크가 제공되었고, 업로드는 대략 정각에 완료될 예정입니다.

---

### Eleuther ▷ #research (27 messages🔥):
> Baguettotron, Nature에 게재된 ML 논문, ViT에 문제 발생?, Differential Attention
-   Baguettotron이 출시되었습니다!: Baguettotron 모델은 4608개의 피처와 완전한 자동 해석 라벨을 특징으로 하며, 7억 7,400만 토큰으로 학습되었고, 레이어 48/80, 8배 확장, top_k 32를 사용합니다. 제작자는 또한 맥락 설명을 위해 X 게시물을 공유했습니다.

제작자는 라이브 데모 링크를 제공했습니다.
-   Nature 출판물 = 약세 신호?: 한 멤버는 DeepMind가 하는 경우를 제외하고 Nature에 게재된 ML 논문은 약세 신호라고 농담했습니다.

이 발언은 골격 안정화와 세부 렌더링을 기술적으로 연결하는 게이팅 메커니즘에 대한 상세한 설명에 대한 응답이었습니다.
-   Vision Transformer에 문제가 발생했나요?: 한 멤버는 ViT를 CIFAR10에 순진하게 적용하는 것은 잘못된 것이라고 말했습니다. 이는 간단한 선형 레이어로 패치를 토큰으로 변환하는 것이 불충분하여 최적화되지 않은 표현으로 이어진다고 주장했습니다.
-   Differential Attention Ablation Study 피드백: 한 멤버가 differential attention과 관련된 어블레이션 스터디에 대한 피드백을 요청하며 PDF 문서를 공유했습니다.

한 응답자는 어블레이션이 differential attention이 근본적으로 더 나은지 또는 단순히 해당 방법으로부터 불균형적으로 이득을 얻는지를 증명하지 못했다고 비판했습니다.

---

### Eleuther ▷ #interpretability-general (1 messages):
> LLM 행동 디버깅, LLM 추론 트레이스, LLM 거부, LLM 에이전트 행동
-   연구원들이 LLM 디버깅 인터뷰를 찾고 있습니다: 연구원들은 LLM 행동 평가 또는 디버깅에 참여하는 개인들과 20~30분간의 인터뷰를 진행하고자 하며, 보상으로 25달러 상당의 Amazon 기프트 카드 또는 자선 기부를 제공합니다.

특히 LLM이 특정 출력을 생성한 이유를 이해하는 데 도움이 되는 워크플로우와 도구에 관심이 있으며, 추론 트레이스, 거부, 에이전트 행동에 중점을 둡니다. 예약 링크가 제공되었습니다.
-   LLM 평가 중점 영역 상세 설명: 이 연구는 특히 CoT(chain-of-thought) 검사, 해석 가능성 또는 잠재 지식, 에이전트 행동 디버깅, LLM의 거부 또는 안전 실패 분석과 관련된 작업을 하는 개인을 대상으로 합니다.

목표는 평가 및 디버깅 프로세스 동안 시간 할당을 매핑하여 현재 관행에 대한 귀중한 통찰력을 제공하는 것입니다.

---

### Eleuther ▷ #lm-thunderdome (2 messages):
> lm-evaluation-harness 버그 수정
-   작은 PR이 까다로운 테스트 트윅을 해결합니다: 한 멤버가 lm-evaluation-harness의 버그를 수정하기 위해 한 줄짜리 PR을 제출했습니다.

그는 이 수정이 검토하기 매우 간단할 것이라고 언급했습니다.
-   Athena가 지원에 감사드립니다: 한 멤버가 버그 수정 제출에 대해 감사를 표했습니다.

이러한 인정은 프로젝트의 협력적 특성을 강조합니다.

---

### Eleuther ▷ #gpt-neox-dev (2 messages):
> eval_adapter.py 수정
-   Forward Pass 버그가 해결되었습니다: 한 멤버가 eval_adapter.py의 수정된 버전을 공유하며, forward pass 호출의 문제를 해결했습니다.

이 해결책은 forward pass 호출을 래핑하고 요소를 eval_adapter.py 파일의 스키마와 일치하도록 조정하는 것을 포함합니다.
-   어댑터 수정의 리포지토리 통합 고려: 한 멤버가 커뮤니티의 관심 여부에 따라 어댑터 수정을 리포지토리에 통합할 것을 제안했습니다.

이는 eval_adapter.py 사용자들을 위해 forward pass 문제를 더 광범위하게 해결하는 것을 목표로 합니다.

---

### GPU MODE ▷ #general (8 messages🔥):
> LLM 메모리 트레이스, IO 테스트 라이브러리, RTX 카드에서 소형 모델 학습, Graph DB vs Vector DB, Tiny GPU Compiler
-   SOTA 메모리 트레이스 방법 모색: 한 멤버가 LLM 워크로드에서 메모리 트레이스를 생성하는 SOTA 방법에 대해 문의했습니다.

즉각적인 논의에서는 특정 방법이 공유되지 않았지만, 질문 자체는 LLM 애플리케이션 내에서 메모리 사용을 최적화하는 데 대한 관심을 나타냅니다.
-   Tiny GPU Compiler가 오픈소스 GPU 하드웨어를 목표로 합니다: 한 멤버가 오픈소스 GPU 하드웨어를 목표로 하는 교육용 MLIR 기반 컴파일러인 tiny-gpu-compiler를 소개했으며, 이 GitHub 리포지토리에서 설명합니다.

이 컴파일러는 C-like GPU 커널 언어를 16비트 바이너리 명령어로 변환하며, tiny-gpu-compiler에서 사용할 수 있는 단계별 실행 분석을 위한 대화형 웹 비주얼라이저를 포함합니다.
-   Graph DB가 Vector DB에 도전합니다: 한 멤버가 에이전트를 위해 Vector DB 대신 Graph DB가 근본적으로 어떤 도움을 주는지 문의했습니다.

이 대화는 자세히 설명되지는 않았지만, 질문은 에이전트 기반 애플리케이션을 위한 대체 데이터베이스 아키텍처를 탐색하는 것을 시사합니다.
-   RTX 카드를 사용하여 소형 모델을 학습하는 방법: 한 멤버가 RTX 2070-2080 또는 3070-3080 카드를 사용하여 소형 모델(1억 2,500만 매개변수)을 학습하는 방법에 대해 질문했습니다.

그는 커스텀 커널을 사용하는 자신의 GTX 1080 Ti 설정과 비교하기 위해 초당 처리되는 토큰 수에 대한 정보를 찾고 있었습니다.

---

### GPU MODE ▷ #triton-gluon (3 messages):
> Triton, Gluon, TTGIR, TTIR
-   Gluon은 TTGIR 위에 구축되었으며 Triton의 대체품이 아닙니다: 한 멤버가 Gluon이 Triton의 확장인지 대체품인지 문의했고, 다른 멤버는 Gluon이 TTIR 대신 TTGIR 위에 구축된 새로운 언어라고 명확히 설명했습니다.
-   Gluon: 새로운 언어: Gluon이 Triton의 단순한 확장이 아니라 완전히 새로운 언어로 설계되었다는 점이 논의에서 명확해졌습니다.

---

### GPU MODE ▷ #cuda (17 messages🔥):
> GPU 메모리 최적화, CUDA memcpy_async 및 __syncthreads(), CPU-CUDA 검증 전략
-   최적화: GPU에서 더 많은 성능을 끌어내세요: GPU 코드를 최적화하려면, 연산이 읽어야 하는 메모리 양과 GPU가 이 메모리를 읽는 속도, 그리고 연산이 수행해야 하는 작업 수와 GPU가 이를 수행하는 속도를 측정해야 합니다.

RMS norm의 경우 성능은 메모리 바운드일 가능성이 높으므로, 메모리 접근 패턴과 대역폭 활용 최적화에 집중하고 Nvidia의 CUDA 비동기 복사 문서(Asynchronous Copies)를 확인해야 합니다.
-   동기화: CUDA의 비동기 메모리 복사에 대한 심층 분석: CUDA C++ cuda::memcpy_async와 함께 __syncthreads()를 사용하는 것은 메모리 가시성을 위해 필수적이며, 모든 스레드가 어떤 스레드에 의해 복사된 데이터라도 볼 수 있도록 보장합니다. 이는 CUDA 비동기 배리어 문서(asynchronous barriers)를 참조하여 명확히 설명되었습니다.
-   포트 권한: CUDA 코드 검증: CPU 코드를 프로덕션용 CUDA로 포팅할 때, 검증에 대한 일반적인 지침에는 부동 소수점 정밀도 관리와 다양한 부동 소수점 크기에 대한 gemm과 같은 연산의 표준 허용 오차 설정이 포함됩니다. 특히 GPU 버전 관리 중에 중요합니다.

접근 방식은 PyTorch 또는 VLLM과 같은 컨텍스트에 따라 달라지며, 검증할 코드 단위(커널), 테스트할 입력/출력 수, 그리고 단순한 정밀도를 넘어선 광범위한 고려 사항을 포함합니다.

---

### GPU MODE ▷ #torch (2 messages):
> FlashAttention 3, PyTorch의 SDPA, 사전 빌드된 Wheels
-   Flash Attention 3 사전 빌드된 wheels가 출시되었습니다!: 다양한 CUDA 버전(12.6+, 13), CPU(x86, ARM) 및 OS(Linux, Windows)용 Flash Attention 3 사전 빌드된 wheels가 download.pytorch.org에서 제공됩니다.

이 wheels는 LibTorch ABI 안정성을 가지며 Python 버전 >= 3.10 및 torch 버전 >= 2.9에서 작동해야 합니다.
-   Torch의 SDPA 커널 선택 검토: 한 사용자가 Torch의 SDPA(Scaled Dot-Product Attention)가 올바른 커널을 어떻게 선택하는지 질문했습니다.

답변은 디스패처가 FA3 커널을 사용하도록 리디렉션하기 위해 activate_flash_attention_impl("FA3")를 사용하는 것을 포함했습니다.

---

### GPU MODE ▷ #announcements (1 messages):
> eBPF, GPU, 프로파일러, OS 정책
-   eBPF가

### Yannick Kilcher ▷ #ml-news (6 messages):
> Liquid AI의 LFM2-24B-A2B, WarClaude, Alibaba Qwen 출시
- Liquid AI가 LFM2-24B-A2B를 공개했습니다: Liquid AI는 최신 발전 사항을 선보이는 블로그 게시물에서 LFM2-24B-A2B의 출시를 발표했습니다.

이 모델은 효율적이고 효과적인 AI 솔루션의 새로운 표준을 제시하는 것을 목표로 합니다.
- Alibaba Qwen이 의문을 해소했습니다: Alibaba는 X의 게시물에서 Qwen에 대한 업데이트를 도입하여 기능과 접근성을 향상시켰습니다.

사용자들은 개선 사항 및 새로운 기능에 대한 자세한 내용을 발표에서 확인할 것을 권장합니다.
- X에 WarClaude가 등장했습니다: 한 멤버가 WarClaude에 관심을 표명하며 X의 관련 콘텐츠(게시물 1, 게시물 2 참조)로 연결했습니다.

WarClaude가 실제로 무엇인지에 대한 다른 논의나 맥락은 제공되지 않았습니다.

---

### Manus.im Discord ▷ #general (19 messages🔥):
> 취약점 보고, 무제한 채팅 티어, 계정 이전, Telegram 크레딧 사용량, 데스크톱 앱 청구
- 취약점 보고 문의: 한 사용자가 취약점을 발견했다고 보고했으며, 피드백 페이지로 안내받았습니다.

사용자는 취약점을 어떻게, 어디에 보고해야 할지 혼란스러워했습니다.
- 무제한 티어 고려: 한 사용자가 Telegram의 Manus Agent 크레딧이 빠르게 소진되는 문제로 인해 ChatGPT 또는 Grok과 유사한 잠재적인 무제한 채팅 티어에 대해 문의했습니다.

담당자는 피드백에 감사하며 제품 개선을 위해 지속적으로 노력하고 있다고 답변했습니다.
- 계정 이전 문제: 한 사용자가 자신의 프로젝트를 다른 계정으로 이전해달라고 요청하며 관련 이메일 주소를 제공했습니다.

지원팀은 현재 직접적인 계정 이전은 지원되지 않으며, 사용자들에게 콘텐츠를 로컬로 다운로드하고 새 계정에서 새 작업을 시작할 것을 권장했습니다.
- Telegram Agent의 크레딧 소비: 한 사용자가 Telegram 에이전트가 매우 좋지만 높은 크레딧 사용량으로 인해 계정에서 많은 포인트를 소진시킨다고 언급했습니다.

이는 크레딧 문제 완화를 위한 구독 옵션에 대한 이전 질문을 재확인시켜 줍니다.
- AI/ML 엔지니어가 진지한 AI 제품 스케일링을 위한 전문성을 제공합니다: 한 AI/ML 엔지니어가 스케일링 가능한 진지한 AI 제품 구축을 위한 전문성을 제공하며, 인퍼런스 비용, 메모리 설계, 부하 시 시스템 동작의 중요성을 강조했습니다.

그는 지난 몇 년간 기술적 결정이 제품의 생존 여부에 실제로 영향을 미치는 AI 시스템에서 작업했습니다.

---

### Modular (Mojo 🔥) ▷ #general (1 messages):
darinsimmons: Zayden님 환영합니다. 이 Discord는 Modular, mojo, MAX에 대한 논의를 위한 공간입니다.

---

### Modular (Mojo 🔥) ▷ #mojo (7 messages):
> Mojo의 문자열 템플릿, Writable 및 Writer 트레이트, ExternalFunction 구조체
- Mojo의 문자열 템플릿 엔진 제안이 나왔습니다: 한 멤버가 Mojo의 새로운 문자열 템플릿 기능에 대한 제안을 공개했으며, 포럼에서 토론 스레드가 진행 중입니다.

이 기능은 1.0 버전 이후에 나올 가능성이 높으며, 현재의 Writable/Writer 트레이트를 더 복잡한 TemplatedWritable로 확장하기를 희망하고 있습니다.
- Writable 및 Writer 트레이트에 대한 개선이 필요합니다: 현재의 Writable 및 Writer 트레이트는 다른 트레이트 또는 기본 트레이트 메서드/타입을 통한 확장/커스터마이징 지점을 최소화해야 합니다.

로드맵은 제안을 다루기 전에 Int 통합과 같은 다른 기능을 우선시할 것이며, write_to 및 write_repr_to 구현을 단일 함수로 통합하는 것을 목표로 합니다.
- ExternalFunction 구조체 트릭: 한 멤버가 ExternalFunction 구조체를 영감으로 삼아 함수 시그니처를 매개변수/반환 타입으로 분해하는 더 멋진 버전을 찾고 있다고 언급했습니다.

그들은 모든 외부 포인터에 대한 원본 캐스트를 코딩해야 할 것입니다.

---

### MCP Contributors (Official) ▷ #general (8 messages🔥):
> Github CI 실패, 문서의 깨진 링크, Linux Foundation Summit, Ezra Klein 에이전트
- Github CI 실패 수정 조사: 한 멤버가 PR 2278에서 npm run generate, npm run format, npm run check가 모두 로컬에서 통과했지만 CI에서 실패가 발생했다고 보고했습니다.

근본 원인은 docs/community/seps/index.mdx의 깨진 링크로 이어진 누락된 파일이었습니다.
- Linux Foundation Summit 모임: 한 멤버가 캘리포니아 나파에서 열리는 LF Member Summit에 참석하는 다른 사람들에게 MCP에 대해 만나서 이야기하자고 초대했습니다.

메시지에는 장소나 일정에 대한 추가 세부 정보가 제공되지 않았습니다.
- Ezra Klein이 에이전트에 대해 배웁니다: 한 멤버가 Ezra Klein이 에이전트에 대해 배우는 YouTube 동영상을 공유했습니다.

해당 동영상은 추가적인 설명 없이 공유되었습니다.

---

### aider (Paul Gauthier) ▷ #general (4 messages):
> Aider 향후 업데이트, Aider의 Git 서브모듈 지원, Aider를 위한 저비용 LLM
- Aider의 미래 불확실: 한 사용자가 Aider가 여전히 활발하게 개발 중인지, 그리고 권장되는 대안이 있는지 문의했습니다.

다른 멤버는 Aider보다 더 발전된 다른 CLI가 있다고 언급했습니다.
- Aider는 Git 서브모듈을 지원하지 않습니다: 한 컴퓨터 과학자가 Aider가 git 서브모듈을 지원하지 않으며, 이 GitHub 이슈에서 자세히 설명된 개선 사항을 제안했습니다.

그들은 이 제안된 기능에 대한 피드백과 조언을 구하고 있습니다.
- Aider를 위한 저비용 LLM 찾기: 한 멤버가 Gemini가 토큰을 빠르게 소진하여 Aider와 함께 사용할 저비용 LLM을 찾는 데 대한 조언을 구하고 있습니다.

그들은 Aider 프레임워크 내에서 비용 효율성과 사용성을 균형 있게 갖춘 LLM을 찾고 있습니다.

---

### aider (Paul Gauthier) ▷ #questions-and-tips (1 messages):
> Aider의 복잡한 작업 한계, 반복 작업을 위한 Aider 스크립팅, 외부 스크립트 또는 에이전트와 Aider 사용, 함수 사용법 찾기
- 사용자가 Aider의 퍼지 파일 찾기 기능이 기대에 못 미친다고 지적합니다: 한 사용자가 Aider를 여러 파일에 걸쳐 퍼지 검색 및 교체와 같은 작업에 유용한 AI 도구로 평가하지만, 더 복잡한 시나리오에서는 한계에 직면하고 있다고 공유했습니다.

사용자는 한 번에 너무 많은 파일을 처리할 때 diff 포맷팅 문제에 부딪혀, 더 작은 덩어리로 작업해야 합니다.
- 작업 자동화를 위해 스크립트로 Aider 활용하기: 사용자는 파일들을 반복하며 편집을 수행하는 것과 같이 Aider로 반복적인 작업을 자동화하기 위해 외부 스크립트를 사용하는 방법에 대한 지침을 구하고 있습니다.

그들은 Aider와의 이러한 종류의 상호작용을 이미 용이하게 하는 기존 도구가 있는지 묻고 있습니다.
- 에이전트: Aider의 다음 프론티어?: 사용자는 자신이 원하는 기능이 AI 에이전트의 개념과 일치하는지 궁금해하며, Aider 포크 또는 opendesk나 cline와 같은 도구를 탐색할 의향이 있습니다.

그들은 VSCode에서 수동 개입 없이 함수 사용법을 찾고, 특정 기준을 충족하는지 확인한 다음, 줄을 추가하고 새 매개변수를 전달하여 파일을 편집하는 워크플로우를 개선하고자 합니다.
- 사용자가 모든 함수 사용법을 찾는 데 도움을 요청합니다: 사용자는 함수의 모든 사용법을 찾는 프로세스를 자동화하고 싶어 합니다.

그들은 사용법이 특정 기준을 충족하는지 확인한 다음, 두 줄을 더 추가하고 새 매개변수를 전달하는 간단한 파일 편집을 하고 싶어 합니다.

---

### tinygrad (George Hotz) ▷ #general (4 messages):
> tiny-gpu, AMD Ryzen AI, MLIR 컴파일러
- Tiny-GPU 컴파일러 출시!: 한 멤버가 오픈소스 GPU 하드웨어를 대상으로 하는 교육용 MLIR 기반 컴파일러인 tiny-gpu-compiler를 대화형 웹 시각화 도구와 함께 소개했습니다.
- Tiny-GPU 컴파일러, 바이너리화: tiny-gpu-compiler는 C-유사 GPU 커널 언어를 Verilog로 작성된 오픈소스 GPU인 tiny-gpu를 대상으로 하는 16비트 바이너리 명령어로 컴파일합니다.
- AMD Ryzen AI 등장: CES 2026 이후, AMD.com에서 새로운 AMD Ryzen AI를 출시했습니다.

---

*이 문서는 news.smol.ai의 뉴스레터를 자동 번역한 것입니다.*
